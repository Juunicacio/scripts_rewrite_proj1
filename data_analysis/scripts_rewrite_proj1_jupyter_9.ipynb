{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#import pyproj as pj # for reliable gps\n",
    "# or from pyproj import Geod (and remove the pj when executing the functionality)\n",
    "from pyproj import Geod\n",
    "import numpy as np # for reliable gps\n",
    "from collections import Counter # for reliable gps\n",
    "import datetime as dt # for reliable gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurtleData:\n",
    "    \"\"\"Commom base class for all turtle's data \"\"\"\n",
    "    \n",
    "    C1 = 'Acquisition Time'\n",
    "    C2 ='Acquisition Start Time'\n",
    "    C3 ='Iridium CEP Radius'\n",
    "    C4 ='Iridium Latitude'\n",
    "    C5 ='Iridium Longitude'\n",
    "    C6 ='GPS Fix Time'\n",
    "    C7 ='GPS Fix Attempt'\n",
    "    C8 ='GPS Latitude'\n",
    "    C9 ='GPS Longitude'\n",
    "    C10 ='GPS UTM Zone'\n",
    "    C11 ='GPS UTM Northing'\n",
    "    C12 ='GPS UTM Easting'\n",
    "    C13 ='GPS Altitude'\n",
    "    C14 ='GPS Horizontal Error'\n",
    "    C15 ='GPS Horizontal Dilution'\n",
    "    C16 ='GPS Satellite Bitmap'\n",
    "    C17 ='GPS Satellite Count'\n",
    "    C18 ='Underwater Percentage'\n",
    "    C19 ='Dive Count'\n",
    "    C20 ='Average Dive Duration'\n",
    "    C21 ='Dive Duration Standard Deviation'\n",
    "    C22 ='Maximum Dive Duration'\n",
    "    C23 ='Maximum Dive Depth'\n",
    "    C24 ='Duration Limit 1 Dive Count'\n",
    "    C25 ='Duration Limit 2 Dive Count'\n",
    "    C26 ='Duration Limit 3 Dive Count'\n",
    "    C27 ='Duration Limit 4 Dive Count'\n",
    "    C28 ='Duration Limit 5 Dive Count'\n",
    "    C29 ='Duration Limit 6 Dive Count'\n",
    "    C30 ='Layer 1 Percentage'\n",
    "    C31 ='Layer 2 Percentage'\n",
    "    C32 ='Layer 3 Percentage'\n",
    "    C33 ='Layer 4 Percentage'\n",
    "    C34 ='Layer 5 Percentage'\n",
    "    C35 ='Layer 6 Percentage'\n",
    "    C36 ='Layer 7 Percentage'\n",
    "    C37 ='Layer 8 Percentage'\n",
    "    C38 ='Layer 9 Percentage'\n",
    "    C39 ='Layer 10 Percentage'\n",
    "    C40 ='Layer 1 Dive Count'\n",
    "    C41 ='Layer 2 Dive Count'\n",
    "    C42 ='Layer 3 Dive Count'\n",
    "    C43 ='Layer 4 Dive Count'\n",
    "    C44 ='Layer 5 Dive Count'\n",
    "    C45 ='Layer 6 Dive Count'\n",
    "    C46 ='Layer 7 Dive Count'\n",
    "    C47 ='Layer 8 Dive Count'\n",
    "    C48 ='Layer 9 Dive Count'\n",
    "    C49 ='Layer 10 Dive Count'\n",
    "    C50 ='Temperature'\n",
    "    C51 ='Satellite Uplink'\n",
    "    C52 ='Receive Time'\n",
    "    C53 ='Repetition Count'\n",
    "    C54 ='Low Voltage'\n",
    "    C55 ='Mortality'\n",
    "    C56 ='Saltwater Failsafe'\n",
    "    C57 ='Iridium Command'\n",
    "    C58 ='Schedule Set'\n",
    "    C59 ='Diagnostic Dive Data'\n",
    "    C60 ='Predeployment Data'\n",
    "    C61 ='Error'\n",
    "    col_names = list([\n",
    "        C1, C2, C3, C4, C5, C6, C7, C8, C9, C10, \n",
    "        C11, C12, C13, C14, C15, C16, C17, C18, C19, C20, \n",
    "        C21, C22, C23, C24, C25, C26, C27, C28, C29, C30, \n",
    "        C31, C32, C33, C34, C35, C36, C37, C38, C39, C40, \n",
    "        C41, C42, C43, C44, C45, C46, C47, C48, C49, C50, \n",
    "        C51, C52, C53, C54, C55, C56, C57, C58, C59, C60, \n",
    "        C61\n",
    "    ])\n",
    "    gps_col_names = list([\n",
    "        C1, C2, C6, C7, C8, C9\n",
    "    ])\n",
    "    ID_ALLGPSDF_COLUMN_NAME = \"All GPS's Track ID\"\n",
    "\n",
    "    @staticmethod\n",
    "    def basedNamesForCsv(lastEntryRowDF, selfDfNameString, selfTurtleTag):\n",
    "        for value in enumerate(lastEntryRowDF):\n",
    "            #print(value[1][0])\n",
    "            lastDate = value[1][0]\n",
    "            date = dt.datetime.strptime(lastDate, \"%Y.%m.%d\")\n",
    "            stringDate = date.strftime(\"%Y\") + \"_\" + date.strftime(\"%b\")\n",
    "            print(f\"The Last Entry in the Dataframe for {selfTurtleTag} is from: \")\n",
    "            print(stringDate)\n",
    "            # Give the CSV a Name based on this values above\n",
    "            # name = allGpsDf_tag_xxxxx_until_lastdate\n",
    "            cvsName = selfDfNameString + \"_Tag_\" + selfTurtleTag + \"_\" + stringDate +\".csv\"\n",
    "            print(f\"The Name of the {selfDfNameString} CSV for the turtleData {selfTurtleTag} is: \")\n",
    "            print(cvsName)\n",
    "            print('--------------')\n",
    "            return cvsName \n",
    "\n",
    "    @staticmethod\n",
    "    def calculateDistance(geodRef, lon1, lat1, lon2, lat2):\n",
    "        # # compute forward and back azimuths, plus distance\n",
    "        az12,az21,dist = geodRef.inv(lon1, lat1, lon2, lat2) #Take the second row and the first row on the count. it shoul give 3 values, but I only need the dist.\n",
    "        # f\"{az12:.3f} {az21:.3f} {dist:.3f}\"\n",
    "        return dist #Put the dist inside the distances variable once empty.\n",
    "    \n",
    "    @staticmethod\n",
    "    def convertUnixTimeFromString(timeString):\n",
    "        return dt.datetime.strptime(timeString, '%Y.%m.%d %H:%M:%S').timestamp() #[i] is the position in an array\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculateSpeed(d, t1, t2):\n",
    "        speed = d / (t2 - t1)\n",
    "        return speed\n",
    "\n",
    "    def __init__(self, tag):\n",
    "        self.turtleTag = tag\n",
    "        self.df = pd.DataFrame()\n",
    "        self.allGpsDf = pd.DataFrame()\n",
    "        self.allGpsDfCsvName = \"\"\n",
    "        #self.allGpsDf2019 = pd.DataFrame()\n",
    "        self.allCleanedGpsDf = pd.DataFrame()\n",
    "        self.allCleanedGpsDfCsvName = \"\"\n",
    "        self.reliableGpsDf = pd.DataFrame()\n",
    "    #def addElement(self, row, header):\n",
    "        #self.__dict__= dict(zip(header, row))\n",
    "\n",
    "    def addDataFromCsv(self, filename):\n",
    "        temporaryDf = pd.read_csv(filename, skiprows=23, names=TurtleData.col_names)\n",
    "        \n",
    "        #print(f' ITS CURRENT DF IS: {self.df}') \n",
    "        #print('--------------')\n",
    "        #print(f' ITS TEMPORARY DF IS {temporaryDf}') \n",
    "        \n",
    "        self.df = self.df.append(temporaryDf, ignore_index=True)\n",
    "        self.df.sort_values(\"Acquisition Time\", inplace = True)\n",
    "\n",
    "    def getTag(self):\n",
    "        return self.turtleTag\n",
    "\n",
    "    def getDf(self):        \n",
    "        return self.df\n",
    "    \n",
    "    def giveAllGpsDf(self):\n",
    "        # see all the columns in the df\n",
    "        #print(self.df.columns)\n",
    "        # see one column at a time        \n",
    "        self.allGpsDf = self.df.copy()\n",
    "        print(TurtleData.gps_col_names)\n",
    "        tempList = TurtleData.gps_col_names.copy()\n",
    "        for c in self.allGpsDf.columns:\n",
    "            print(c)            \n",
    "            if c not in tempList:\n",
    "                self.allGpsDf.drop(c, inplace=True, axis=1)\n",
    "            else:\n",
    "                tempList.remove(c)        \n",
    "\n",
    "        if tempList:\n",
    "            print(\"Colummn Data missing in!\")\n",
    "        else:\n",
    "            print(\"The dataframe contains all the GPS columns\")\n",
    "        \n",
    "        print('-----DF with NaN values ---------')\n",
    "        print(self.allGpsDf)       \n",
    "        \n",
    "        #### Eliminate those GPS's null (NaN) rows from the dataframe\n",
    "        self.allGpsDf.drop(self.allGpsDf[~self.allGpsDf['GPS Latitude'].notna()].index, inplace=True)\n",
    "        self.allGpsDf.reset_index(drop=True, inplace=True) # reset index\n",
    "\n",
    "        print('-----SAME DF without NaN values ---------')\n",
    "        print(self.allGpsDf)\n",
    "\n",
    "        ####Create a column for id GPS points to the left\n",
    "        trackId = self.allGpsDf.index + 1\n",
    "        self.allGpsDf.insert(0, TurtleData.ID_ALLGPSDF_COLUMN_NAME, trackId)\n",
    "        \n",
    "        print(self.allGpsDf)        \n",
    "        print(' End of all GPS Df ^')\n",
    "        print('--------------')    \n",
    "    \n",
    "    def generateAllGpsDfCsvName(self):\n",
    "        # Last entry:\n",
    "        lastEntry = self.allGpsDf['Acquisition Time'].tail(1)\n",
    "        #print(lastEntry)\n",
    "        # separing date from time in that column\n",
    "        lastEntry = pd.Series([[y for y in x.split()] for x in lastEntry])\n",
    "        #print(lastEntry)\n",
    "        # assign the Name in the Class Variable\n",
    "        self.allGpsDfCsvName = TurtleData.basedNamesForCsv(lastEntry, \"allGpsDf\", self.turtleTag)        \n",
    "    \n",
    "    def saveAllGpsData(self, pathToFilePlusCsvName):\n",
    "        self.allGpsDf.to_csv(pathToFilePlusCsvName, index=False)\n",
    "    \n",
    "    def giveAllCleanedGpsDf(self):\n",
    "        # without 2019 date and without duplicate rows\n",
    "        precedentYearRowsTemporaryDf = self.allGpsDf.copy()\n",
    "        print(f\"Before cleaning, the AllGpsDf called: {self.allGpsDfCsvName}, contained {len(precedentYearRowsTemporaryDf.index)} rows\")\n",
    "        \n",
    "        ##### ---------- This Part is not needed ---------- #####\n",
    "        # Remove 2019 data from 'Acquisition Time column:\n",
    "        dateColumn = precedentYearRowsTemporaryDf['Acquisition Time']\n",
    "        #print(dateColumn)\n",
    "        # separing date from time in that column\n",
    "        dateColumn = pd.Series([[y for y in x.split()] for x in dateColumn])\n",
    "        #print(dateColumn)\n",
    "        all2019DateData = []\n",
    "        allOtherDateData = []        \n",
    "        for value in enumerate(dateColumn):\n",
    "            #print(value[1][0])\n",
    "            # assign the date rows to the variable dateData\n",
    "            dateData = value[1][0]\n",
    "            # removing 2019 from the list\n",
    "            if dateData.startswith('2019'):\n",
    "                #print(f\"dateData that starts with 2019 = {dateData}\")\n",
    "                # append the 2019 data to the list\n",
    "                all2019DateData.append(dateData)\n",
    "            else:\n",
    "                #print(f\"dateData that do not starts with 2019 = {dateData}\")\n",
    "                # append any other data to this list\n",
    "                allOtherDateData.append(dateData)\n",
    "        #print(f\" 2019 list = {all2019DateData}\")\n",
    "        #print(f\" 2020/2021 list = {allOtherDateData}\")\n",
    "        ##### ---------- END OF the Part not needed ---------- #####\n",
    "\n",
    "        #### Eliminate those 2019 data rows from the dataframe\n",
    "        ### example: df = df[~df['c'].astype(str).str.startswith('1')]\n",
    "        print(f\"Removing 2019 data from the {self.allGpsDfCsvName}\")\n",
    "        precedentYearRowsTemporaryDf.drop(precedentYearRowsTemporaryDf[precedentYearRowsTemporaryDf['Acquisition Time'].astype(str).str.startswith('2019')].index, inplace=True)\n",
    "        precedentYearRowsTemporaryDf.reset_index(drop=True, inplace=True) # reset index\n",
    "        #print(precedentYearRowsTemporaryDf)\n",
    "        print(f\"After removing 2019 data, the AllGpsDf called: {self.allGpsDfCsvName}, contained {len(precedentYearRowsTemporaryDf.index)} rows\")\n",
    "\n",
    "        ### Eliminate duplicate rows\n",
    "        # Select duplicate rows except first occurrence based on all columns\n",
    "        ## example of Selection by Position, to see example duplicated rows ----------------------------------\n",
    "        ## df.iloc[row_indexer,column_indexer]\n",
    "        print('--------------')\n",
    "        duplicateRowsTemporaryDf = precedentYearRowsTemporaryDf\n",
    "        duplicateRowsTemporaryDf = duplicateRowsTemporaryDf.drop_duplicates(\n",
    "            [\n",
    "                'Acquisition Time','Acquisition Start Time', 'GPS Fix Time', 'GPS Fix Attempt', 'GPS Latitude', 'GPS Longitude'\n",
    "            ], keep='first'\n",
    "        )\n",
    "        print(duplicateRowsTemporaryDf)\n",
    "        print(duplicateRowsTemporaryDf.iloc[13:19,1])\n",
    "        print(f\"Without duplicated rows, the dataframe has now {len(duplicateRowsTemporaryDf.index)} rows\")\n",
    "        print(\"The df without duplicated rows is the duplicateRowsTemporaryDf\")\n",
    "        print('--------------')\n",
    "        print(\"Saving this temporary df into the allCleanedGpsDf...\")\n",
    "        self.allCleanedGpsDf = self.allCleanedGpsDf.append(duplicateRowsTemporaryDf, ignore_index=True)\n",
    "        print(self.allCleanedGpsDf)\n",
    "        print(self.allCleanedGpsDf.iloc[13:19,1])\n",
    "        print(\"The df without duplicated rows is now the self.allCleanedGpsDf\")\n",
    "        print('------- END -------')\n",
    "\n",
    "    def generateAllCleanedGpsDfCsvName(self):\n",
    "        # Last entry:\n",
    "        lastEntry = self.allCleanedGpsDf['Acquisition Time'].tail(1)\n",
    "        #print(lastEntry)\n",
    "        # separing date from time in that column\n",
    "        lastEntry = pd.Series([[y for y in x.split()] for x in lastEntry])\n",
    "        #print(lastEntry)\n",
    "        # assign the Name in the Class Variable\n",
    "        self.allCleanedGpsDfCsvName = TurtleData.basedNamesForCsv(lastEntry, \"allCleanedGpsDf\", self.turtleTag)\n",
    "    \n",
    "    def saveAllCleanedGpsData(self, pathToFilePlusCsvName):\n",
    "        self.allCleanedGpsDf.to_csv(pathToFilePlusCsvName, index=False)\n",
    "\n",
    "    def giveReliableGpsDf(self):\n",
    "        '''\n",
    "        Remove GPS Errors by Angular velocity/Rotational speed \n",
    "        (degree per second)\n",
    "        Geod Object for Calculations is used as objec to calculate \n",
    "        distances between points expressed in lat/lon (in degree)\n",
    "        Choosing a Reference Ellipsoid - distance in degree more \n",
    "        accurate than a spherical method\n",
    "        '''\n",
    "        gpsErrorsTemporaryDf = self.allCleanedGpsDf.copy()\n",
    "        #print(gpsErrorsTemporaryDf)\n",
    "        wgs84_geod = Geod(ellps='WGS84')\n",
    "        ## Converting data to a NumPy array.        \n",
    "        latitudes = gpsErrorsTemporaryDf[['GPS Latitude']].to_numpy() \n",
    "        longitudes = gpsErrorsTemporaryDf[['GPS Longitude']].to_numpy()\n",
    "        acquisitionTimes = gpsErrorsTemporaryDf[['Acquisition Time']].to_numpy()\n",
    "        \n",
    "        #latitudes = gpsErrorsTemporaryDf['GPS Latitude'].reset_index().values\n",
    "        #longitudes = gpsErrorsTemporaryDf['GPS Longitude'].reset_index().values\n",
    "        ##acquisitionTimes = gpsErrorsTemporaryDf[['Acquisition Time']].reset_index().values\n",
    "        #acquisitionTimes = gpsErrorsTemporaryDf[['Acquisition Time']].to_numpy()        \n",
    "        \n",
    "        #print(latitudes.dtype)\n",
    "        #print(longitudes.dtype)\n",
    "        #print(acquisitionTimes.dtype)\n",
    "        \n",
    "        #print(latitudes)\n",
    "        #print(longitudes)\n",
    "        #print(acquisitionTimes)\n",
    "\n",
    "        distances = []\n",
    "        tripTimes = []\n",
    "        speeds = []\n",
    "        remSpeeds = []\n",
    "        pointsToRemove = []        \n",
    "        \n",
    "        distances.append(0)\n",
    "        tripTimes.append(0)\n",
    "        speeds.append(0)\n",
    "\n",
    "        i=1\n",
    "        while i < (len(latitudes)):\n",
    "            foundS = False\n",
    "            previous = i-1\n",
    "            D = 0\n",
    "            S = 100\n",
    "            while (S > 1.111) and (i < len(latitudes)):\n",
    "                D = TurtleData.calculateDistance(wgs84_geod, longitudes[previous], latitudes[previous], longitudes[i], latitudes[i])\n",
    "                t1 = TurtleData.convertUnixTimeFromString(acquisitionTimes[previous,0])\n",
    "                t2 = TurtleData.convertUnixTimeFromString(acquisitionTimes[i,0])\n",
    "                S = TurtleData.calculateSpeed(D,t1,t2)\n",
    "                #print(f\" D = {D}\")\n",
    "                #print('dist: %.3f' % D)\n",
    "                #print(f\" S = {S}\")\n",
    "                #print('S: %.3f' % S)\n",
    "                if(S > 1.111):\n",
    "                    remSpeeds.append(S)\n",
    "                    #print(f\"remSpeeds List: {remSpeeds}\")                    \n",
    "                    pointsToRemove.append(acquisitionTimes[i,0])\n",
    "                    #print(pointsToRemove)\n",
    "                    i+=1\n",
    "                else:\n",
    "                    foundS = True\n",
    "            if(foundS):\n",
    "                distances.append(D)\n",
    "                tripTimes.append(t2-t1)\n",
    "                speeds.append(S)\n",
    "            i+=1\n",
    "        print(\"Length of pointsToRemove List: \")\n",
    "        print(len(pointsToRemove))\n",
    "        print(f\"remSpeeds List: {remSpeeds}\")\n",
    "        print(f\"pointsToRemove List: {pointsToRemove}\")\n",
    "        #---------\n",
    "        #print(self.turtleTag)\n",
    "        #print(remSpeeds)\n",
    "        #print(pointsToRemove)        \n",
    "        \n",
    "        #cond = gpsErrorsTemporaryDf['Acquisition Time'].isin(pointsToRemove)\n",
    "        ##removedPointsRowDf = gpsErrorsTemporaryDf[gpsErrorsTemporaryDf['Acquisition Time'].isin(pointsToRemove)].index, inplace=True)\n",
    "        ##removedPointsRowDf.reset_index(drop=True, inplace=True) # reset index\n",
    "        ##removedPointsRowDf['Speeds > 1,11111 m/s'] = remSpeeds\n",
    "        #removedPointsRowDf = gpsErrorsTemporaryDf.drop(gpsErrorsTemporaryDf[cond].index, inplace = True)\n",
    "        #gpsErrorsTemporaryDf.drop(gpsErrorsTemporaryDf[cond].index, inplace = True)\n",
    "        #gpsErrorsTemporaryDf.reset_index(drop=True, inplace=True)\n",
    "         \n",
    "        #gpsErrorsTemporaryDf['Length (m)'] = distances\n",
    "        #gpsErrorsTemporaryDf['Length (m)'] = gpsErrorsTemporaryDf['Length (m)'].str[0] #remove the brackets of the values in the column\n",
    "        #gpsErrorsTemporaryDf['Time (s)'] = tripTimes\n",
    "        #gpsErrorsTemporaryDf['Speed m/s'] = speeds\n",
    "        #gpsErrorsTemporaryDf['Speed m/s'] = gpsErrorsTemporaryDf['Speed m/s'].str[0] #remove the brackets of the values in the column\t\n",
    "        #print(gpsErrorsTemporaryDf.dtypes)\n",
    "        #gpsErrorsTemporaryDf['Time (h)'] = pd.to_timedelta(gpsErrorsTemporaryDf['Time (s)'], unit='s') # Add a Column with the Time passed from on Point to another in hours\n",
    "         \n",
    "        ##removedPointsRowDf.loc[:, ('Speeds > 1,11111 m/s')] = remSpeeds        \n",
    "        #print(removedPointsRowDf)\n",
    "        print('--------------')\n",
    "        #print(gpsErrorsTemporaryDf)\n",
    "        #print('--------------')\n",
    "        \n",
    "        # Saving Removed Points in another dataframe removedPointsRowDf and dropping those out of the gpsErrorsTemporaryDf\n",
    "        #removedPointsRowDf = gpsErrorsTemporaryDf[gpsErrorsTemporaryDf['Acquisition Time'].isin(pointsToRemove)]\n",
    "        #removedPointsRowDf.loc[:,'Speeds > 1,11111 m/s'] = remSpeeds\n",
    "        ## reseting index\n",
    "        #removedPointsRowDf.reset_index(drop=True, inplace=True) \n",
    "        #removedGPSPoints = removedPointsRowDf.index + 1 \n",
    "        ## Creating a Column for ID Removed Track Points on the Left\n",
    "        #removedPointsRowDf.insert(0, 'Removed GPS by Speed', removedGPSPoints) \n",
    "        ## Saving the amount of removed points data\n",
    "        #qtyremovedGPSpointsSept = len(removedPointsRowDf.index) \n",
    "        #print(f'QTY OF REMOVED POINTS: {qtyremovedGPSpointsSept}')\n",
    "        #print(removedPointsRowDf)\n",
    "        \n",
    "        ## Add the list values as New Columns of the DataFrame\n",
    "        #gpsErrorsTemporaryDf.reset_index(drop=True, inplace=True) \n",
    "        #gpsErrorsTemporaryDf['Length (m)'] = distances\n",
    "        #gpsErrorsTemporaryDf['Length (m)'] = gpsErrorsTemporaryDf['Length (m)'].str[0] #remove the brackets of the values in the column\n",
    "        #gpsErrorsTemporaryDf['Time (s)'] = tripTimes\n",
    "        #gpsErrorsTemporaryDf['Speed m/s'] = speeds\n",
    "        #gpsErrorsTemporaryDf['Speed m/s'] = gpsErrorsTemporaryDf['Speed m/s'].str[0] #remove the brackets of the values in the column\t\n",
    "        #print(gpsErrorsTemporaryDf.dtypes)\n",
    "        #gpsErrorsTemporaryDf['Time (h)'] = pd.to_timedelta(gpsErrorsTemporaryDf['Time (s)'], unit='s') # Add a Column with the Time passed from on Point to another in hours\n",
    "        #print('--------------')\n",
    "        #print(gpsErrorsTemporaryDf)\n",
    "        #print('--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run with terminal OR jupyter notebook:\n",
    "ASSETS_FOLDER = \"assets\"\n",
    "ASSETS_FOLDER_ITENS = os.listdir(ASSETS_FOLDER)# (\"assets\")\n",
    "\n",
    "DATACLEANINGRESULTS_FOLDER = \"dataCleaningResults\"\n",
    "DATACLEANINGRESULTS_FOLDER_ITENS = os.listdir(DATACLEANINGRESULTS_FOLDER)# (\"data_analysis/dataCleaningResults\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_TURTLE_1 = '710333A'\n",
    "TAG_TURTLE_2 = '710348A'\n",
    "\n",
    "INITIAL_TAG_DIGITS = '7103'\n",
    "\n",
    "# Replace spaces in filenames with underlines\n",
    "def replace_space_with_underline(file_name):\n",
    "    return file_name.replace(\" \", \"_\")\n",
    "\n",
    "# Convert excel files into csv\n",
    "def converting_excel_file_into_csv_file(folder_obj, file):        \n",
    "    # read excel   \n",
    "    df_xlsx = pd.read_excel(os.path.join(folder_obj, file))\n",
    "    # change file format\n",
    "    file_in_csv = file.replace(\".xlsx\", \".csv\")\n",
    "    # transform excel to csv file with path to store the CSV file\n",
    "    df_xlsx.to_csv(os.path.join(folder_obj, file_in_csv), index = False)        \n",
    "\n",
    "# Check if some excel file has not been converted into csv yet\n",
    "def check_for_excel_files():\n",
    "    all_my_files = []\n",
    "    n = 0\n",
    "    for file in ASSETS_FOLDER_ITENS:\n",
    "        # put all the file names in the same format\n",
    "        file = replace_space_with_underline(file).lower()\n",
    "        all_my_files.append(file)\n",
    "    \n",
    "    # Create a copy of list\n",
    "    for file in all_my_files[:]:\n",
    "        if file.endswith('.xlsx'):\n",
    "            print('- Excel file = ' + file)\n",
    "            file_name = file.split('.', 1)[0] # remove everything (the format) after the dot\n",
    "            # remove the excel file from my all_my_files list\n",
    "            all_my_files.remove(file)            \n",
    "            # check if another file with the same name in the folder exists\n",
    "            if any(file_name in word for word in all_my_files):            \n",
    "                print(f\"-- Excellent! We've already converted the excel file \\'{file_name}\\' into csv file\")\n",
    "            else:\n",
    "                print(f'-- Oh No! The excel file \\'{file_name}\\' has been not converted. Converting it into csv file...')\n",
    "                # Call function \"Convert excel files into csv\"\n",
    "                converting_excel_file_into_csv_file(ASSETS_FOLDER, file)\n",
    "                file_in_csv = file.replace(\".xlsx\", \".csv\") \n",
    "                all_my_files.append(file_in_csv)\n",
    "                print('---> ' + file_in_csv + ' has been created!')\n",
    "                \n",
    "    # Updated all_my_files List\n",
    "    print('--- CSV files in the assets folder: ', all_my_files)\n",
    "\n",
    "def getTurtlesData():\n",
    "    split_char = '_'\n",
    "    csvs = []        \n",
    "    turtlesData = []\n",
    "    #turtleDfs = []\n",
    "    for file in ASSETS_FOLDER_ITENS:\n",
    "        if file.endswith('.csv'):\n",
    "            # put all the file names in the same format\n",
    "            csv_string_filename = replace_space_with_underline(file).lower()\n",
    "            filename_splitted = csv_string_filename.split(split_char)                        \n",
    "            for word in filename_splitted:\n",
    "                if word.startswith(INITIAL_TAG_DIGITS):\n",
    "                    csvs.append(file)\n",
    "                    currentFileCsv = ASSETS_FOLDER + '\\\\' + file\n",
    "                    print('--------------')\n",
    "                    print(\"Found TAG (\"+ word +\") in filename , check if tag is already associated with an object...\")\n",
    "\n",
    "                    #--------------------\n",
    "                                \n",
    "                    foundTurtleData = None\n",
    "                    # check inside the list if the turtle has already been created with that tag (word)\n",
    "                    for obj in turtlesData:\n",
    "                        if obj.getTag() == word:\n",
    "                            foundTurtleData = obj\n",
    "                            break    \n",
    "                    #--------------------    \n",
    "                                    \n",
    "                    if foundTurtleData == None:\n",
    "                        print(\"Instance for TAG (\"+ word +\") NOT found! Creating a new instance...\")\n",
    "                        # create a TurtleData obj with the turtle tag\n",
    "                        foundTurtleData = TurtleData(word)\n",
    "                        turtlesData.append(foundTurtleData)\n",
    "                        print(\"Instance for TAG (\"+ word +\") CREATED!\")\n",
    "                    else:\n",
    "                        print(\"Instance for TAG (\"+ word +\") ALREADY EXISTS, skipping object creation!\")\n",
    "                        print('--------------')\n",
    "\n",
    "                    # for the instances turtleData objs in the list (for each turtle tag):\n",
    "                    foundTurtleData.addDataFromCsv(currentFileCsv)                    \n",
    "\n",
    "    return turtlesData\n",
    "\n",
    "def checkInstancesAndItsDfs(turtlesData):\n",
    "    print('Created instances for Obj turtleData: ')\n",
    "    for turtleData in turtlesData:        \n",
    "        print(turtleData.getTag())\n",
    "    print('--------------')\n",
    "    print('Created Dataframes: ')\n",
    "    i = 0\n",
    "    for turtleData in turtlesData: \n",
    "        print(f'turtlesData[{i}].df')\n",
    "        print(turtleData.turtleTag)\n",
    "        print(turtleData.df)\n",
    "        print('--------------')\n",
    "        i+=1\n",
    "\n",
    "def getAllGpsDataframes(turtlesData):\n",
    "    for turtleData in turtlesData:\n",
    "        turtleData.giveAllGpsDf()\n",
    "\n",
    "def displayAllGpsDf(turtlesData):\n",
    "    i = 0\n",
    "    for turtleData in turtlesData:\n",
    "        print(f'turtlesData[{i}].allGpsDf')\n",
    "        print(turtleData.turtleTag)\n",
    "        print(turtleData.allGpsDf)\n",
    "\n",
    "def createAllGpsDfCsvNameForEachInstance(turtlesData):\n",
    "    # create a AllGpsDf's name for each turtleData\n",
    "    for turtleData in turtlesData:\n",
    "        turtleData.generateAllGpsDfCsvName()\n",
    "\n",
    "def checkIfAllGpsDfHasBeenSaved(turtlesData):\n",
    "    filesInResultsFolder = []    \n",
    "    \n",
    "    for file in DATACLEANINGRESULTS_FOLDER_ITENS:\n",
    "        filesInResultsFolder.append(file)    \n",
    "    print(filesInResultsFolder)\n",
    "\n",
    "    for turtleData in turtlesData:\n",
    "        if not filesInResultsFolder:\n",
    "            print(f\"The filename {turtleData.allGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allGpsDfCsvName)\n",
    "            turtleData.saveAllGpsData(pathToFilePlusCsvName)\n",
    "            print(f\"{turtleData.allGpsDfCsvName} has been saved in the results folder!\")\n",
    "            #append file in list\n",
    "\n",
    "        elif turtleData.allGpsDfCsvName in filesInResultsFolder:\n",
    "            print(f\"The CSV {turtleData.allGpsDfCsvName} has already been saved in the results folder\")\n",
    "        else:\n",
    "            print(f\"The filename {turtleData.allGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allGpsDfCsvName)\n",
    "            turtleData.saveAllGpsData(pathToFilePlusCsvName)\n",
    "    \n",
    "def getAllCleanedGpsDataframes(turtlesData):\n",
    "    for turtleData in turtlesData:\n",
    "        turtleData.giveAllCleanedGpsDf()\n",
    "\n",
    "def createAllCleanedGpsDfCsvNameForEachInstance(turtlesData):\n",
    "    # create a allCleanedGpsDf's name for each turtleData\n",
    "    for turtleData in turtlesData:\n",
    "        turtleData.generateAllCleanedGpsDfCsvName()\n",
    "\n",
    "def checkIfAllCleanedGpsDfHasBeenSaved(turtlesData):\n",
    "    filesInResultsFolder = []    \n",
    "    \n",
    "    for file in DATACLEANINGRESULTS_FOLDER_ITENS:\n",
    "        filesInResultsFolder.append(file)    \n",
    "    print(filesInResultsFolder)\n",
    "\n",
    "    for turtleData in turtlesData:\n",
    "        if not filesInResultsFolder:\n",
    "            ## Saving AllGpsDf Data \n",
    "            #print(f\"The filename {turtleData.allGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            #pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allGpsDfCsvName)                       \n",
    "            #turtleData.saveAllGpsData(pathToFilePlusCsvName)\n",
    "            #print(f\"{turtleData.allGpsDfCsvName} has been saved in the results folder!\")            \n",
    "            #print('--------------')\n",
    "            ## Saving AllCleanedGps Data\n",
    "            print(f\"The filename {turtleData.allCleanedGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allCleanedGpsDfCsvName)\n",
    "            turtleData.saveAllCleanedGpsData(pathToFilePlusCsvName)\n",
    "            print(f\"{turtleData.allCleanedGpsDfCsvName} has been saved in the results folder!\")\n",
    "\n",
    "        #elif turtleData.allGpsDfCsvName in filesInResultsFolder:\n",
    "            #print(f\"The CSV {turtleData.allGpsDfCsvName} has already been saved in the results folder\")\n",
    "        elif turtleData.allCleanedGpsDfCsvName in filesInResultsFolder:\n",
    "            print(f\"The CSV {turtleData.allCleanedGpsDfCsvName} has already been saved in the results folder\")\n",
    "        else:            \n",
    "            ## Saving AllGpsDf Data\n",
    "            #print(f\"The filename {turtleData.allGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            #pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allGpsDfCsvName)\n",
    "            #turtleData.saveAllGpsData(pathToFilePlusCsvName)\n",
    "            #print(f\"{turtleData.allGpsDfCsvName} has been saved in the results folder!\")              \n",
    "            #print('--------------')\n",
    "            ## Saving AllCleanedGps Data\n",
    "            print(f\"The filename {turtleData.allCleanedGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allCleanedGpsDfCsvName)\n",
    "            turtleData.saveAllCleanedGpsData(pathToFilePlusCsvName)\n",
    "            print(f\"{turtleData.allCleanedGpsDfCsvName} has been saved in the results folder!\")\n",
    "        #print(filesInResultsFolder)\n",
    "        print('--------------')\n",
    "\n",
    "        # THIS FUNCTION ABOVE IS THE SAME FUNCTION TO SAVE THE ALL GPS DF, TRY TO DO ONLY ONE FUNCTION TO BOTH,\n",
    "        # AND ALSO TRY TO MAKE THIS ONE FUNCTION TO WAIT UNTIL THE CLEANING HAS BEEN MADE TO THEN SAVE THE\n",
    "        # ALL CLEANED GPS DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReliableGpsDataframes(turtlesData):\n",
    "    for turtleData in turtlesData:\n",
    "        turtleData.giveReliableGpsDf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Excel file = mytest.xlsx\n",
      "-- Excellent! We've already converted the excel file 'mytest' into csv file\n",
      "- Excel file = tag_710333a_20_sept.xlsx\n",
      "-- Excellent! We've already converted the excel file 'tag_710333a_20_sept' into csv file\n",
      "--- CSV files in the assets folder:  ['710333a_93_condensed.csv', '710348a_49_condensed.csv', 'mytest.csv', 'tag_710333a_20_sept.csv']\n",
      "--------------\n",
      "Found TAG (710333a) in filename , check if tag is already associated with an object...\n",
      "Instance for TAG (710333a) NOT found! Creating a new instance...\n",
      "Instance for TAG (710333a) CREATED!\n",
      "--------------\n",
      "Found TAG (710348a) in filename , check if tag is already associated with an object...\n",
      "Instance for TAG (710348a) NOT found! Creating a new instance...\n",
      "Instance for TAG (710348a) CREATED!\n",
      "--------------\n",
      "Found TAG (710333a) in filename , check if tag is already associated with an object...\n",
      "Instance for TAG (710333a) ALREADY EXISTS, skipping object creation!\n",
      "--------------\n",
      "Created instances for Obj turtleData: \n",
      "710333a\n",
      "710348a\n",
      "--------------\n",
      "Created Dataframes: \n",
      "turtlesData[0].df\n",
      "710333a\n",
      "         Acquisition Time Acquisition Start Time  Iridium CEP Radius  \\\n",
      "0     2019.07.15 14:15:00    2019.07.15 14:15:00                 NaN   \n",
      "1     2019.07.15 14:15:08    2019.07.15 14:15:00                 NaN   \n",
      "2     2019.07.15 14:30:00    2019.07.15 14:15:00                 NaN   \n",
      "3     2019.07.15 14:30:00    2019.07.15 14:30:00                 NaN   \n",
      "4     2019.07.15 14:30:10    2019.07.15 14:30:00                 NaN   \n",
      "...                   ...                    ...                 ...   \n",
      "6903  2021.02.11 05:55:38    2021.02.11 05:00:00                 NaN   \n",
      "6904  2021.02.11 06:00:00    2021.02.11 04:00:00                 NaN   \n",
      "6905  2021.02.11 06:00:10    2021.02.11 06:00:00                 NaN   \n",
      "6906  2021.02.11 08:00:00    2021.02.11 06:00:00                 NaN   \n",
      "6907  2021.02.11 10:57:07    2021.02.11 10:57:07                 3.0   \n",
      "\n",
      "      Iridium Latitude  Iridium Longitude         GPS Fix Time  \\\n",
      "0                  NaN                NaN                  NaN   \n",
      "1                  NaN                NaN  2019.07.15 14:15:08   \n",
      "2                  NaN                NaN                  NaN   \n",
      "3                  NaN                NaN                  NaN   \n",
      "4                  NaN                NaN  2019.07.15 14:30:10   \n",
      "...                ...                ...                  ...   \n",
      "6903               NaN                NaN  2021.02.11 05:55:38   \n",
      "6904               NaN                NaN                  NaN   \n",
      "6905               NaN                NaN  2021.02.11 06:00:10   \n",
      "6906               NaN                NaN                  NaN   \n",
      "6907          38.72645            11.8152                  NaN   \n",
      "\n",
      "     GPS Fix Attempt  GPS Latitude  GPS Longitude GPS UTM Zone  ...  \\\n",
      "0                NaN           NaN            NaN          NaN  ...   \n",
      "1       Resolved QFP     33.384364    -111.811310          12S  ...   \n",
      "2                NaN           NaN            NaN          NaN  ...   \n",
      "3                NaN           NaN            NaN          NaN  ...   \n",
      "4       Resolved QFP     33.384385    -111.811292          12S  ...   \n",
      "...              ...           ...            ...          ...  ...   \n",
      "6903    Resolved QFP     38.720644      11.825379          32S  ...   \n",
      "6904             NaN           NaN            NaN          NaN  ...   \n",
      "6905    Resolved QFP     38.720648      11.825217          32S  ...   \n",
      "6906             NaN           NaN            NaN          NaN  ...   \n",
      "6907             NaN           NaN            NaN          NaN  ...   \n",
      "\n",
      "             Receive Time  Repetition Count  Low Voltage  Mortality  \\\n",
      "0     2019.07.15 14:40:24                 1          NaN        NaN   \n",
      "1     2019.07.15 14:40:24                 1          NaN        NaN   \n",
      "2     2019.07.15 14:40:24                 1          NaN        NaN   \n",
      "3     2019.07.15 14:40:24                 1          NaN        NaN   \n",
      "4     2019.07.15 14:40:24                 1          NaN        NaN   \n",
      "...                   ...               ...          ...        ...   \n",
      "6903  2021.02.11 10:57:07                 1          NaN        NaN   \n",
      "6904  2021.02.11 10:57:07                 1          NaN        NaN   \n",
      "6905  2021.02.11 10:57:07                 1          NaN        NaN   \n",
      "6906  2021.02.11 10:57:07                 1          NaN        NaN   \n",
      "6907  2021.02.11 10:57:07                 1           No        NaN   \n",
      "\n",
      "      Saltwater Failsafe Iridium Command  Schedule Set  \\\n",
      "0                    NaN             NaN     Roof Test   \n",
      "1                    NaN             NaN     Roof Test   \n",
      "2                    NaN             NaN     Roof Test   \n",
      "3                    NaN             NaN     Roof Test   \n",
      "4                    NaN             NaN     Roof Test   \n",
      "...                  ...             ...           ...   \n",
      "6903                 NaN             NaN       Primary   \n",
      "6904                 NaN             NaN       Primary   \n",
      "6905                 NaN             NaN       Primary   \n",
      "6906                 NaN             NaN       Primary   \n",
      "6907                  No             NaN           NaN   \n",
      "\n",
      "           Diagnostic Dive Data  Predeployment Data  Error  \n",
      "0                           NaN                  No    NaN  \n",
      "1                           NaN                  No    NaN  \n",
      "2                           NaN                  No    NaN  \n",
      "3                           NaN                  No    NaN  \n",
      "4                           NaN                  No    NaN  \n",
      "...                         ...                 ...    ...  \n",
      "6903                        NaN                  No    NaN  \n",
      "6904                        NaN                  No    NaN  \n",
      "6905                        NaN                  No    NaN  \n",
      "6906                        NaN                  No    NaN  \n",
      "6907  23094 7698 8878 3 0 0 2 1                  No    NaN  \n",
      "\n",
      "[9528 rows x 61 columns]\n",
      "--------------\n",
      "turtlesData[1].df\n",
      "710348a\n",
      "         Acquisition Time Acquisition Start Time  Iridium CEP Radius  \\\n",
      "0     2019.07.15 14:15:00    2019.07.15 14:15:00                 NaN   \n",
      "1     2019.07.15 14:15:08    2019.07.15 14:15:00                 NaN   \n",
      "2     2019.07.15 14:30:00    2019.07.15 14:15:00                 NaN   \n",
      "3     2019.07.15 14:30:00    2019.07.15 14:30:00                 NaN   \n",
      "4     2019.07.15 14:30:06    2019.07.15 14:30:00                 NaN   \n",
      "...                   ...                    ...                 ...   \n",
      "5666  2021.02.11 04:00:00    2021.02.11 02:00:00                 NaN   \n",
      "5667  2021.02.11 05:50:10    2021.02.11 05:00:00                 NaN   \n",
      "5668  2021.02.11 06:00:00    2021.02.11 04:00:00                 NaN   \n",
      "5669  2021.02.11 06:41:28    2021.02.11 06:00:00                 NaN   \n",
      "5670  2021.02.11 10:40:30    2021.02.11 10:40:30                 4.0   \n",
      "\n",
      "      Iridium Latitude  Iridium Longitude         GPS Fix Time  \\\n",
      "0                  NaN                NaN                  NaN   \n",
      "1                  NaN                NaN  2019.07.15 14:15:08   \n",
      "2                  NaN                NaN                  NaN   \n",
      "3                  NaN                NaN                  NaN   \n",
      "4                  NaN                NaN  2019.07.15 14:30:06   \n",
      "...                ...                ...                  ...   \n",
      "5666               NaN                NaN                  NaN   \n",
      "5667               NaN                NaN  2021.02.11 05:50:10   \n",
      "5668               NaN                NaN                  NaN   \n",
      "5669               NaN                NaN  2021.02.11 06:41:28   \n",
      "5670          37.71965           17.37297                  NaN   \n",
      "\n",
      "     GPS Fix Attempt  GPS Latitude  GPS Longitude GPS UTM Zone  ...  \\\n",
      "0                NaN           NaN            NaN          NaN  ...   \n",
      "1       Resolved QFP     33.384380    -111.811327          12S  ...   \n",
      "2                NaN           NaN            NaN          NaN  ...   \n",
      "3                NaN           NaN            NaN          NaN  ...   \n",
      "4       Resolved QFP     33.384410    -111.811311          12S  ...   \n",
      "...              ...           ...            ...          ...  ...   \n",
      "5666             NaN           NaN            NaN          NaN  ...   \n",
      "5667    Resolved QFP     37.752154      17.380009          33S  ...   \n",
      "5668             NaN           NaN            NaN          NaN  ...   \n",
      "5669    Resolved QFP     37.742126      17.386460          33S  ...   \n",
      "5670             NaN           NaN            NaN          NaN  ...   \n",
      "\n",
      "             Receive Time  Repetition Count  Low Voltage  Mortality  \\\n",
      "0     2019.07.15 14:38:49                 1          NaN        NaN   \n",
      "1     2019.07.15 14:38:49                 1          NaN        NaN   \n",
      "2     2019.07.15 14:38:49                 1          NaN        NaN   \n",
      "3     2019.07.15 14:38:49                 1          NaN        NaN   \n",
      "4     2019.07.15 14:38:49                 1          NaN        NaN   \n",
      "...                   ...               ...          ...        ...   \n",
      "5666  2021.02.11 10:40:30                 1          NaN        NaN   \n",
      "5667  2021.02.11 10:40:30                 1          NaN        NaN   \n",
      "5668  2021.02.11 10:40:30                 1          NaN        NaN   \n",
      "5669  2021.02.11 10:40:30                 1          NaN        NaN   \n",
      "5670  2021.02.11 10:40:30                 1           No        NaN   \n",
      "\n",
      "      Saltwater Failsafe Iridium Command  Schedule Set Diagnostic Dive Data  \\\n",
      "0                    NaN             NaN     Roof Test                  NaN   \n",
      "1                    NaN             NaN     Roof Test                  NaN   \n",
      "2                    NaN             NaN     Roof Test                  NaN   \n",
      "3                    NaN             NaN     Roof Test                  NaN   \n",
      "4                    NaN             NaN     Roof Test                  NaN   \n",
      "...                  ...             ...           ...                  ...   \n",
      "5666                 NaN             NaN       Primary                  NaN   \n",
      "5667                 NaN             NaN       Primary                  NaN   \n",
      "5668                 NaN             NaN       Primary                  NaN   \n",
      "5669                 NaN             NaN       Primary                  NaN   \n",
      "5670                  No             NaN           NaN  0 0 13927 5 0 0 0 0   \n",
      "\n",
      "      Predeployment Data  Error  \n",
      "0                     No    NaN  \n",
      "1                     No    NaN  \n",
      "2                     No    NaN  \n",
      "3                     No    NaN  \n",
      "4                     No    NaN  \n",
      "...                  ...    ...  \n",
      "5666                  No    NaN  \n",
      "5667                  No    NaN  \n",
      "5668                  No    NaN  \n",
      "5669                  No    NaN  \n",
      "5670                  No    NaN  \n",
      "\n",
      "[5671 rows x 61 columns]\n",
      "--------------\n",
      "['Acquisition Time', 'Acquisition Start Time', 'GPS Fix Time', 'GPS Fix Attempt', 'GPS Latitude', 'GPS Longitude']\n",
      "Acquisition Time\n",
      "Acquisition Start Time\n",
      "Iridium CEP Radius\n",
      "Iridium Latitude\n",
      "Iridium Longitude\n",
      "GPS Fix Time\n",
      "GPS Fix Attempt\n",
      "GPS Latitude\n",
      "GPS Longitude\n",
      "GPS UTM Zone\n",
      "GPS UTM Northing\n",
      "GPS UTM Easting\n",
      "GPS Altitude\n",
      "GPS Horizontal Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPS Horizontal Dilution\n",
      "GPS Satellite Bitmap\n",
      "GPS Satellite Count\n",
      "Underwater Percentage\n",
      "Dive Count\n",
      "Average Dive Duration\n",
      "Dive Duration Standard Deviation\n",
      "Maximum Dive Duration\n",
      "Maximum Dive Depth\n",
      "Duration Limit 1 Dive Count\n",
      "Duration Limit 2 Dive Count\n",
      "Duration Limit 3 Dive Count\n",
      "Duration Limit 4 Dive Count\n",
      "Duration Limit 5 Dive Count\n",
      "Duration Limit 6 Dive Count\n",
      "Layer 1 Percentage\n",
      "Layer 2 Percentage\n",
      "Layer 3 Percentage\n",
      "Layer 4 Percentage\n",
      "Layer 5 Percentage\n",
      "Layer 6 Percentage\n",
      "Layer 7 Percentage\n",
      "Layer 8 Percentage\n",
      "Layer 9 Percentage\n",
      "Layer 10 Percentage\n",
      "Layer 1 Dive Count\n",
      "Layer 2 Dive Count\n",
      "Layer 3 Dive Count\n",
      "Layer 4 Dive Count\n",
      "Layer 5 Dive Count\n",
      "Layer 6 Dive Count\n",
      "Layer 7 Dive Count\n",
      "Layer 8 Dive Count\n",
      "Layer 9 Dive Count\n",
      "Layer 10 Dive Count\n",
      "Temperature\n",
      "Satellite Uplink\n",
      "Receive Time\n",
      "Repetition Count\n",
      "Low Voltage\n",
      "Mortality\n",
      "Saltwater Failsafe\n",
      "Iridium Command\n",
      "Schedule Set\n",
      "Diagnostic Dive Data\n",
      "Predeployment Data\n",
      "Error\n",
      "The dataframe contains all the GPS columns\n",
      "-----DF with NaN values ---------\n",
      "         Acquisition Time Acquisition Start Time         GPS Fix Time  \\\n",
      "0     2019.07.15 14:15:00    2019.07.15 14:15:00                  NaN   \n",
      "1     2019.07.15 14:15:08    2019.07.15 14:15:00  2019.07.15 14:15:08   \n",
      "2     2019.07.15 14:30:00    2019.07.15 14:15:00                  NaN   \n",
      "3     2019.07.15 14:30:00    2019.07.15 14:30:00                  NaN   \n",
      "4     2019.07.15 14:30:10    2019.07.15 14:30:00  2019.07.15 14:30:10   \n",
      "...                   ...                    ...                  ...   \n",
      "6903  2021.02.11 05:55:38    2021.02.11 05:00:00  2021.02.11 05:55:38   \n",
      "6904  2021.02.11 06:00:00    2021.02.11 04:00:00                  NaN   \n",
      "6905  2021.02.11 06:00:10    2021.02.11 06:00:00  2021.02.11 06:00:10   \n",
      "6906  2021.02.11 08:00:00    2021.02.11 06:00:00                  NaN   \n",
      "6907  2021.02.11 10:57:07    2021.02.11 10:57:07                  NaN   \n",
      "\n",
      "     GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0                NaN           NaN            NaN  \n",
      "1       Resolved QFP     33.384364    -111.811310  \n",
      "2                NaN           NaN            NaN  \n",
      "3                NaN           NaN            NaN  \n",
      "4       Resolved QFP     33.384385    -111.811292  \n",
      "...              ...           ...            ...  \n",
      "6903    Resolved QFP     38.720644      11.825379  \n",
      "6904             NaN           NaN            NaN  \n",
      "6905    Resolved QFP     38.720648      11.825217  \n",
      "6906             NaN           NaN            NaN  \n",
      "6907             NaN           NaN            NaN  \n",
      "\n",
      "[9528 rows x 6 columns]\n",
      "-----SAME DF without NaN values ---------\n",
      "         Acquisition Time Acquisition Start Time         GPS Fix Time  \\\n",
      "0     2019.07.15 14:15:08    2019.07.15 14:15:00  2019.07.15 14:15:08   \n",
      "1     2019.07.15 14:30:10    2019.07.15 14:30:00  2019.07.15 14:30:10   \n",
      "2     2019.07.15 14:45:08    2019.07.15 14:45:00  2019.07.15 14:45:08   \n",
      "3     2019.07.15 15:00:10    2019.07.15 15:00:00  2019.07.15 15:00:10   \n",
      "4     2019.07.15 15:15:07    2019.07.15 15:15:00  2019.07.15 15:15:07   \n",
      "...                   ...                    ...                  ...   \n",
      "4647  2021.02.10 19:28:58    2021.02.10 19:00:00  2021.02.10 19:28:58   \n",
      "4648  2021.02.10 22:42:32    2021.02.10 22:00:00  2021.02.10 22:42:32   \n",
      "4649  2021.02.11 02:28:20    2021.02.11 02:00:00  2021.02.11 02:28:20   \n",
      "4650  2021.02.11 05:55:38    2021.02.11 05:00:00  2021.02.11 05:55:38   \n",
      "4651  2021.02.11 06:00:10    2021.02.11 06:00:00  2021.02.11 06:00:10   \n",
      "\n",
      "               GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0                 Resolved QFP     33.384364    -111.811310  \n",
      "1                 Resolved QFP     33.384385    -111.811292  \n",
      "2                 Resolved QFP     33.384473    -111.811319  \n",
      "3                 Resolved QFP     33.384442    -111.811340  \n",
      "4     Resolved QFP (Uncertain)     33.384412    -111.811369  \n",
      "...                        ...           ...            ...  \n",
      "4647              Resolved QFP     38.754772      11.809630  \n",
      "4648              Resolved QFP     38.741873      11.821516  \n",
      "4649              Resolved QFP     38.727643      11.821051  \n",
      "4650              Resolved QFP     38.720644      11.825379  \n",
      "4651              Resolved QFP     38.720648      11.825217  \n",
      "\n",
      "[4652 rows x 6 columns]\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                      1  2019.07.15 14:15:08    2019.07.15 14:15:00   \n",
      "1                      2  2019.07.15 14:30:10    2019.07.15 14:30:00   \n",
      "2                      3  2019.07.15 14:45:08    2019.07.15 14:45:00   \n",
      "3                      4  2019.07.15 15:00:10    2019.07.15 15:00:00   \n",
      "4                      5  2019.07.15 15:15:07    2019.07.15 15:15:00   \n",
      "...                  ...                  ...                    ...   \n",
      "4647                4648  2021.02.10 19:28:58    2021.02.10 19:00:00   \n",
      "4648                4649  2021.02.10 22:42:32    2021.02.10 22:00:00   \n",
      "4649                4650  2021.02.11 02:28:20    2021.02.11 02:00:00   \n",
      "4650                4651  2021.02.11 05:55:38    2021.02.11 05:00:00   \n",
      "4651                4652  2021.02.11 06:00:10    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time           GPS Fix Attempt  GPS Latitude  \\\n",
      "0     2019.07.15 14:15:08              Resolved QFP     33.384364   \n",
      "1     2019.07.15 14:30:10              Resolved QFP     33.384385   \n",
      "2     2019.07.15 14:45:08              Resolved QFP     33.384473   \n",
      "3     2019.07.15 15:00:10              Resolved QFP     33.384442   \n",
      "4     2019.07.15 15:15:07  Resolved QFP (Uncertain)     33.384412   \n",
      "...                   ...                       ...           ...   \n",
      "4647  2021.02.10 19:28:58              Resolved QFP     38.754772   \n",
      "4648  2021.02.10 22:42:32              Resolved QFP     38.741873   \n",
      "4649  2021.02.11 02:28:20              Resolved QFP     38.727643   \n",
      "4650  2021.02.11 05:55:38              Resolved QFP     38.720644   \n",
      "4651  2021.02.11 06:00:10              Resolved QFP     38.720648   \n",
      "\n",
      "      GPS Longitude  \n",
      "0       -111.811310  \n",
      "1       -111.811292  \n",
      "2       -111.811319  \n",
      "3       -111.811340  \n",
      "4       -111.811369  \n",
      "...             ...  \n",
      "4647      11.809630  \n",
      "4648      11.821516  \n",
      "4649      11.821051  \n",
      "4650      11.825379  \n",
      "4651      11.825217  \n",
      "\n",
      "[4652 rows x 7 columns]\n",
      " End of all GPS Df ^\n",
      "--------------\n",
      "['Acquisition Time', 'Acquisition Start Time', 'GPS Fix Time', 'GPS Fix Attempt', 'GPS Latitude', 'GPS Longitude']\n",
      "Acquisition Time\n",
      "Acquisition Start Time\n",
      "Iridium CEP Radius\n",
      "Iridium Latitude\n",
      "Iridium Longitude\n",
      "GPS Fix Time\n",
      "GPS Fix Attempt\n",
      "GPS Latitude\n",
      "GPS Longitude\n",
      "GPS UTM Zone\n",
      "GPS UTM Northing\n",
      "GPS UTM Easting\n",
      "GPS Altitude\n",
      "GPS Horizontal Error\n",
      "GPS Horizontal Dilution\n",
      "GPS Satellite Bitmap\n",
      "GPS Satellite Count\n",
      "Underwater Percentage\n",
      "Dive Count\n",
      "Average Dive Duration\n",
      "Dive Duration Standard Deviation\n",
      "Maximum Dive Duration\n",
      "Maximum Dive Depth\n",
      "Duration Limit 1 Dive Count\n",
      "Duration Limit 2 Dive Count\n",
      "Duration Limit 3 Dive Count\n",
      "Duration Limit 4 Dive Count\n",
      "Duration Limit 5 Dive Count\n",
      "Duration Limit 6 Dive Count\n",
      "Layer 1 Percentage\n",
      "Layer 2 Percentage\n",
      "Layer 3 Percentage\n",
      "Layer 4 Percentage\n",
      "Layer 5 Percentage\n",
      "Layer 6 Percentage\n",
      "Layer 7 Percentage\n",
      "Layer 8 Percentage\n",
      "Layer 9 Percentage\n",
      "Layer 10 Percentage\n",
      "Layer 1 Dive Count\n",
      "Layer 2 Dive Count\n",
      "Layer 3 Dive Count\n",
      "Layer 4 Dive Count\n",
      "Layer 5 Dive Count\n",
      "Layer 6 Dive Count\n",
      "Layer 7 Dive Count\n",
      "Layer 8 Dive Count\n",
      "Layer 9 Dive Count\n",
      "Layer 10 Dive Count\n",
      "Temperature\n",
      "Satellite Uplink\n",
      "Receive Time\n",
      "Repetition Count\n",
      "Low Voltage\n",
      "Mortality\n",
      "Saltwater Failsafe\n",
      "Iridium Command\n",
      "Schedule Set\n",
      "Diagnostic Dive Data\n",
      "Predeployment Data\n",
      "Error\n",
      "The dataframe contains all the GPS columns\n",
      "-----DF with NaN values ---------\n",
      "         Acquisition Time Acquisition Start Time         GPS Fix Time  \\\n",
      "0     2019.07.15 14:15:00    2019.07.15 14:15:00                  NaN   \n",
      "1     2019.07.15 14:15:08    2019.07.15 14:15:00  2019.07.15 14:15:08   \n",
      "2     2019.07.15 14:30:00    2019.07.15 14:15:00                  NaN   \n",
      "3     2019.07.15 14:30:00    2019.07.15 14:30:00                  NaN   \n",
      "4     2019.07.15 14:30:06    2019.07.15 14:30:00  2019.07.15 14:30:06   \n",
      "...                   ...                    ...                  ...   \n",
      "5666  2021.02.11 04:00:00    2021.02.11 02:00:00                  NaN   \n",
      "5667  2021.02.11 05:50:10    2021.02.11 05:00:00  2021.02.11 05:50:10   \n",
      "5668  2021.02.11 06:00:00    2021.02.11 04:00:00                  NaN   \n",
      "5669  2021.02.11 06:41:28    2021.02.11 06:00:00  2021.02.11 06:41:28   \n",
      "5670  2021.02.11 10:40:30    2021.02.11 10:40:30                  NaN   \n",
      "\n",
      "     GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0                NaN           NaN            NaN  \n",
      "1       Resolved QFP     33.384380    -111.811327  \n",
      "2                NaN           NaN            NaN  \n",
      "3                NaN           NaN            NaN  \n",
      "4       Resolved QFP     33.384410    -111.811311  \n",
      "...              ...           ...            ...  \n",
      "5666             NaN           NaN            NaN  \n",
      "5667    Resolved QFP     37.752154      17.380009  \n",
      "5668             NaN           NaN            NaN  \n",
      "5669    Resolved QFP     37.742126      17.386460  \n",
      "5670             NaN           NaN            NaN  \n",
      "\n",
      "[5671 rows x 6 columns]\n",
      "-----SAME DF without NaN values ---------\n",
      "         Acquisition Time Acquisition Start Time         GPS Fix Time  \\\n",
      "0     2019.07.15 14:15:08    2019.07.15 14:15:00  2019.07.15 14:15:08   \n",
      "1     2019.07.15 14:30:06    2019.07.15 14:30:00  2019.07.15 14:30:06   \n",
      "2     2019.07.15 14:45:11    2019.07.15 14:45:00  2019.07.15 14:45:11   \n",
      "3     2019.07.15 15:00:07    2019.07.15 15:00:00  2019.07.15 15:00:07   \n",
      "4     2019.07.15 15:15:08    2019.07.15 15:15:00  2019.07.15 15:15:08   \n",
      "...                   ...                    ...                  ...   \n",
      "2575  2021.02.10 22:28:03    2021.02.10 22:00:00  2021.02.10 22:28:03   \n",
      "2576  2021.02.11 02:57:25    2021.02.11 02:00:00  2021.02.11 02:57:25   \n",
      "2577  2021.02.11 03:00:07    2021.02.11 03:00:00  2021.02.11 03:00:07   \n",
      "2578  2021.02.11 05:50:10    2021.02.11 05:00:00  2021.02.11 05:50:10   \n",
      "2579  2021.02.11 06:41:28    2021.02.11 06:00:00  2021.02.11 06:41:28   \n",
      "\n",
      "     GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0       Resolved QFP     33.384380    -111.811327  \n",
      "1       Resolved QFP     33.384410    -111.811311  \n",
      "2       Resolved QFP     33.384463    -111.811327  \n",
      "3       Resolved QFP     33.384328    -111.811264  \n",
      "4       Resolved QFP     33.384443    -111.811241  \n",
      "...              ...           ...            ...  \n",
      "2575    Resolved QFP     37.799874      17.300539  \n",
      "2576    Resolved QFP     37.781820      17.352911  \n",
      "2577    Resolved QFP     37.781188      17.353534  \n",
      "2578    Resolved QFP     37.752154      17.380009  \n",
      "2579    Resolved QFP     37.742126      17.386460  \n",
      "\n",
      "[2580 rows x 6 columns]\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                      1  2019.07.15 14:15:08    2019.07.15 14:15:00   \n",
      "1                      2  2019.07.15 14:30:06    2019.07.15 14:30:00   \n",
      "2                      3  2019.07.15 14:45:11    2019.07.15 14:45:00   \n",
      "3                      4  2019.07.15 15:00:07    2019.07.15 15:00:00   \n",
      "4                      5  2019.07.15 15:15:08    2019.07.15 15:15:00   \n",
      "...                  ...                  ...                    ...   \n",
      "2575                2576  2021.02.10 22:28:03    2021.02.10 22:00:00   \n",
      "2576                2577  2021.02.11 02:57:25    2021.02.11 02:00:00   \n",
      "2577                2578  2021.02.11 03:00:07    2021.02.11 03:00:00   \n",
      "2578                2579  2021.02.11 05:50:10    2021.02.11 05:00:00   \n",
      "2579                2580  2021.02.11 06:41:28    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0     2019.07.15 14:15:08    Resolved QFP     33.384380    -111.811327  \n",
      "1     2019.07.15 14:30:06    Resolved QFP     33.384410    -111.811311  \n",
      "2     2019.07.15 14:45:11    Resolved QFP     33.384463    -111.811327  \n",
      "3     2019.07.15 15:00:07    Resolved QFP     33.384328    -111.811264  \n",
      "4     2019.07.15 15:15:08    Resolved QFP     33.384443    -111.811241  \n",
      "...                   ...             ...           ...            ...  \n",
      "2575  2021.02.10 22:28:03    Resolved QFP     37.799874      17.300539  \n",
      "2576  2021.02.11 02:57:25    Resolved QFP     37.781820      17.352911  \n",
      "2577  2021.02.11 03:00:07    Resolved QFP     37.781188      17.353534  \n",
      "2578  2021.02.11 05:50:10    Resolved QFP     37.752154      17.380009  \n",
      "2579  2021.02.11 06:41:28    Resolved QFP     37.742126      17.386460  \n",
      "\n",
      "[2580 rows x 7 columns]\n",
      " End of all GPS Df ^\n",
      "--------------\n",
      "turtlesData[0].allGpsDf\n",
      "710333a\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                      1  2019.07.15 14:15:08    2019.07.15 14:15:00   \n",
      "1                      2  2019.07.15 14:30:10    2019.07.15 14:30:00   \n",
      "2                      3  2019.07.15 14:45:08    2019.07.15 14:45:00   \n",
      "3                      4  2019.07.15 15:00:10    2019.07.15 15:00:00   \n",
      "4                      5  2019.07.15 15:15:07    2019.07.15 15:15:00   \n",
      "...                  ...                  ...                    ...   \n",
      "4647                4648  2021.02.10 19:28:58    2021.02.10 19:00:00   \n",
      "4648                4649  2021.02.10 22:42:32    2021.02.10 22:00:00   \n",
      "4649                4650  2021.02.11 02:28:20    2021.02.11 02:00:00   \n",
      "4650                4651  2021.02.11 05:55:38    2021.02.11 05:00:00   \n",
      "4651                4652  2021.02.11 06:00:10    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time           GPS Fix Attempt  GPS Latitude  \\\n",
      "0     2019.07.15 14:15:08              Resolved QFP     33.384364   \n",
      "1     2019.07.15 14:30:10              Resolved QFP     33.384385   \n",
      "2     2019.07.15 14:45:08              Resolved QFP     33.384473   \n",
      "3     2019.07.15 15:00:10              Resolved QFP     33.384442   \n",
      "4     2019.07.15 15:15:07  Resolved QFP (Uncertain)     33.384412   \n",
      "...                   ...                       ...           ...   \n",
      "4647  2021.02.10 19:28:58              Resolved QFP     38.754772   \n",
      "4648  2021.02.10 22:42:32              Resolved QFP     38.741873   \n",
      "4649  2021.02.11 02:28:20              Resolved QFP     38.727643   \n",
      "4650  2021.02.11 05:55:38              Resolved QFP     38.720644   \n",
      "4651  2021.02.11 06:00:10              Resolved QFP     38.720648   \n",
      "\n",
      "      GPS Longitude  \n",
      "0       -111.811310  \n",
      "1       -111.811292  \n",
      "2       -111.811319  \n",
      "3       -111.811340  \n",
      "4       -111.811369  \n",
      "...             ...  \n",
      "4647      11.809630  \n",
      "4648      11.821516  \n",
      "4649      11.821051  \n",
      "4650      11.825379  \n",
      "4651      11.825217  \n",
      "\n",
      "[4652 rows x 7 columns]\n",
      "turtlesData[0].allGpsDf\n",
      "710348a\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                      1  2019.07.15 14:15:08    2019.07.15 14:15:00   \n",
      "1                      2  2019.07.15 14:30:06    2019.07.15 14:30:00   \n",
      "2                      3  2019.07.15 14:45:11    2019.07.15 14:45:00   \n",
      "3                      4  2019.07.15 15:00:07    2019.07.15 15:00:00   \n",
      "4                      5  2019.07.15 15:15:08    2019.07.15 15:15:00   \n",
      "...                  ...                  ...                    ...   \n",
      "2575                2576  2021.02.10 22:28:03    2021.02.10 22:00:00   \n",
      "2576                2577  2021.02.11 02:57:25    2021.02.11 02:00:00   \n",
      "2577                2578  2021.02.11 03:00:07    2021.02.11 03:00:00   \n",
      "2578                2579  2021.02.11 05:50:10    2021.02.11 05:00:00   \n",
      "2579                2580  2021.02.11 06:41:28    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0     2019.07.15 14:15:08    Resolved QFP     33.384380    -111.811327  \n",
      "1     2019.07.15 14:30:06    Resolved QFP     33.384410    -111.811311  \n",
      "2     2019.07.15 14:45:11    Resolved QFP     33.384463    -111.811327  \n",
      "3     2019.07.15 15:00:07    Resolved QFP     33.384328    -111.811264  \n",
      "4     2019.07.15 15:15:08    Resolved QFP     33.384443    -111.811241  \n",
      "...                   ...             ...           ...            ...  \n",
      "2575  2021.02.10 22:28:03    Resolved QFP     37.799874      17.300539  \n",
      "2576  2021.02.11 02:57:25    Resolved QFP     37.781820      17.352911  \n",
      "2577  2021.02.11 03:00:07    Resolved QFP     37.781188      17.353534  \n",
      "2578  2021.02.11 05:50:10    Resolved QFP     37.752154      17.380009  \n",
      "2579  2021.02.11 06:41:28    Resolved QFP     37.742126      17.386460  \n",
      "\n",
      "[2580 rows x 7 columns]\n",
      "The Last Entry in the Dataframe for 710333a is from: \n",
      "2021_Feb\n",
      "The Name of the allGpsDf CSV for the turtleData 710333a is: \n",
      "allGpsDf_Tag_710333a_2021_Feb.csv\n",
      "--------------\n",
      "The Last Entry in the Dataframe for 710348a is from: \n",
      "2021_Feb\n",
      "The Name of the allGpsDf CSV for the turtleData 710348a is: \n",
      "allGpsDf_Tag_710348a_2021_Feb.csv\n",
      "--------------\n",
      "['allCleanedGpsDf_Tag_710333a_2021_Feb.csv', 'allCleanedGpsDf_Tag_710348a_2021_Feb.csv', 'allGpsDf_Tag_710333a_2021_Feb.csv', 'allGpsDf_Tag_710348a_2021_Feb.csv']\n",
      "The CSV allGpsDf_Tag_710333a_2021_Feb.csv has already been saved in the results folder\n",
      "The CSV allGpsDf_Tag_710348a_2021_Feb.csv has already been saved in the results folder\n",
      "Before cleaning, the AllGpsDf called: allGpsDf_Tag_710333a_2021_Feb.csv, contained 4652 rows\n",
      "Removing 2019 data from the allGpsDf_Tag_710333a_2021_Feb.csv\n",
      "After removing 2019 data, the AllGpsDf called: allGpsDf_Tag_710333a_2021_Feb.csv, contained 4641 rows\n",
      "--------------\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                     12  2020.06.27 08:03:28    2020.06.27 08:02:40   \n",
      "1                     13  2020.06.27 15:39:07    2020.06.27 15:35:59   \n",
      "2                     14  2020.06.29 09:24:06    2020.06.29 09:22:54   \n",
      "3                     15  2020.06.29 10:00:07    2020.06.29 10:00:00   \n",
      "4                     16  2020.06.29 10:30:07    2020.06.29 10:30:00   \n",
      "...                  ...                  ...                    ...   \n",
      "4636                4648  2021.02.10 19:28:58    2021.02.10 19:00:00   \n",
      "4637                4649  2021.02.10 22:42:32    2021.02.10 22:00:00   \n",
      "4638                4650  2021.02.11 02:28:20    2021.02.11 02:00:00   \n",
      "4639                4651  2021.02.11 05:55:38    2021.02.11 05:00:00   \n",
      "4640                4652  2021.02.11 06:00:10    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0     2020.06.27 08:03:28       Succeeded     37.995522      16.123309  \n",
      "1     2020.06.27 15:39:07       Succeeded     37.925063      16.059105  \n",
      "2     2020.06.29 09:24:06       Succeeded     37.924899      16.058567  \n",
      "3     2020.06.29 10:00:07    Resolved QFP     37.924433      16.058961  \n",
      "4     2020.06.29 10:30:07    Resolved QFP     37.924525      16.058992  \n",
      "...                   ...             ...           ...            ...  \n",
      "4636  2021.02.10 19:28:58    Resolved QFP     38.754772      11.809630  \n",
      "4637  2021.02.10 22:42:32    Resolved QFP     38.741873      11.821516  \n",
      "4638  2021.02.11 02:28:20    Resolved QFP     38.727643      11.821051  \n",
      "4639  2021.02.11 05:55:38    Resolved QFP     38.720644      11.825379  \n",
      "4640  2021.02.11 06:00:10    Resolved QFP     38.720648      11.825217  \n",
      "\n",
      "[3329 rows x 7 columns]\n",
      "13    2020.07.09 23:00:09\n",
      "15    2020.07.09 23:30:12\n",
      "17    2020.07.10 00:30:08\n",
      "19    2020.07.10 01:00:08\n",
      "21    2020.07.10 01:30:07\n",
      "23    2020.07.10 02:00:08\n",
      "Name: Acquisition Time, dtype: object\n",
      "Without duplicated rows, the dataframe has now 3329 rows\n",
      "The df without duplicated rows is the duplicateRowsTemporaryDf\n",
      "--------------\n",
      "Saving this temporary df into the allCleanedGpsDf...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                     12  2020.06.27 08:03:28    2020.06.27 08:02:40   \n",
      "1                     13  2020.06.27 15:39:07    2020.06.27 15:35:59   \n",
      "2                     14  2020.06.29 09:24:06    2020.06.29 09:22:54   \n",
      "3                     15  2020.06.29 10:00:07    2020.06.29 10:00:00   \n",
      "4                     16  2020.06.29 10:30:07    2020.06.29 10:30:00   \n",
      "...                  ...                  ...                    ...   \n",
      "3324                4648  2021.02.10 19:28:58    2021.02.10 19:00:00   \n",
      "3325                4649  2021.02.10 22:42:32    2021.02.10 22:00:00   \n",
      "3326                4650  2021.02.11 02:28:20    2021.02.11 02:00:00   \n",
      "3327                4651  2021.02.11 05:55:38    2021.02.11 05:00:00   \n",
      "3328                4652  2021.02.11 06:00:10    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0     2020.06.27 08:03:28       Succeeded     37.995522      16.123309  \n",
      "1     2020.06.27 15:39:07       Succeeded     37.925063      16.059105  \n",
      "2     2020.06.29 09:24:06       Succeeded     37.924899      16.058567  \n",
      "3     2020.06.29 10:00:07    Resolved QFP     37.924433      16.058961  \n",
      "4     2020.06.29 10:30:07    Resolved QFP     37.924525      16.058992  \n",
      "...                   ...             ...           ...            ...  \n",
      "3324  2021.02.10 19:28:58    Resolved QFP     38.754772      11.809630  \n",
      "3325  2021.02.10 22:42:32    Resolved QFP     38.741873      11.821516  \n",
      "3326  2021.02.11 02:28:20    Resolved QFP     38.727643      11.821051  \n",
      "3327  2021.02.11 05:55:38    Resolved QFP     38.720644      11.825379  \n",
      "3328  2021.02.11 06:00:10    Resolved QFP     38.720648      11.825217  \n",
      "\n",
      "[3329 rows x 7 columns]\n",
      "13    2020.07.09 23:00:09\n",
      "14    2020.07.09 23:30:12\n",
      "15    2020.07.10 00:30:08\n",
      "16    2020.07.10 01:00:08\n",
      "17    2020.07.10 01:30:07\n",
      "18    2020.07.10 02:00:08\n",
      "Name: Acquisition Time, dtype: object\n",
      "The df without duplicated rows is now the self.allCleanedGpsDf\n",
      "------- END -------\n",
      "Before cleaning, the AllGpsDf called: allGpsDf_Tag_710348a_2021_Feb.csv, contained 2580 rows\n",
      "Removing 2019 data from the allGpsDf_Tag_710348a_2021_Feb.csv\n",
      "After removing 2019 data, the AllGpsDf called: allGpsDf_Tag_710348a_2021_Feb.csv, contained 2569 rows\n",
      "--------------\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                     12  2020.08.03 20:38:24    2020.08.03 20:37:17   \n",
      "1                     13  2020.08.04 12:49:31    2020.08.04 12:45:00   \n",
      "2                     14  2020.08.04 12:49:31    2020.08.04 12:48:35   \n",
      "3                     15  2020.08.05 12:29:21    2020.08.05 12:15:00   \n",
      "4                     16  2020.08.05 12:29:21    2020.08.05 12:28:28   \n",
      "...                  ...                  ...                    ...   \n",
      "2564                2576  2021.02.10 22:28:03    2021.02.10 22:00:00   \n",
      "2565                2577  2021.02.11 02:57:25    2021.02.11 02:00:00   \n",
      "2566                2578  2021.02.11 03:00:07    2021.02.11 03:00:00   \n",
      "2567                2579  2021.02.11 05:50:10    2021.02.11 05:00:00   \n",
      "2568                2580  2021.02.11 06:41:28    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0     2020.08.03 20:38:24       Succeeded     37.918752      15.990526  \n",
      "1     2020.08.04 12:49:31       Succeeded     37.918734      15.990457  \n",
      "2     2020.08.04 12:49:31       Succeeded     37.918734      15.990457  \n",
      "3     2020.08.05 12:29:21       Succeeded     37.918737      15.990459  \n",
      "4     2020.08.05 12:29:21       Succeeded     37.918737      15.990459  \n",
      "...                   ...             ...           ...            ...  \n",
      "2564  2021.02.10 22:28:03    Resolved QFP     37.799874      17.300539  \n",
      "2565  2021.02.11 02:57:25    Resolved QFP     37.781820      17.352911  \n",
      "2566  2021.02.11 03:00:07    Resolved QFP     37.781188      17.353534  \n",
      "2567  2021.02.11 05:50:10    Resolved QFP     37.752154      17.380009  \n",
      "2568  2021.02.11 06:41:28    Resolved QFP     37.742126      17.386460  \n",
      "\n",
      "[2569 rows x 7 columns]\n",
      "13    2020.08.12 07:58:14\n",
      "14    2020.08.12 08:00:06\n",
      "15    2020.08.12 08:34:30\n",
      "16    2020.08.12 09:16:38\n",
      "17    2020.08.12 09:54:19\n",
      "18    2020.08.12 10:00:06\n",
      "Name: Acquisition Time, dtype: object\n",
      "Without duplicated rows, the dataframe has now 2569 rows\n",
      "The df without duplicated rows is the duplicateRowsTemporaryDf\n",
      "--------------\n",
      "Saving this temporary df into the allCleanedGpsDf...\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                     12  2020.08.03 20:38:24    2020.08.03 20:37:17   \n",
      "1                     13  2020.08.04 12:49:31    2020.08.04 12:45:00   \n",
      "2                     14  2020.08.04 12:49:31    2020.08.04 12:48:35   \n",
      "3                     15  2020.08.05 12:29:21    2020.08.05 12:15:00   \n",
      "4                     16  2020.08.05 12:29:21    2020.08.05 12:28:28   \n",
      "...                  ...                  ...                    ...   \n",
      "2564                2576  2021.02.10 22:28:03    2021.02.10 22:00:00   \n",
      "2565                2577  2021.02.11 02:57:25    2021.02.11 02:00:00   \n",
      "2566                2578  2021.02.11 03:00:07    2021.02.11 03:00:00   \n",
      "2567                2579  2021.02.11 05:50:10    2021.02.11 05:00:00   \n",
      "2568                2580  2021.02.11 06:41:28    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0     2020.08.03 20:38:24       Succeeded     37.918752      15.990526  \n",
      "1     2020.08.04 12:49:31       Succeeded     37.918734      15.990457  \n",
      "2     2020.08.04 12:49:31       Succeeded     37.918734      15.990457  \n",
      "3     2020.08.05 12:29:21       Succeeded     37.918737      15.990459  \n",
      "4     2020.08.05 12:29:21       Succeeded     37.918737      15.990459  \n",
      "...                   ...             ...           ...            ...  \n",
      "2564  2021.02.10 22:28:03    Resolved QFP     37.799874      17.300539  \n",
      "2565  2021.02.11 02:57:25    Resolved QFP     37.781820      17.352911  \n",
      "2566  2021.02.11 03:00:07    Resolved QFP     37.781188      17.353534  \n",
      "2567  2021.02.11 05:50:10    Resolved QFP     37.752154      17.380009  \n",
      "2568  2021.02.11 06:41:28    Resolved QFP     37.742126      17.386460  \n",
      "\n",
      "[2569 rows x 7 columns]\n",
      "13    2020.08.12 07:58:14\n",
      "14    2020.08.12 08:00:06\n",
      "15    2020.08.12 08:34:30\n",
      "16    2020.08.12 09:16:38\n",
      "17    2020.08.12 09:54:19\n",
      "18    2020.08.12 10:00:06\n",
      "Name: Acquisition Time, dtype: object\n",
      "The df without duplicated rows is now the self.allCleanedGpsDf\n",
      "------- END -------\n",
      "The Last Entry in the Dataframe for 710333a is from: \n",
      "2021_Feb\n",
      "The Name of the allCleanedGpsDf CSV for the turtleData 710333a is: \n",
      "allCleanedGpsDf_Tag_710333a_2021_Feb.csv\n",
      "--------------\n",
      "The Last Entry in the Dataframe for 710348a is from: \n",
      "2021_Feb\n",
      "The Name of the allCleanedGpsDf CSV for the turtleData 710348a is: \n",
      "allCleanedGpsDf_Tag_710348a_2021_Feb.csv\n",
      "--------------\n",
      "['allCleanedGpsDf_Tag_710333a_2021_Feb.csv', 'allCleanedGpsDf_Tag_710348a_2021_Feb.csv', 'allGpsDf_Tag_710333a_2021_Feb.csv', 'allGpsDf_Tag_710348a_2021_Feb.csv']\n",
      "The CSV allCleanedGpsDf_Tag_710333a_2021_Feb.csv has already been saved in the results folder\n",
      "--------------\n",
      "The CSV allCleanedGpsDf_Tag_710348a_2021_Feb.csv has already been saved in the results folder\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# Check if some excel file has not been converted into csv yet\n",
    "check_for_excel_files()\n",
    "turtlesData = getTurtlesData()\n",
    "\n",
    "# see instances for Obj turtleData created and its dfs\n",
    "checkInstancesAndItsDfs(turtlesData)\n",
    "#turtlesData[0].df\n",
    "#turtlesData[1].df\n",
    "\n",
    "# build dfs of all gps\n",
    "getAllGpsDataframes(turtlesData)\n",
    "\n",
    "# see dfs of all gps\n",
    "displayAllGpsDf(turtlesData)\n",
    "# or\n",
    "#turtlesData[0].allGpsDf\n",
    "#turtlesData[1].allGpsDf\n",
    "\n",
    "# get name for each ALL GPS DF turtleData\n",
    "createAllGpsDfCsvNameForEachInstance(turtlesData)\n",
    "\n",
    "# SAVE THE ALL GPS DATAFRAME in the Results Folder\n",
    "checkIfAllGpsDfHasBeenSaved(turtlesData)\n",
    "\n",
    "# now we need to look at the all gps df and delete the duplicates rows, before calculating the errors by speed\n",
    "# deleting duplicate rows and 2019 date\n",
    "getAllCleanedGpsDataframes(turtlesData)\n",
    "\n",
    "# get name for each ALL CLEANED GPS DF turtleData\n",
    "createAllCleanedGpsDfCsvNameForEachInstance(turtlesData)\n",
    "\n",
    "# SAVE THE ALL CLEANED GPS DATAFRAME in the Results Folder\n",
    "checkIfAllCleanedGpsDfHasBeenSaved(turtlesData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juliana\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:109: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pointsToRemove List: \n",
      "101\n",
      "remSpeeds List: [array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([1.18930457]), array([1.13096368]), array([inf]), array([inf]), array([inf]), array([inf]), array([42.3998984]), array([inf]), array([inf]), array([988.21761595]), array([inf]), array([282.15571977]), array([4.03555561]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([171.75018604]), array([59.95711877]), array([inf]), array([10.36168531]), array([inf]), array([inf]), array([15.99201645]), array([inf]), array([inf]), array([inf]), array([inf]), array([inf]), array([234.99330641]), array([inf]), array([inf]), array([inf]), array([inf]), array([38.33812958]), array([218.95642372]), array([329.99169271]), array([1.40032288]), array([1.17689876]), array([151.11015997]), array([80.5629416]), array([21.39557692]), array([1.59042348]), array([27.78637835]), array([1.14580626]), array([41.69783778]), array([3.86245364]), array([1.22538072]), array([6.8776525]), array([23.15440736]), array([5.07402054]), array([9.28365653]), array([1.34491866]), array([29.8952071]), array([1.12774978]), array([111.65462206])]\n",
      "pointsToRemove List: ['2020.07.10 06:08:16', '2020.07.11 01:47:22', '2020.07.13 01:32:09', '2020.07.13 02:00:09', '2020.07.13 23:00:07', '2020.07.14 01:39:08', '2020.07.14 02:00:07', '2020.07.14 08:30:15', '2020.07.17 01:43:18', '2020.07.17 02:02:50', '2020.07.18 01:17:02', '2020.07.18 01:55:10', '2020.07.19 14:00:43', '2020.07.19 18:44:25', '2020.07.20 01:56:34', '2020.07.20 13:50:16', '2020.07.20 22:30:09', '2020.07.21 01:00:06', '2020.07.21 01:30:07', '2020.07.21 15:31:17', '2020.07.22 06:01:10', '2020.07.23 01:03:14', '2020.07.23 01:30:06', '2020.07.24 01:03:35', '2020.07.24 05:53:04', '2020.07.25 00:39:12', '2020.07.25 05:04:52', '2020.07.25 13:37:21', '2020.07.26 01:11:02', '2020.07.26 04:57:31', '2020.07.26 05:30:07', '2020.07.28 17:33:12', '2020.07.28 18:11:14', '2020.07.31 07:52:09', '2020.07.31 18:00:19', '2020.08.01 08:23:48', '2020.08.02 04:34:30', '2020.08.03 01:00:09', '2020.08.05 05:00:32', '2020.08.05 07:01:05', '2020.08.05 23:42:53', '2020.08.06 08:38:31', '2020.08.06 17:36:30', '2020.08.07 10:30:10', '2020.08.07 17:19:10', '2020.08.08 00:42:04', '2020.08.08 17:17:38', '2020.08.08 19:08:48', '2020.08.10 12:40:38', '2020.08.10 16:34:22', '2020.08.10 23:30:08', '2020.08.11 00:34:53', '2020.08.11 17:00:11', '2020.08.11 23:00:38', '2020.08.12 12:33:20', '2020.08.13 04:30:07', '2020.08.13 08:00:58', '2020.08.13 23:05:39', '2020.08.14 12:04:35', '2020.08.15 12:02:22', '2020.08.16 00:00:04', '2020.08.16 16:41:43', '2020.08.23 19:36:02', '2020.08.24 06:58:17', '2020.08.24 16:02:35', '2020.08.26 01:09:49', '2020.08.28 11:00:15', '2020.08.29 04:03:55', '2020.08.30 07:10:28', '2020.08.30 17:10:38', '2020.08.31 03:18:50', '2020.08.31 21:15:23', '2020.09.05 23:09:55', '2020.09.06 15:14:09', '2020.09.11 22:58:22', '2020.09.12 10:00:07', '2020.09.12 14:21:32', '2020.09.13 18:18:18', '2020.09.17 21:11:41', '2020.09.19 15:40:49', '2020.10.10 03:25:59', '2020.10.20 23:10:33', '2020.10.25 10:00:06', '2020.11.02 05:00:21', '2020.11.09 12:01:17', '2020.11.29 12:40:16', '2020.12.18 15:00:40', '2020.12.23 23:02:39', '2020.12.25 13:45:58', '2020.12.29 09:15:12', '2021.01.02 17:11:16', '2021.01.07 14:00:02', '2021.01.10 00:00:02', '2021.01.17 16:10:06', '2021.01.21 23:00:19', '2021.01.22 23:00:06', '2021.01.23 14:00:06', '2021.01.25 07:25:21', '2021.01.27 09:49:09', '2021.01.29 05:50:59', '2021.02.10 15:59:39']\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juliana\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:109: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pointsToRemove List: \n",
      "14\n",
      "remSpeeds List: [array([32.6084126]), array([1.170557]), array([177.62047653]), array([177.47599964]), array([1.55690435]), array([192.31635835]), array([168.02518142]), array([1.17419418]), array([42.03013665]), array([5.1905697]), array([10.26749834]), array([44.55296201]), array([1.25665037]), array([21.49260763])]\n",
      "pointsToRemove List: ['2020.08.13 02:04:04', '2020.08.14 21:01:15', '2020.08.16 21:01:00', '2020.08.17 02:36:48', '2020.08.20 13:09:28', '2020.09.07 01:30:11', '2020.09.17 21:09:34', '2020.09.27 20:00:17', '2020.10.11 18:09:28', '2020.11.22 12:00:48', '2020.11.22 18:02:52', '2020.12.04 00:00:49', '2020.12.21 19:00:03', '2021.01.27 18:00:17']\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# see dfs of reliable gps (Remove GPS Errors by Angular velocity/Rotational speed)\n",
    "getReliableGpsDataframes(turtlesData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The errors is because we have still 2 data of the same time that must be removed the second one, that is that one that is giving us inf values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We need, first to remove the 2 acquisition time identicals and then do this same calculating distance and speed operation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
