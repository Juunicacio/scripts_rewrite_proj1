{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove df rows, before Turtle Tag Datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### the instances have their start date assign, see how to read it in the df and delete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#import pyproj as pj # for reliable gps\n",
    "# or from pyproj import Geod (and remove the pj when executing the functionality)\n",
    "from pyproj import Geod\n",
    "import numpy as np # for reliable gps\n",
    "from collections import Counter # for reliable gps\n",
    "import datetime as dt # for reliable gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurtleData:\n",
    "    \"\"\"Commom base class for all turtle's data \"\"\"\n",
    "    \n",
    "    C1 = 'Acquisition Time'\n",
    "    C2 ='Acquisition Start Time'\n",
    "    C3 ='Iridium CEP Radius'\n",
    "    C4 ='Iridium Latitude'\n",
    "    C5 ='Iridium Longitude'\n",
    "    C6 ='GPS Fix Time'\n",
    "    C7 ='GPS Fix Attempt'\n",
    "    C8 ='GPS Latitude'\n",
    "    C9 ='GPS Longitude'\n",
    "    C10 ='GPS UTM Zone'\n",
    "    C11 ='GPS UTM Northing'\n",
    "    C12 ='GPS UTM Easting'\n",
    "    C13 ='GPS Altitude'\n",
    "    C14 ='GPS Horizontal Error'\n",
    "    C15 ='GPS Horizontal Dilution'\n",
    "    C16 ='GPS Satellite Bitmap'\n",
    "    C17 ='GPS Satellite Count'\n",
    "    C18 ='Underwater Percentage'\n",
    "    C19 ='Dive Count'\n",
    "    C20 ='Average Dive Duration'\n",
    "    C21 ='Dive Duration Standard Deviation'\n",
    "    C22 ='Maximum Dive Duration'\n",
    "    C23 ='Maximum Dive Depth'\n",
    "    C24 ='Duration Limit 1 Dive Count'\n",
    "    C25 ='Duration Limit 2 Dive Count'\n",
    "    C26 ='Duration Limit 3 Dive Count'\n",
    "    C27 ='Duration Limit 4 Dive Count'\n",
    "    C28 ='Duration Limit 5 Dive Count'\n",
    "    C29 ='Duration Limit 6 Dive Count'\n",
    "    C30 ='Layer 1 Percentage'\n",
    "    C31 ='Layer 2 Percentage'\n",
    "    C32 ='Layer 3 Percentage'\n",
    "    C33 ='Layer 4 Percentage'\n",
    "    C34 ='Layer 5 Percentage'\n",
    "    C35 ='Layer 6 Percentage'\n",
    "    C36 ='Layer 7 Percentage'\n",
    "    C37 ='Layer 8 Percentage'\n",
    "    C38 ='Layer 9 Percentage'\n",
    "    C39 ='Layer 10 Percentage'\n",
    "    C40 ='Layer 1 Dive Count'\n",
    "    C41 ='Layer 2 Dive Count'\n",
    "    C42 ='Layer 3 Dive Count'\n",
    "    C43 ='Layer 4 Dive Count'\n",
    "    C44 ='Layer 5 Dive Count'\n",
    "    C45 ='Layer 6 Dive Count'\n",
    "    C46 ='Layer 7 Dive Count'\n",
    "    C47 ='Layer 8 Dive Count'\n",
    "    C48 ='Layer 9 Dive Count'\n",
    "    C49 ='Layer 10 Dive Count'\n",
    "    C50 ='Temperature'\n",
    "    C51 ='Satellite Uplink'\n",
    "    C52 ='Receive Time'\n",
    "    C53 ='Repetition Count'\n",
    "    C54 ='Low Voltage'\n",
    "    C55 ='Mortality'\n",
    "    C56 ='Saltwater Failsafe'\n",
    "    C57 ='Iridium Command'\n",
    "    C58 ='Schedule Set'\n",
    "    C59 ='Diagnostic Dive Data'\n",
    "    C60 ='Predeployment Data'\n",
    "    C61 ='Error'\n",
    "    col_names = list([\n",
    "        C1, C2, C3, C4, C5, C6, C7, C8, C9, C10, \n",
    "        C11, C12, C13, C14, C15, C16, C17, C18, C19, C20, \n",
    "        C21, C22, C23, C24, C25, C26, C27, C28, C29, C30, \n",
    "        C31, C32, C33, C34, C35, C36, C37, C38, C39, C40, \n",
    "        C41, C42, C43, C44, C45, C46, C47, C48, C49, C50, \n",
    "        C51, C52, C53, C54, C55, C56, C57, C58, C59, C60, \n",
    "        C61\n",
    "    ])\n",
    "    gps_col_names = list([\n",
    "        C1, C2, C6, C7, C8, C9\n",
    "    ])\n",
    "    ID_ALLGPSDF_COLUMN_NAME = \"All GPS's Track ID\"\n",
    "\n",
    "    @staticmethod\n",
    "    def basedNamesForCsv(lastEntryRowDF, selfDfNameString, selfTurtleTag):\n",
    "        for value in enumerate(lastEntryRowDF):\n",
    "            #print(value[1][0])\n",
    "            lastDate = value[1][0]\n",
    "            date = dt.datetime.strptime(lastDate, \"%Y.%m.%d\")\n",
    "            stringDate = date.strftime(\"%Y\") + \"_\" + date.strftime(\"%b\")\n",
    "            print(f\"The Last Entry in the Dataframe for {selfTurtleTag} is from: \")\n",
    "            print(stringDate)\n",
    "            # Give the CSV a Name based on this values above\n",
    "            # name = allGpsDf_tag_xxxxx_until_lastdate\n",
    "            cvsName = selfDfNameString + \"_Tag_\" + selfTurtleTag + \"_\" + stringDate +\".csv\"\n",
    "            print(f\"The Name for the {selfDfNameString} CSV for the turtleData {selfTurtleTag} is: \")\n",
    "            print(cvsName)\n",
    "            print('--------------')\n",
    "            return cvsName \n",
    "\n",
    "    @staticmethod\n",
    "    def calculateDistance(geodRef, lon1, lat1, lon2, lat2):\n",
    "        # # compute forward and back azimuths, plus distance\n",
    "        az12,az21,dist = geodRef.inv(lon1, lat1, lon2, lat2) #Take the second row and the first row on the count. it shoul give 3 values, but I only need the dist.\n",
    "        # f\"{az12:.3f} {az21:.3f} {dist:.3f}\"        \n",
    "        return dist #Put the dist inside the distances variable once empty.\n",
    "    \n",
    "    @staticmethod\n",
    "    def convertUnixTimeFromString(timeString):\n",
    "        return dt.datetime.strptime(timeString, '%Y.%m.%d %H:%M:%S').timestamp() #[i] is the position in an array\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculateSpeed(d, t1, t2):\n",
    "        speed = d / (t2 - t1)\n",
    "        return speed\n",
    "\n",
    "    def __init__(self, tag):\n",
    "        self.turtleTag = tag\n",
    "        self.tagDate = \"\"\n",
    "        self.tagTime = \"\"\n",
    "        self.tagDatetime = \"\"\n",
    "        self.df = pd.DataFrame()\n",
    "        self.allGpsDf = pd.DataFrame()\n",
    "        self.allGpsDfCsvName = \"\"\n",
    "        #self.allGpsDf2019 = pd.DataFrame()\n",
    "        self.allCleanedGpsDf = pd.DataFrame()\n",
    "        self.allCleanedGpsDfCsvName = \"\"\n",
    "        self.tempReliableGpsDfWithNoTagDate = pd.DataFrame()\n",
    "        self.tempReliableGpsDfWithNoTagDateCsvName = \"\" \n",
    "        self.reliableGpsDf = pd.DataFrame()\n",
    "        self.reliableGpsDfCsvName = \"\"\n",
    "    #def addElement(self, row, header):\n",
    "        #self.__dict__= dict(zip(header, row))\n",
    "\n",
    "    def addDataFromCsv(self, filename):\n",
    "        temporaryDf = pd.read_csv(filename, skiprows=23, names=TurtleData.col_names)\n",
    "        \n",
    "        #print(f' ITS CURRENT DF IS: {self.df}') \n",
    "        #print('--------------')\n",
    "        #print(f' ITS TEMPORARY DF IS {temporaryDf}') \n",
    "        \n",
    "        self.df = self.df.append(temporaryDf, ignore_index=True)\n",
    "        self.df.sort_values(\"Acquisition Time\", inplace = True)\n",
    "\n",
    "    def getTag(self):\n",
    "        return self.turtleTag\n",
    "\n",
    "    def getDf(self):        \n",
    "        return self.df\n",
    "    \n",
    "    def giveAllGpsDf(self):\n",
    "        # see all the columns in the df\n",
    "        #print(self.df.columns)\n",
    "        # see one column at a time        \n",
    "        self.allGpsDf = self.df.copy()\n",
    "        print(TurtleData.gps_col_names)\n",
    "        tempList = TurtleData.gps_col_names.copy()\n",
    "        for c in self.allGpsDf.columns:\n",
    "            print(c)            \n",
    "            if c not in tempList:\n",
    "                self.allGpsDf.drop(c, inplace=True, axis=1)\n",
    "            else:\n",
    "                tempList.remove(c)        \n",
    "\n",
    "        if tempList:\n",
    "            print(\"Colummn Data missing in!\")\n",
    "        else:\n",
    "            print(\"The dataframe contains all the GPS columns\")\n",
    "        \n",
    "        print('-----DF with NaN values ---------')\n",
    "        print(self.allGpsDf)       \n",
    "        \n",
    "        #### Eliminate those GPS's null (NaN) rows from the dataframe\n",
    "        self.allGpsDf.drop(self.allGpsDf[~self.allGpsDf['GPS Latitude'].notna()].index, inplace=True)\n",
    "        self.allGpsDf.reset_index(drop=True, inplace=True) # reset index\n",
    "\n",
    "        print('-----SAME DF without NaN values ---------')\n",
    "        print(self.allGpsDf)\n",
    "\n",
    "        ####Create a column for id GPS points to the left\n",
    "        trackId = self.allGpsDf.index + 1\n",
    "        self.allGpsDf.insert(0, TurtleData.ID_ALLGPSDF_COLUMN_NAME, trackId)\n",
    "        \n",
    "        print(self.allGpsDf)        \n",
    "        print(' End of all GPS Df ^')\n",
    "        print('--------------')    \n",
    "    \n",
    "    def generateAllGpsDfCsvName(self):\n",
    "        # Last entry:\n",
    "        lastEntry = self.allGpsDf['Acquisition Time'].tail(1)\n",
    "        #print(lastEntry)\n",
    "        # separing date from time in that column\n",
    "        lastEntry = pd.Series([[y for y in x.split()] for x in lastEntry])\n",
    "        #print(lastEntry)\n",
    "        # assign the Name in the Class Variable\n",
    "        self.allGpsDfCsvName = TurtleData.basedNamesForCsv(lastEntry, \"allGpsDf\", self.turtleTag)        \n",
    "    \n",
    "    def saveAllGpsDfData(self, pathToFilePlusCsvName):\n",
    "        self.allGpsDf.to_csv(pathToFilePlusCsvName, index=False)\n",
    "    \n",
    "    def assignTagTurtleDayDatetime(self, TagDate, TagTime):\n",
    "        '''\n",
    "        the Date and Time of the turtle's Tag Day\n",
    "        '''\n",
    "        self.tagDate = TagDate\n",
    "        self.tagTime = TagTime\n",
    "        self.tagDatetime = self.tagDate + \" \" + self.tagTime\n",
    "    \n",
    "    def giveAllCleanedGpsDf(self):\n",
    "        # without 2019 date and without duplicate rows\n",
    "        precedentYearRowsTemporaryDf = self.allGpsDf.copy()\n",
    "        print(f\"Before cleaning, the AllGpsDf called: {self.allGpsDfCsvName}, contained {len(precedentYearRowsTemporaryDf.index)} rows\")\n",
    "        \n",
    "        ##### ---------- This Part is not needed ---------- #####\n",
    "        # Remove 2019 data from 'Acquisition Time column:\n",
    "        dateColumn = precedentYearRowsTemporaryDf['Acquisition Time']\n",
    "        #print(dateColumn)\n",
    "        # separing date from time in that column\n",
    "        dateColumn = pd.Series([[y for y in x.split()] for x in dateColumn])\n",
    "        #print(dateColumn)\n",
    "        all2019DateData = []\n",
    "        allOtherDateData = []        \n",
    "        for value in enumerate(dateColumn):\n",
    "            #print(value[1][0])\n",
    "            # assign the date rows to the variable dateData\n",
    "            dateData = value[1][0]\n",
    "            # removing 2019 from the list\n",
    "            if dateData.startswith('2019'):\n",
    "                #print(f\"dateData that starts with 2019 = {dateData}\")\n",
    "                # append the 2019 data to the list\n",
    "                all2019DateData.append(dateData)\n",
    "            else:\n",
    "                #print(f\"dateData that do not starts with 2019 = {dateData}\")\n",
    "                # append any other data to this list\n",
    "                allOtherDateData.append(dateData)\n",
    "        #print(f\" 2019 list = {all2019DateData}\")\n",
    "        #print(f\" 2020/2021 list = {allOtherDateData}\")\n",
    "        ##### ---------- END OF the Part not needed ---------- #####\n",
    "\n",
    "        #### Eliminate those 2019 data rows from the dataframe\n",
    "        ### example: df = df[~df['c'].astype(str).str.startswith('1')]\n",
    "        print(f\"Removing 2019 data from the {self.allGpsDfCsvName}\")\n",
    "        precedentYearRowsTemporaryDf.drop(precedentYearRowsTemporaryDf[precedentYearRowsTemporaryDf['Acquisition Time'].astype(str).str.startswith('2019')].index, inplace=True)\n",
    "        precedentYearRowsTemporaryDf.reset_index(drop=True, inplace=True) # reset index\n",
    "        #print(precedentYearRowsTemporaryDf)\n",
    "        print(f\"After removing 2019 data, the AllGpsDf called: {self.allGpsDfCsvName}, contained {len(precedentYearRowsTemporaryDf.index)} rows\")\n",
    "        \n",
    "        ### Eliminate duplicate rows\n",
    "        # Select duplicate rows except first occurrence based on all columns\n",
    "        ## example of Selection by Position, to see example duplicated rows ----------------------------------\n",
    "        ## df.iloc[row_indexer,column_indexer]\n",
    "        print('--------------')\n",
    "        duplicateRowsTemporaryDf = precedentYearRowsTemporaryDf\n",
    "        duplicateRowsTemporaryDf = duplicateRowsTemporaryDf.drop_duplicates(\n",
    "            [\n",
    "                'Acquisition Time','Acquisition Start Time', 'GPS Fix Time', 'GPS Fix Attempt', 'GPS Latitude', 'GPS Longitude'\n",
    "            ], keep='first'\n",
    "        )\n",
    "        print(duplicateRowsTemporaryDf)\n",
    "        print(duplicateRowsTemporaryDf.iloc[13:19,1])\n",
    "        print(f\"Without duplicated rows, the dataframe has now {len(duplicateRowsTemporaryDf.index)} rows\")\n",
    "        # Drop same aquisition time that is giving us error in the calculation of distances and speeds\n",
    "        duplicateRowsTemporaryDf = duplicateRowsTemporaryDf.drop_duplicates(['Acquisition Time'], keep='first')\n",
    "        print(duplicateRowsTemporaryDf)\n",
    "        print(duplicateRowsTemporaryDf.iloc[13:19,1])\n",
    "        print(\"The lines where we had the same acquisition time\")\n",
    "        print(duplicateRowsTemporaryDf.iloc[23:29,1])\n",
    "        print(f\"Without duplicated acquisition times, the dataframe has now {len(duplicateRowsTemporaryDf.index)} rows\")\n",
    "        print(\"The df without duplicated rows and Without duplicated acquisition times is the duplicateRowsTemporaryDf\")\n",
    "        print('--------------')\n",
    "\n",
    "        #### Eliminate test date before its Turtle tag day Datetime\n",
    "        print(\"Excluding date BEFORE TAG DAY DATETIME\")\n",
    "        testDateRowsTemporaryDf = duplicateRowsTemporaryDf\n",
    "        #print(testDateRowsTemporaryDf[testDateRowsTemporaryDf['Acquisition Time'].astype(str).str.startswith(self.tagDatetime)])\n",
    "        ## listing days before\n",
    "        print(testDateRowsTemporaryDf[testDateRowsTemporaryDf['Acquisition Time'] < self.tagDatetime])\n",
    "        ## dropping them\n",
    "        testDateRowsTemporaryDf.drop(testDateRowsTemporaryDf[testDateRowsTemporaryDf['Acquisition Time'] < self.tagDatetime].index, inplace=True)\n",
    "        print(\"TEST -------------- TEST ------- TEST\")\n",
    "        print(self.tagDatetime)\n",
    "        print(testDateRowsTemporaryDf)\n",
    "\n",
    "        print(f\"Without days before turtle tag day, the dataframe has now {len(testDateRowsTemporaryDf.index)} rows\")\n",
    "        print(\"The df without duplicated rows, without duplicated acquisition times and without days before turtle tag is the testDateRowsTemporaryDf\")\n",
    "        print('--------------')\n",
    "\n",
    "        print(\"ALL THE DF THAT IS GONNA BE SAVE IN ALL CLEANED GPS DATAFRAME\")\n",
    "        print(\"Saving this temporary df into the allCleanedGpsDf...\")\n",
    "        self.allCleanedGpsDf = self.allCleanedGpsDf.append(testDateRowsTemporaryDf, ignore_index=True)\n",
    "        print(self.allCleanedGpsDf)\n",
    "        print(self.allCleanedGpsDf.iloc[13:19,1])\n",
    "        print(\"The df without duplicated rows is now the self.allCleanedGpsDf\")\n",
    "        print('------- END -------')\n",
    "\n",
    "    def generateAllCleanedGpsDfCsvName(self):\n",
    "        # Last entry:\n",
    "        lastEntry = self.allCleanedGpsDf['Acquisition Time'].tail(1)\n",
    "        #print(lastEntry)\n",
    "        # separing date from time in that column\n",
    "        lastEntry = pd.Series([[y for y in x.split()] for x in lastEntry])\n",
    "        #print(lastEntry)\n",
    "        # assign the Name in the Class Variable\n",
    "        self.allCleanedGpsDfCsvName = TurtleData.basedNamesForCsv(lastEntry, \"allCleanedGpsDf\", self.turtleTag)\n",
    "    \n",
    "    def saveAllCleanedGpsDfData(self, pathToFilePlusCsvName):\n",
    "        self.allCleanedGpsDf.to_csv(pathToFilePlusCsvName, index=False)\n",
    "\n",
    "    def giveTempReliableGpsDfWithNoTagDate(self):\n",
    "        '''\n",
    "        Remove GPS Errors by Angular velocity/Rotational speed \n",
    "        (degree per second)\n",
    "        Geod Object for Calculations is used as objec to calculate \n",
    "        distances between points expressed in lat/lon (in degree)\n",
    "        Choosing a Reference Ellipsoid - distance in degree more \n",
    "        accurate than a spherical method\n",
    "        '''\n",
    "        removingGpsErrorsTemporaryDf = self.allCleanedGpsDf.copy()\n",
    "        #print(gpsErrorsTemporaryDf)\n",
    "        wgs84_geod = Geod(ellps='WGS84')\n",
    "        ## Converting data to a NumPy array.        \n",
    "        latitudes = removingGpsErrorsTemporaryDf[['GPS Latitude']].to_numpy() \n",
    "        longitudes = removingGpsErrorsTemporaryDf[['GPS Longitude']].to_numpy()\n",
    "        acquisitionTimes = removingGpsErrorsTemporaryDf[['Acquisition Time']].to_numpy()\n",
    "        \n",
    "        #latitudes = removingGpsErrorsTemporaryDf['GPS Latitude'].reset_index().values\n",
    "        #longitudes = removingGpsErrorsTemporaryDf['GPS Longitude'].reset_index().values\n",
    "        ##acquisitionTimes = removingGpsErrorsTemporaryDf[['Acquisition Time']].reset_index().values\n",
    "        #acquisitionTimes = removingGpsErrorsTemporaryDf[['Acquisition Time']].to_numpy()        \n",
    "        \n",
    "        #print(latitudes.dtype)\n",
    "        #print(longitudes.dtype)\n",
    "        #print(acquisitionTimes.dtype)\n",
    "        \n",
    "        #print(latitudes)\n",
    "        #print(longitudes)\n",
    "        #print(acquisitionTimes)\n",
    "\n",
    "        distances = []\n",
    "        tripTimes = []\n",
    "        speeds = []\n",
    "        remSpeeds = []\n",
    "        pointsToRemove = []        \n",
    "        \n",
    "        distances.append(0)\n",
    "        tripTimes.append(0)\n",
    "        speeds.append(0)\n",
    "\n",
    "        i=1\n",
    "        while i < (len(latitudes)):\n",
    "            foundS = False\n",
    "            previous = i-1\n",
    "            D = 0\n",
    "            S = 100\n",
    "            while (S > 1.111) and (i < len(latitudes)):\n",
    "                D = TurtleData.calculateDistance(wgs84_geod, longitudes[previous], latitudes[previous], longitudes[i], latitudes[i])\n",
    "                t1 = TurtleData.convertUnixTimeFromString(acquisitionTimes[previous,0])\n",
    "                t2 = TurtleData.convertUnixTimeFromString(acquisitionTimes[i,0])\n",
    "                S = TurtleData.calculateSpeed(D,t1,t2)\n",
    "                #print(f\" D = {D}\")\n",
    "                #print('dist: %.3f' % D)\n",
    "                #print(f\" S = {S}\")\n",
    "                #print('S: %.3f' % S)\n",
    "                if(S > 1.111):\n",
    "                    remSpeeds.append(S)\n",
    "                    #print(f\"remSpeeds List: {remSpeeds}\")                    \n",
    "                    pointsToRemove.append(acquisitionTimes[i,0])\n",
    "                    #print(pointsToRemove)                    \n",
    "                    i+=1\n",
    "                else:\n",
    "                    foundS = True\n",
    "            if(foundS):\n",
    "                distances.append(D)\n",
    "                tripTimes.append(t2-t1)\n",
    "                speeds.append(S)\n",
    "            i+=1\n",
    "        print(self.turtleTag)\n",
    "        print(\"Length of pointsToRemove List: \")\n",
    "        print(len(pointsToRemove))\n",
    "        print(f\"remSpeeds List: {remSpeeds}\")\n",
    "        #---------\n",
    "        print('--------------')        \n",
    "        print(pointsToRemove)\n",
    "        \n",
    "        print('BEFORE DROP - removingGpsErrorsTemporaryDf')\n",
    "        print(len(removingGpsErrorsTemporaryDf))\n",
    "        \n",
    "        cond = removingGpsErrorsTemporaryDf['Acquisition Time'].isin(pointsToRemove)        \n",
    "        removingGpsErrorsTemporaryDf.drop(removingGpsErrorsTemporaryDf[cond].index, inplace = True)\n",
    "        print('AFTER DROP - removingGpsErrorsTemporaryDf')\n",
    "        print(len(removingGpsErrorsTemporaryDf))\n",
    "\n",
    "        # LATER TRY TO WORK WITH REMOVING DAYS BEFORE TURTLE TAGGED ---------------------------------------------------\n",
    "\n",
    "        ## cond2 remove datetime before specific datetime\n",
    "        ##df['date'] = pd.to_datetime(df['date'])\n",
    "        ##res = df[~(df['date'] < '2018-04-01')]\n",
    "        \n",
    "        #print(\"SEE IF DATETIME WORKS\")\n",
    "        #if self.turtleTag == '710333A':\n",
    "            #removingGpsErrorsTemporaryDf['Acquisition Time'] = pd.to_datetime(removingGpsErrorsTemporaryDf['Acquisition Time'])\n",
    "            #cond2 = removingGpsErrorsTemporaryDf[(removingGpsErrorsTemporaryDf['Acquisition Time'] < '2020.07.09 23:00:09')] #2020.07.09 23:00:09\n",
    "            #print(cond2)\n",
    "            #print('--------------')\n",
    "            #removingGpsErrorsTemporaryDf.drop(removingGpsErrorsTemporaryDf[cond2].index, inplace = True)\n",
    "        \n",
    "        # ---------------------------------------------------\n",
    "         \n",
    "        removingGpsErrorsTemporaryDf['Distance (m)'] = distances        \n",
    "        removingGpsErrorsTemporaryDf['Time (s)'] = tripTimes\n",
    "        removingGpsErrorsTemporaryDf['Speed m/s'] = speeds\n",
    "        removingGpsErrorsTemporaryDf['Time (h)'] = pd.to_timedelta(removingGpsErrorsTemporaryDf['Time (s)'], unit='s') # Add a Column with the Time passed from on Point to another in hours\n",
    "        print('BEFORE CHANGES - FROM INT TO FLOAT')\n",
    "        print(type(removingGpsErrorsTemporaryDf.loc[0, 'Distance (m)']))\n",
    "        \n",
    "        # Removing Square brackets From values in the 'Distance (m)' and 'Speed m/s' Columns\n",
    "        #remove brackets of the values in Columns        \n",
    "        removingGpsErrorsTemporaryDf = removingGpsErrorsTemporaryDf.astype({\"Distance (m)\":'float', \"Speed m/s\":'float'}) \n",
    "        #removingGpsErrorsTemporaryDf['Distance (m)'] = removingGpsErrorsTemporaryDf['Distance (m)'].str[0] #remove the brackets of the values in the column\n",
    "        #removingGpsErrorsTemporaryDf['Speed m/s'] = removingGpsErrorsTemporaryDf['Speed m/s'].str[0] #remove the brackets of the values in the column\t        \n",
    "        print('AFTER CHANGES - FROM INT TO FLOAT')\n",
    "        print(type(removingGpsErrorsTemporaryDf.loc[0, 'Distance (m)']))\n",
    "        \n",
    "        #print(\"With new columns\")\n",
    "        #print(removingGpsErrorsTemporaryDf)\n",
    "        #print(removingGpsErrorsTemporaryDf.dtypes)        \n",
    "        #print('--------------')\n",
    "        \n",
    "        # Create a ID Column on the Left for the Reliable Tracked Points \n",
    "        speedTrackedPoints = removingGpsErrorsTemporaryDf.index + 1\n",
    "        removingGpsErrorsTemporaryDf.insert(0, 'Speed Reliable ID', speedTrackedPoints)\n",
    "        \n",
    "        #print(\"With ID column\")\n",
    "        #print(removingGpsErrorsTemporaryDf)\n",
    "        #print(removingGpsErrorsTemporaryDf.dtypes)        \n",
    "        #print('--------------')\n",
    "        \n",
    "        self.tempReliableGpsDfWithNoTagDate = self.tempReliableGpsDfWithNoTagDate.append(removingGpsErrorsTemporaryDf, ignore_index=True)\n",
    "        \n",
    "        print(\"Assign the Reliable GPS DF of the objs\")\n",
    "        print(self.tempReliableGpsDfWithNoTagDate)\n",
    "        print(self.tempReliableGpsDfWithNoTagDate.dtypes)        \n",
    "        print('--------------')\n",
    "    \n",
    "    def generateTempReliableGpsDfWithNoTagDateCsvName(self):\n",
    "        # Last entry:\n",
    "        lastEntry = self.tempReliableGpsDfWithNoTagDate['Acquisition Time'].tail(1)\n",
    "        #print(lastEntry)\n",
    "        # separing date from time in that column\n",
    "        lastEntry = pd.Series([[y for y in x.split()] for x in lastEntry])\n",
    "        #print(lastEntry)\n",
    "        # assign the Name in the Class Variable\n",
    "        self.tempReliableGpsDfWithNoTagDateCsvName = TurtleData.basedNamesForCsv(lastEntry, \"tempReliableGpsDfWithNoTagDate\", self.turtleTag)\n",
    "    \n",
    "    def saveTempReliableGpsDfWithNoTagDateData(self, pathToFilePlusCsvName):\n",
    "        self.tempReliableGpsDfWithNoTagDate.to_csv(pathToFilePlusCsvName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run with terminal OR jupyter notebook:\n",
    "ASSETS_FOLDER = \"assets\"\n",
    "ASSETS_FOLDER_ITENS = os.listdir(ASSETS_FOLDER)# (\"assets\")\n",
    "\n",
    "DATACLEANINGRESULTS_FOLDER = \"dataCleaningResults\"\n",
    "DATACLEANINGRESULTS_FOLDER_ITENS = os.listdir(DATACLEANINGRESULTS_FOLDER)# (\"data_analysis/dataCleaningResults\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_TURTLE_1 = '710333a'\n",
    "DATE_TAG_TURTLE_1 = '2020.07.09'\n",
    "TIME_TAG_TURTLE_1 = '23:00:09'\n",
    "\n",
    "TAG_TURTLE_2 = '710348a'\n",
    "DATE_TAG_TURTLE_2 = '2020.08.12'\n",
    "TIME_TAG_TURTLE_2 = '02:00:11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_TAG_DIGITS = '7103'\n",
    "\n",
    "# Replace spaces in filenames with underlines\n",
    "def replace_space_with_underline(file_name):\n",
    "    return file_name.replace(\" \", \"_\")\n",
    "\n",
    "# Convert excel files into csv\n",
    "def converting_excel_file_into_csv_file(folder_obj, file):        \n",
    "    # read excel   \n",
    "    df_xlsx = pd.read_excel(os.path.join(folder_obj, file))\n",
    "    # change file format\n",
    "    file_in_csv = file.replace(\".xlsx\", \".csv\")\n",
    "    # transform excel to csv file with path to store the CSV file\n",
    "    df_xlsx.to_csv(os.path.join(folder_obj, file_in_csv), index = False)        \n",
    "\n",
    "# Check if some excel file has not been converted into csv yet\n",
    "def check_for_excel_files():\n",
    "    all_my_files = []\n",
    "    n = 0\n",
    "    for file in ASSETS_FOLDER_ITENS:\n",
    "        # put all the file names in the same format\n",
    "        file = replace_space_with_underline(file).lower()\n",
    "        all_my_files.append(file)\n",
    "    \n",
    "    # Create a copy of list\n",
    "    for file in all_my_files[:]:\n",
    "        if file.endswith('.xlsx'):\n",
    "            print('- Excel file = ' + file)\n",
    "            file_name = file.split('.', 1)[0] # remove everything (the format) after the dot\n",
    "            # remove the excel file from my all_my_files list\n",
    "            all_my_files.remove(file)            \n",
    "            # check if another file with the same name in the folder exists\n",
    "            if any(file_name in word for word in all_my_files):            \n",
    "                print(f\"-- Excellent! We've already converted the excel file \\'{file_name}\\' into csv file\")\n",
    "            else:\n",
    "                print(f'-- Oh No! The excel file \\'{file_name}\\' has been not converted. Converting it into csv file...')\n",
    "                # Call function \"Convert excel files into csv\"\n",
    "                converting_excel_file_into_csv_file(ASSETS_FOLDER, file)\n",
    "                file_in_csv = file.replace(\".xlsx\", \".csv\") \n",
    "                all_my_files.append(file_in_csv)\n",
    "                print('---> ' + file_in_csv + ' has been created!')\n",
    "                \n",
    "    # Updated all_my_files List\n",
    "    print('--- CSV files in the assets folder: ', all_my_files)\n",
    "\n",
    "def getTurtlesData():\n",
    "    split_char = '_'\n",
    "    csvs = []        \n",
    "    turtlesData = []\n",
    "    #turtleDfs = []\n",
    "    for file in ASSETS_FOLDER_ITENS:\n",
    "        if file.endswith('.csv'):\n",
    "            # put all the file names in the same format\n",
    "            csv_string_filename = replace_space_with_underline(file).lower()\n",
    "            filename_splitted = csv_string_filename.split(split_char)                        \n",
    "            for word in filename_splitted:\n",
    "                if word.startswith(INITIAL_TAG_DIGITS):\n",
    "                    csvs.append(file)\n",
    "                    currentFileCsv = ASSETS_FOLDER + '\\\\' + file\n",
    "                    print('--------------')\n",
    "                    print(\"Found TAG (\"+ word +\") in filename , check if tag is already associated with an object...\")\n",
    "\n",
    "                    #--------------------\n",
    "                                \n",
    "                    foundTurtleData = None\n",
    "                    # check inside the list if the turtle has already been created with that tag (word)\n",
    "                    for obj in turtlesData:\n",
    "                        if obj.getTag() == word:\n",
    "                            foundTurtleData = obj\n",
    "                            break    \n",
    "                    #--------------------    \n",
    "                                    \n",
    "                    if foundTurtleData == None:\n",
    "                        print(\"Instance for TAG (\"+ word +\") NOT found! Creating a new instance...\")\n",
    "                        # create a TurtleData obj with the turtle tag\n",
    "                        foundTurtleData = TurtleData(word)\n",
    "                        turtlesData.append(foundTurtleData)\n",
    "                        print(\"Instance for TAG (\"+ word +\") CREATED!\")\n",
    "                    else:\n",
    "                        print(\"Instance for TAG (\"+ word +\") ALREADY EXISTS, skipping object creation!\")\n",
    "                        print('--------------')\n",
    "\n",
    "                    # for the instances turtleData objs in the list (for each turtle tag):\n",
    "                    foundTurtleData.addDataFromCsv(currentFileCsv)                    \n",
    "\n",
    "    return turtlesData\n",
    "\n",
    "def checkInstancesAndItsDfs(turtlesData):\n",
    "    print('Created instances for Obj turtleData: ')\n",
    "    for turtleData in turtlesData:        \n",
    "        print(turtleData.getTag())\n",
    "    print('--------------')\n",
    "    print('Created Dataframes: ')\n",
    "    i = 0\n",
    "    for turtleData in turtlesData: \n",
    "        print(f'turtlesData[{i}].df')\n",
    "        print(turtleData.turtleTag)\n",
    "        print(turtleData.df)\n",
    "        print('--------------')\n",
    "        i+=1\n",
    "\n",
    "def getAllGpsDataframes(turtlesData):\n",
    "    for turtleData in turtlesData:\n",
    "        turtleData.giveAllGpsDf()\n",
    "\n",
    "def displayAllGpsDf(turtlesData):\n",
    "    i = 0\n",
    "    for turtleData in turtlesData:\n",
    "        print(f'turtlesData[{i}].allGpsDf')\n",
    "        print(turtleData.turtleTag)\n",
    "        print(turtleData.allGpsDf)\n",
    "\n",
    "def createAllGpsDfCsvNameForEachInstance(turtlesData):\n",
    "    # create a AllGpsDf's name for each turtleData\n",
    "    for turtleData in turtlesData:\n",
    "        turtleData.generateAllGpsDfCsvName()\n",
    "\n",
    "def checkIfAllGpsDfHasBeenSaved(turtlesData):\n",
    "    filesInResultsFolder = []    \n",
    "    \n",
    "    for file in DATACLEANINGRESULTS_FOLDER_ITENS:\n",
    "        filesInResultsFolder.append(file)    \n",
    "    print(filesInResultsFolder)\n",
    "\n",
    "    for turtleData in turtlesData:\n",
    "        if not filesInResultsFolder:\n",
    "            print(f\"The filename {turtleData.allGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allGpsDfCsvName)\n",
    "            turtleData.saveAllGpsDfData(pathToFilePlusCsvName)\n",
    "            print(f\"{turtleData.allGpsDfCsvName} has been saved in the results folder!\")\n",
    "            #append file in list\n",
    "\n",
    "        elif turtleData.allGpsDfCsvName in filesInResultsFolder:\n",
    "            print(f\"The CSV {turtleData.allGpsDfCsvName} has already been saved in the results folder\")\n",
    "        else:\n",
    "            print(f\"The filename {turtleData.allGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allGpsDfCsvName)\n",
    "            turtleData.saveAllGpsDfData(pathToFilePlusCsvName)\n",
    "\n",
    "def assignTagDayDatetimeToEachInstance(turtlesData):\n",
    "    notFoundTurtleTagDatetime = False\n",
    "    for turtleData in turtlesData:\n",
    "        if turtleData.getTag() == TAG_TURTLE_1:\n",
    "            turtleData.assignTagTurtleDayDatetime(DATE_TAG_TURTLE_1, TIME_TAG_TURTLE_1)\n",
    "        elif turtleData.getTag() == TAG_TURTLE_2:\n",
    "            turtleData.assignTagTurtleDayDatetime(DATE_TAG_TURTLE_2, TIME_TAG_TURTLE_2)\n",
    "        else:\n",
    "            notFoundTurtleTagDatetime = True\n",
    "            print(\"Attention!\")\n",
    "            print(f\"{turtleData.turtleTag} has not a Tag Datetime yet!\")\n",
    "        # for obj in Class, print its tagDatetime\n",
    "        print(\"For obj in Class, print its tagDatetime\")\n",
    "        print(turtleData.tagDatetime)\n",
    "    if not notFoundTurtleTagDatetime:\n",
    "        print(\"Tag Datetime for all instances assign!\")\n",
    "    \n",
    "def getAllCleanedGpsDataframes(turtlesData):\n",
    "    for turtleData in turtlesData:\n",
    "        turtleData.giveAllCleanedGpsDf()\n",
    "\n",
    "def createAllCleanedGpsDfCsvNameForEachInstance(turtlesData):\n",
    "    # create a allCleanedGpsDf's name for each turtleData\n",
    "    for turtleData in turtlesData:\n",
    "        turtleData.generateAllCleanedGpsDfCsvName()\n",
    "\n",
    "def checkIfAllCleanedGpsDfHasBeenSaved(turtlesData):\n",
    "    filesInResultsFolder = []    \n",
    "    \n",
    "    for file in DATACLEANINGRESULTS_FOLDER_ITENS:\n",
    "        filesInResultsFolder.append(file)    \n",
    "    print(filesInResultsFolder)\n",
    "\n",
    "    for turtleData in turtlesData:\n",
    "        if not filesInResultsFolder:\n",
    "            ## Saving AllGpsDf Data \n",
    "            #print(f\"The filename {turtleData.allGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            #pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allGpsDfCsvName)                       \n",
    "            #turtleData.saveAllGpsData(pathToFilePlusCsvName)\n",
    "            #print(f\"{turtleData.allGpsDfCsvName} has been saved in the results folder!\")            \n",
    "            #print('--------------')\n",
    "            ## Saving AllCleanedGps Data\n",
    "            print(f\"The filename {turtleData.allCleanedGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allCleanedGpsDfCsvName)\n",
    "            turtleData.saveAllCleanedGpsDfData(pathToFilePlusCsvName)\n",
    "            print(f\"{turtleData.allCleanedGpsDfCsvName} has been saved in the results folder!\")\n",
    "\n",
    "        #elif turtleData.allGpsDfCsvName in filesInResultsFolder:\n",
    "            #print(f\"The CSV {turtleData.allGpsDfCsvName} has already been saved in the results folder\")\n",
    "        elif turtleData.allCleanedGpsDfCsvName in filesInResultsFolder:\n",
    "            print(f\"The CSV {turtleData.allCleanedGpsDfCsvName} has already been saved in the results folder\")\n",
    "        else:            \n",
    "            ## Saving AllGpsDf Data\n",
    "            #print(f\"The filename {turtleData.allGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            #pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allGpsDfCsvName)\n",
    "            #turtleData.saveAllGpsData(pathToFilePlusCsvName)\n",
    "            #print(f\"{turtleData.allGpsDfCsvName} has been saved in the results folder!\")              \n",
    "            #print('--------------')\n",
    "            ## Saving AllCleanedGps Data\n",
    "            print(f\"The filename {turtleData.allCleanedGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allCleanedGpsDfCsvName)\n",
    "            turtleData.saveAllCleanedGpsDfData(pathToFilePlusCsvName)\n",
    "            print(f\"{turtleData.allCleanedGpsDfCsvName} has been saved in the results folder!\")\n",
    "        #print(filesInResultsFolder)\n",
    "        print('--------------')\n",
    "\n",
    "        # THIS FUNCTION ABOVE IS THE SAME FUNCTION TO SAVE THE ALL GPS DF, TRY TO DO ONLY ONE FUNCTION TO BOTH,\n",
    "        # AND ALSO TRY TO MAKE THIS ONE FUNCTION TO WAIT UNTIL THE CLEANING HAS BEEN MADE TO THEN SAVE THE\n",
    "        # ALL CLEANED GPS DF\n",
    "\n",
    "def getTempReliableGpsDfWithNoTagDateDataframes(turtlesData):\n",
    "    for turtleData in turtlesData:\n",
    "        turtleData.giveTempReliableGpsDfWithNoTagDate()\n",
    "\n",
    "def createTempReliableGpsDfWithNoTagDateCsvNameCsvNameForEachInstance(turtlesData):\n",
    "    # create a reliableGpsDf's name for each turtleData\n",
    "    for turtleData in turtlesData:\n",
    "        turtleData.generateTempReliableGpsDfWithNoTagDateCsvName()\n",
    "\n",
    "def checkIfTempReliableGpsDfWithNoTagDateHasBeenSaved(turtlesData):\n",
    "    filesInResultsFolder = []    \n",
    "    \n",
    "    for file in DATACLEANINGRESULTS_FOLDER_ITENS:\n",
    "        filesInResultsFolder.append(file)    \n",
    "    print(filesInResultsFolder)\n",
    "\n",
    "    for turtleData in turtlesData:\n",
    "        if not filesInResultsFolder:\n",
    "            ## Saving AllGpsDf Data \n",
    "            #print(f\"The filename {turtleData.allGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            #pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allGpsDfCsvName)                       \n",
    "            #turtleData.saveAllGpsData(pathToFilePlusCsvName)\n",
    "            #print(f\"{turtleData.allGpsDfCsvName} has been saved in the results folder!\")            \n",
    "            #print('--------------')\n",
    "            ## Saving AllCleanedGps Data\n",
    "            #print(f\"The filename {turtleData.allCleanedGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            #pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allCleanedGpsDfCsvName)\n",
    "            #turtleData.saveAllCleanedGpsData(pathToFilePlusCsvName)\n",
    "            #print(f\"{turtleData.allCleanedGpsDfCsvName} has been saved in the results folder!\")\n",
    "            ## Saving tempReliableGpsDfWithNoTagDate Data\n",
    "            print(f\"The filename {turtleData.tempReliableGpsDfWithNoTagDateCsvName} is not yet in the folder... saving csv\")\n",
    "            pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.tempReliableGpsDfWithNoTagDateCsvName)\n",
    "            turtleData.saveTempReliableGpsDfWithNoTagDateData(pathToFilePlusCsvName)\n",
    "            print(f\"{turtleData.tempReliableGpsDfWithNoTagDateCsvName} has been saved in the results folder!\")\n",
    "\n",
    "        #elif turtleData.allGpsDfCsvName in filesInResultsFolder:\n",
    "            #print(f\"The CSV {turtleData.allGpsDfCsvName} has already been saved in the results folder\")\n",
    "        #elif turtleData.allCleanedGpsDfCsvName in filesInResultsFolder:\n",
    "            #print(f\"The CSV {turtleData.allCleanedGpsDfCsvName} has already been saved in the results folder\")\n",
    "        elif turtleData.tempReliableGpsDfWithNoTagDateCsvName in filesInResultsFolder:\n",
    "            print(f\"The CSV {turtleData.tempReliableGpsDfWithNoTagDateCsvName} has already been saved in the results folder\")\n",
    "        else:            \n",
    "            ## Saving AllGpsDf Data\n",
    "            #print(f\"The filename {turtleData.allGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            #pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allGpsDfCsvName)\n",
    "            #turtleData.saveAllGpsData(pathToFilePlusCsvName)\n",
    "            #print(f\"{turtleData.allGpsDfCsvName} has been saved in the results folder!\")              \n",
    "            #print('--------------')\n",
    "            ## Saving AllCleanedGps Data\n",
    "            #print(f\"The filename {turtleData.allCleanedGpsDfCsvName} is not yet in the folder... saving csv\")\n",
    "            #pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.allCleanedGpsDfCsvName)\n",
    "            #turtleData.saveAllCleanedGpsData(pathToFilePlusCsvName)\n",
    "            #print(f\"{turtleData.allCleanedGpsDfCsvName} has been saved in the results folder!\")\n",
    "            ## Saving ReliableGpsDf Data\n",
    "            print(f\"The filename {turtleData.tempReliableGpsDfWithNoTagDateCsvName} is not yet in the folder... saving csv\")\n",
    "            pathToFilePlusCsvName = os.path.join(DATACLEANINGRESULTS_FOLDER, turtleData.tempReliableGpsDfWithNoTagDateCsvName)\n",
    "            turtleData.saveTempReliableGpsDfWithNoTagDateData(pathToFilePlusCsvName)\n",
    "            print(f\"{turtleData.tempReliableGpsDfWithNoTagDateCsvName} has been saved in the results folder!\")\n",
    "        #print(filesInResultsFolder)\n",
    "        print('--------------')\n",
    "\n",
    "        # THIS FUNCTION ABOVE IS THE SAME FUNCTION TO SAVE THE ALL GPS DF AND FOR THE All CLEANED GPS, \n",
    "        # TRY TO DO ONLY ONE FUNCTION FOR ALL,\n",
    "        # AND ALSO TRY TO MAKE THIS ONE FUNCTION TO WAIT UNTIL THE CLEANING HAS BEEN MADE \n",
    "        # TO THEN SAVE THE FIRST THE ALL CLEANED GPS DF AND THEN THE RELIABLE GPS DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Excel file = mytest.xlsx\n",
      "-- Excellent! We've already converted the excel file 'mytest' into csv file\n",
      "- Excel file = tag_710333a_20_sept.xlsx\n",
      "-- Excellent! We've already converted the excel file 'tag_710333a_20_sept' into csv file\n",
      "--- CSV files in the assets folder:  ['710333a_93_condensed.csv', '710348a_49_condensed.csv', 'mytest.csv', 'tag_710333a_20_sept.csv']\n",
      "--------------\n",
      "Found TAG (710333a) in filename , check if tag is already associated with an object...\n",
      "Instance for TAG (710333a) NOT found! Creating a new instance...\n",
      "Instance for TAG (710333a) CREATED!\n",
      "--------------\n",
      "Found TAG (710348a) in filename , check if tag is already associated with an object...\n",
      "Instance for TAG (710348a) NOT found! Creating a new instance...\n",
      "Instance for TAG (710348a) CREATED!\n",
      "--------------\n",
      "Found TAG (710333a) in filename , check if tag is already associated with an object...\n",
      "Instance for TAG (710333a) ALREADY EXISTS, skipping object creation!\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# Check if some excel file has not been converted into csv yet\n",
    "check_for_excel_files()\n",
    "turtlesData = getTurtlesData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created instances for Obj turtleData: \n",
      "710333a\n",
      "710348a\n",
      "--------------\n",
      "Created Dataframes: \n",
      "turtlesData[0].df\n",
      "710333a\n",
      "         Acquisition Time Acquisition Start Time  Iridium CEP Radius  \\\n",
      "0     2019.07.15 14:15:00    2019.07.15 14:15:00                 NaN   \n",
      "1     2019.07.15 14:15:08    2019.07.15 14:15:00                 NaN   \n",
      "2     2019.07.15 14:30:00    2019.07.15 14:15:00                 NaN   \n",
      "3     2019.07.15 14:30:00    2019.07.15 14:30:00                 NaN   \n",
      "4     2019.07.15 14:30:10    2019.07.15 14:30:00                 NaN   \n",
      "...                   ...                    ...                 ...   \n",
      "6903  2021.02.11 05:55:38    2021.02.11 05:00:00                 NaN   \n",
      "6904  2021.02.11 06:00:00    2021.02.11 04:00:00                 NaN   \n",
      "6905  2021.02.11 06:00:10    2021.02.11 06:00:00                 NaN   \n",
      "6906  2021.02.11 08:00:00    2021.02.11 06:00:00                 NaN   \n",
      "6907  2021.02.11 10:57:07    2021.02.11 10:57:07                 3.0   \n",
      "\n",
      "      Iridium Latitude  Iridium Longitude         GPS Fix Time  \\\n",
      "0                  NaN                NaN                  NaN   \n",
      "1                  NaN                NaN  2019.07.15 14:15:08   \n",
      "2                  NaN                NaN                  NaN   \n",
      "3                  NaN                NaN                  NaN   \n",
      "4                  NaN                NaN  2019.07.15 14:30:10   \n",
      "...                ...                ...                  ...   \n",
      "6903               NaN                NaN  2021.02.11 05:55:38   \n",
      "6904               NaN                NaN                  NaN   \n",
      "6905               NaN                NaN  2021.02.11 06:00:10   \n",
      "6906               NaN                NaN                  NaN   \n",
      "6907          38.72645            11.8152                  NaN   \n",
      "\n",
      "     GPS Fix Attempt  GPS Latitude  GPS Longitude GPS UTM Zone  ...  \\\n",
      "0                NaN           NaN            NaN          NaN  ...   \n",
      "1       Resolved QFP     33.384364    -111.811310          12S  ...   \n",
      "2                NaN           NaN            NaN          NaN  ...   \n",
      "3                NaN           NaN            NaN          NaN  ...   \n",
      "4       Resolved QFP     33.384385    -111.811292          12S  ...   \n",
      "...              ...           ...            ...          ...  ...   \n",
      "6903    Resolved QFP     38.720644      11.825379          32S  ...   \n",
      "6904             NaN           NaN            NaN          NaN  ...   \n",
      "6905    Resolved QFP     38.720648      11.825217          32S  ...   \n",
      "6906             NaN           NaN            NaN          NaN  ...   \n",
      "6907             NaN           NaN            NaN          NaN  ...   \n",
      "\n",
      "             Receive Time  Repetition Count  Low Voltage  Mortality  \\\n",
      "0     2019.07.15 14:40:24                 1          NaN        NaN   \n",
      "1     2019.07.15 14:40:24                 1          NaN        NaN   \n",
      "2     2019.07.15 14:40:24                 1          NaN        NaN   \n",
      "3     2019.07.15 14:40:24                 1          NaN        NaN   \n",
      "4     2019.07.15 14:40:24                 1          NaN        NaN   \n",
      "...                   ...               ...          ...        ...   \n",
      "6903  2021.02.11 10:57:07                 1          NaN        NaN   \n",
      "6904  2021.02.11 10:57:07                 1          NaN        NaN   \n",
      "6905  2021.02.11 10:57:07                 1          NaN        NaN   \n",
      "6906  2021.02.11 10:57:07                 1          NaN        NaN   \n",
      "6907  2021.02.11 10:57:07                 1           No        NaN   \n",
      "\n",
      "      Saltwater Failsafe Iridium Command  Schedule Set  \\\n",
      "0                    NaN             NaN     Roof Test   \n",
      "1                    NaN             NaN     Roof Test   \n",
      "2                    NaN             NaN     Roof Test   \n",
      "3                    NaN             NaN     Roof Test   \n",
      "4                    NaN             NaN     Roof Test   \n",
      "...                  ...             ...           ...   \n",
      "6903                 NaN             NaN       Primary   \n",
      "6904                 NaN             NaN       Primary   \n",
      "6905                 NaN             NaN       Primary   \n",
      "6906                 NaN             NaN       Primary   \n",
      "6907                  No             NaN           NaN   \n",
      "\n",
      "           Diagnostic Dive Data  Predeployment Data  Error  \n",
      "0                           NaN                  No    NaN  \n",
      "1                           NaN                  No    NaN  \n",
      "2                           NaN                  No    NaN  \n",
      "3                           NaN                  No    NaN  \n",
      "4                           NaN                  No    NaN  \n",
      "...                         ...                 ...    ...  \n",
      "6903                        NaN                  No    NaN  \n",
      "6904                        NaN                  No    NaN  \n",
      "6905                        NaN                  No    NaN  \n",
      "6906                        NaN                  No    NaN  \n",
      "6907  23094 7698 8878 3 0 0 2 1                  No    NaN  \n",
      "\n",
      "[9528 rows x 61 columns]\n",
      "--------------\n",
      "turtlesData[1].df\n",
      "710348a\n",
      "         Acquisition Time Acquisition Start Time  Iridium CEP Radius  \\\n",
      "0     2019.07.15 14:15:00    2019.07.15 14:15:00                 NaN   \n",
      "1     2019.07.15 14:15:08    2019.07.15 14:15:00                 NaN   \n",
      "2     2019.07.15 14:30:00    2019.07.15 14:15:00                 NaN   \n",
      "3     2019.07.15 14:30:00    2019.07.15 14:30:00                 NaN   \n",
      "4     2019.07.15 14:30:06    2019.07.15 14:30:00                 NaN   \n",
      "...                   ...                    ...                 ...   \n",
      "5666  2021.02.11 04:00:00    2021.02.11 02:00:00                 NaN   \n",
      "5667  2021.02.11 05:50:10    2021.02.11 05:00:00                 NaN   \n",
      "5668  2021.02.11 06:00:00    2021.02.11 04:00:00                 NaN   \n",
      "5669  2021.02.11 06:41:28    2021.02.11 06:00:00                 NaN   \n",
      "5670  2021.02.11 10:40:30    2021.02.11 10:40:30                 4.0   \n",
      "\n",
      "      Iridium Latitude  Iridium Longitude         GPS Fix Time  \\\n",
      "0                  NaN                NaN                  NaN   \n",
      "1                  NaN                NaN  2019.07.15 14:15:08   \n",
      "2                  NaN                NaN                  NaN   \n",
      "3                  NaN                NaN                  NaN   \n",
      "4                  NaN                NaN  2019.07.15 14:30:06   \n",
      "...                ...                ...                  ...   \n",
      "5666               NaN                NaN                  NaN   \n",
      "5667               NaN                NaN  2021.02.11 05:50:10   \n",
      "5668               NaN                NaN                  NaN   \n",
      "5669               NaN                NaN  2021.02.11 06:41:28   \n",
      "5670          37.71965           17.37297                  NaN   \n",
      "\n",
      "     GPS Fix Attempt  GPS Latitude  GPS Longitude GPS UTM Zone  ...  \\\n",
      "0                NaN           NaN            NaN          NaN  ...   \n",
      "1       Resolved QFP     33.384380    -111.811327          12S  ...   \n",
      "2                NaN           NaN            NaN          NaN  ...   \n",
      "3                NaN           NaN            NaN          NaN  ...   \n",
      "4       Resolved QFP     33.384410    -111.811311          12S  ...   \n",
      "...              ...           ...            ...          ...  ...   \n",
      "5666             NaN           NaN            NaN          NaN  ...   \n",
      "5667    Resolved QFP     37.752154      17.380009          33S  ...   \n",
      "5668             NaN           NaN            NaN          NaN  ...   \n",
      "5669    Resolved QFP     37.742126      17.386460          33S  ...   \n",
      "5670             NaN           NaN            NaN          NaN  ...   \n",
      "\n",
      "             Receive Time  Repetition Count  Low Voltage  Mortality  \\\n",
      "0     2019.07.15 14:38:49                 1          NaN        NaN   \n",
      "1     2019.07.15 14:38:49                 1          NaN        NaN   \n",
      "2     2019.07.15 14:38:49                 1          NaN        NaN   \n",
      "3     2019.07.15 14:38:49                 1          NaN        NaN   \n",
      "4     2019.07.15 14:38:49                 1          NaN        NaN   \n",
      "...                   ...               ...          ...        ...   \n",
      "5666  2021.02.11 10:40:30                 1          NaN        NaN   \n",
      "5667  2021.02.11 10:40:30                 1          NaN        NaN   \n",
      "5668  2021.02.11 10:40:30                 1          NaN        NaN   \n",
      "5669  2021.02.11 10:40:30                 1          NaN        NaN   \n",
      "5670  2021.02.11 10:40:30                 1           No        NaN   \n",
      "\n",
      "      Saltwater Failsafe Iridium Command  Schedule Set Diagnostic Dive Data  \\\n",
      "0                    NaN             NaN     Roof Test                  NaN   \n",
      "1                    NaN             NaN     Roof Test                  NaN   \n",
      "2                    NaN             NaN     Roof Test                  NaN   \n",
      "3                    NaN             NaN     Roof Test                  NaN   \n",
      "4                    NaN             NaN     Roof Test                  NaN   \n",
      "...                  ...             ...           ...                  ...   \n",
      "5666                 NaN             NaN       Primary                  NaN   \n",
      "5667                 NaN             NaN       Primary                  NaN   \n",
      "5668                 NaN             NaN       Primary                  NaN   \n",
      "5669                 NaN             NaN       Primary                  NaN   \n",
      "5670                  No             NaN           NaN  0 0 13927 5 0 0 0 0   \n",
      "\n",
      "      Predeployment Data  Error  \n",
      "0                     No    NaN  \n",
      "1                     No    NaN  \n",
      "2                     No    NaN  \n",
      "3                     No    NaN  \n",
      "4                     No    NaN  \n",
      "...                  ...    ...  \n",
      "5666                  No    NaN  \n",
      "5667                  No    NaN  \n",
      "5668                  No    NaN  \n",
      "5669                  No    NaN  \n",
      "5670                  No    NaN  \n",
      "\n",
      "[5671 rows x 61 columns]\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# see instances for Obj turtleData created and its dfs\n",
    "checkInstancesAndItsDfs(turtlesData)\n",
    "#turtlesData[0].df\n",
    "#turtlesData[1].df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Acquisition Time', 'Acquisition Start Time', 'GPS Fix Time', 'GPS Fix Attempt', 'GPS Latitude', 'GPS Longitude']\n",
      "Acquisition Time\n",
      "Acquisition Start Time\n",
      "Iridium CEP Radius\n",
      "Iridium Latitude\n",
      "Iridium Longitude\n",
      "GPS Fix Time\n",
      "GPS Fix Attempt\n",
      "GPS Latitude\n",
      "GPS Longitude\n",
      "GPS UTM Zone\n",
      "GPS UTM Northing\n",
      "GPS UTM Easting\n",
      "GPS Altitude\n",
      "GPS Horizontal Error\n",
      "GPS Horizontal Dilution\n",
      "GPS Satellite Bitmap\n",
      "GPS Satellite Count\n",
      "Underwater Percentage\n",
      "Dive Count\n",
      "Average Dive Duration\n",
      "Dive Duration Standard Deviation\n",
      "Maximum Dive Duration\n",
      "Maximum Dive Depth\n",
      "Duration Limit 1 Dive Count\n",
      "Duration Limit 2 Dive Count\n",
      "Duration Limit 3 Dive Count\n",
      "Duration Limit 4 Dive Count\n",
      "Duration Limit 5 Dive Count\n",
      "Duration Limit 6 Dive Count\n",
      "Layer 1 Percentage\n",
      "Layer 2 Percentage\n",
      "Layer 3 Percentage\n",
      "Layer 4 Percentage\n",
      "Layer 5 Percentage\n",
      "Layer 6 Percentage\n",
      "Layer 7 Percentage\n",
      "Layer 8 Percentage\n",
      "Layer 9 Percentage\n",
      "Layer 10 Percentage\n",
      "Layer 1 Dive Count\n",
      "Layer 2 Dive Count\n",
      "Layer 3 Dive Count\n",
      "Layer 4 Dive Count\n",
      "Layer 5 Dive Count\n",
      "Layer 6 Dive Count\n",
      "Layer 7 Dive Count\n",
      "Layer 8 Dive Count\n",
      "Layer 9 Dive Count\n",
      "Layer 10 Dive Count\n",
      "Temperature\n",
      "Satellite Uplink\n",
      "Receive Time\n",
      "Repetition Count\n",
      "Low Voltage\n",
      "Mortality\n",
      "Saltwater Failsafe\n",
      "Iridium Command\n",
      "Schedule Set\n",
      "Diagnostic Dive Data\n",
      "Predeployment Data\n",
      "Error\n",
      "The dataframe contains all the GPS columns\n",
      "-----DF with NaN values ---------\n",
      "         Acquisition Time Acquisition Start Time         GPS Fix Time  \\\n",
      "0     2019.07.15 14:15:00    2019.07.15 14:15:00                  NaN   \n",
      "1     2019.07.15 14:15:08    2019.07.15 14:15:00  2019.07.15 14:15:08   \n",
      "2     2019.07.15 14:30:00    2019.07.15 14:15:00                  NaN   \n",
      "3     2019.07.15 14:30:00    2019.07.15 14:30:00                  NaN   \n",
      "4     2019.07.15 14:30:10    2019.07.15 14:30:00  2019.07.15 14:30:10   \n",
      "...                   ...                    ...                  ...   \n",
      "6903  2021.02.11 05:55:38    2021.02.11 05:00:00  2021.02.11 05:55:38   \n",
      "6904  2021.02.11 06:00:00    2021.02.11 04:00:00                  NaN   \n",
      "6905  2021.02.11 06:00:10    2021.02.11 06:00:00  2021.02.11 06:00:10   \n",
      "6906  2021.02.11 08:00:00    2021.02.11 06:00:00                  NaN   \n",
      "6907  2021.02.11 10:57:07    2021.02.11 10:57:07                  NaN   \n",
      "\n",
      "     GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0                NaN           NaN            NaN  \n",
      "1       Resolved QFP     33.384364    -111.811310  \n",
      "2                NaN           NaN            NaN  \n",
      "3                NaN           NaN            NaN  \n",
      "4       Resolved QFP     33.384385    -111.811292  \n",
      "...              ...           ...            ...  \n",
      "6903    Resolved QFP     38.720644      11.825379  \n",
      "6904             NaN           NaN            NaN  \n",
      "6905    Resolved QFP     38.720648      11.825217  \n",
      "6906             NaN           NaN            NaN  \n",
      "6907             NaN           NaN            NaN  \n",
      "\n",
      "[9528 rows x 6 columns]\n",
      "-----SAME DF without NaN values ---------\n",
      "         Acquisition Time Acquisition Start Time         GPS Fix Time  \\\n",
      "0     2019.07.15 14:15:08    2019.07.15 14:15:00  2019.07.15 14:15:08   \n",
      "1     2019.07.15 14:30:10    2019.07.15 14:30:00  2019.07.15 14:30:10   \n",
      "2     2019.07.15 14:45:08    2019.07.15 14:45:00  2019.07.15 14:45:08   \n",
      "3     2019.07.15 15:00:10    2019.07.15 15:00:00  2019.07.15 15:00:10   \n",
      "4     2019.07.15 15:15:07    2019.07.15 15:15:00  2019.07.15 15:15:07   \n",
      "...                   ...                    ...                  ...   \n",
      "4647  2021.02.10 19:28:58    2021.02.10 19:00:00  2021.02.10 19:28:58   \n",
      "4648  2021.02.10 22:42:32    2021.02.10 22:00:00  2021.02.10 22:42:32   \n",
      "4649  2021.02.11 02:28:20    2021.02.11 02:00:00  2021.02.11 02:28:20   \n",
      "4650  2021.02.11 05:55:38    2021.02.11 05:00:00  2021.02.11 05:55:38   \n",
      "4651  2021.02.11 06:00:10    2021.02.11 06:00:00  2021.02.11 06:00:10   \n",
      "\n",
      "               GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0                 Resolved QFP     33.384364    -111.811310  \n",
      "1                 Resolved QFP     33.384385    -111.811292  \n",
      "2                 Resolved QFP     33.384473    -111.811319  \n",
      "3                 Resolved QFP     33.384442    -111.811340  \n",
      "4     Resolved QFP (Uncertain)     33.384412    -111.811369  \n",
      "...                        ...           ...            ...  \n",
      "4647              Resolved QFP     38.754772      11.809630  \n",
      "4648              Resolved QFP     38.741873      11.821516  \n",
      "4649              Resolved QFP     38.727643      11.821051  \n",
      "4650              Resolved QFP     38.720644      11.825379  \n",
      "4651              Resolved QFP     38.720648      11.825217  \n",
      "\n",
      "[4652 rows x 6 columns]\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                      1  2019.07.15 14:15:08    2019.07.15 14:15:00   \n",
      "1                      2  2019.07.15 14:30:10    2019.07.15 14:30:00   \n",
      "2                      3  2019.07.15 14:45:08    2019.07.15 14:45:00   \n",
      "3                      4  2019.07.15 15:00:10    2019.07.15 15:00:00   \n",
      "4                      5  2019.07.15 15:15:07    2019.07.15 15:15:00   \n",
      "...                  ...                  ...                    ...   \n",
      "4647                4648  2021.02.10 19:28:58    2021.02.10 19:00:00   \n",
      "4648                4649  2021.02.10 22:42:32    2021.02.10 22:00:00   \n",
      "4649                4650  2021.02.11 02:28:20    2021.02.11 02:00:00   \n",
      "4650                4651  2021.02.11 05:55:38    2021.02.11 05:00:00   \n",
      "4651                4652  2021.02.11 06:00:10    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time           GPS Fix Attempt  GPS Latitude  \\\n",
      "0     2019.07.15 14:15:08              Resolved QFP     33.384364   \n",
      "1     2019.07.15 14:30:10              Resolved QFP     33.384385   \n",
      "2     2019.07.15 14:45:08              Resolved QFP     33.384473   \n",
      "3     2019.07.15 15:00:10              Resolved QFP     33.384442   \n",
      "4     2019.07.15 15:15:07  Resolved QFP (Uncertain)     33.384412   \n",
      "...                   ...                       ...           ...   \n",
      "4647  2021.02.10 19:28:58              Resolved QFP     38.754772   \n",
      "4648  2021.02.10 22:42:32              Resolved QFP     38.741873   \n",
      "4649  2021.02.11 02:28:20              Resolved QFP     38.727643   \n",
      "4650  2021.02.11 05:55:38              Resolved QFP     38.720644   \n",
      "4651  2021.02.11 06:00:10              Resolved QFP     38.720648   \n",
      "\n",
      "      GPS Longitude  \n",
      "0       -111.811310  \n",
      "1       -111.811292  \n",
      "2       -111.811319  \n",
      "3       -111.811340  \n",
      "4       -111.811369  \n",
      "...             ...  \n",
      "4647      11.809630  \n",
      "4648      11.821516  \n",
      "4649      11.821051  \n",
      "4650      11.825379  \n",
      "4651      11.825217  \n",
      "\n",
      "[4652 rows x 7 columns]\n",
      " End of all GPS Df ^\n",
      "--------------\n",
      "['Acquisition Time', 'Acquisition Start Time', 'GPS Fix Time', 'GPS Fix Attempt', 'GPS Latitude', 'GPS Longitude']\n",
      "Acquisition Time\n",
      "Acquisition Start Time\n",
      "Iridium CEP Radius\n",
      "Iridium Latitude\n",
      "Iridium Longitude\n",
      "GPS Fix Time\n",
      "GPS Fix Attempt\n",
      "GPS Latitude\n",
      "GPS Longitude\n",
      "GPS UTM Zone\n",
      "GPS UTM Northing\n",
      "GPS UTM Easting\n",
      "GPS Altitude\n",
      "GPS Horizontal Error\n",
      "GPS Horizontal Dilution\n",
      "GPS Satellite Bitmap\n",
      "GPS Satellite Count\n",
      "Underwater Percentage\n",
      "Dive Count\n",
      "Average Dive Duration\n",
      "Dive Duration Standard Deviation\n",
      "Maximum Dive Duration\n",
      "Maximum Dive Depth\n",
      "Duration Limit 1 Dive Count\n",
      "Duration Limit 2 Dive Count\n",
      "Duration Limit 3 Dive Count\n",
      "Duration Limit 4 Dive Count\n",
      "Duration Limit 5 Dive Count\n",
      "Duration Limit 6 Dive Count\n",
      "Layer 1 Percentage\n",
      "Layer 2 Percentage\n",
      "Layer 3 Percentage\n",
      "Layer 4 Percentage\n",
      "Layer 5 Percentage\n",
      "Layer 6 Percentage\n",
      "Layer 7 Percentage\n",
      "Layer 8 Percentage\n",
      "Layer 9 Percentage\n",
      "Layer 10 Percentage\n",
      "Layer 1 Dive Count\n",
      "Layer 2 Dive Count\n",
      "Layer 3 Dive Count\n",
      "Layer 4 Dive Count\n",
      "Layer 5 Dive Count\n",
      "Layer 6 Dive Count\n",
      "Layer 7 Dive Count\n",
      "Layer 8 Dive Count\n",
      "Layer 9 Dive Count\n",
      "Layer 10 Dive Count\n",
      "Temperature\n",
      "Satellite Uplink\n",
      "Receive Time\n",
      "Repetition Count\n",
      "Low Voltage\n",
      "Mortality\n",
      "Saltwater Failsafe\n",
      "Iridium Command\n",
      "Schedule Set\n",
      "Diagnostic Dive Data\n",
      "Predeployment Data\n",
      "Error\n",
      "The dataframe contains all the GPS columns\n",
      "-----DF with NaN values ---------\n",
      "         Acquisition Time Acquisition Start Time         GPS Fix Time  \\\n",
      "0     2019.07.15 14:15:00    2019.07.15 14:15:00                  NaN   \n",
      "1     2019.07.15 14:15:08    2019.07.15 14:15:00  2019.07.15 14:15:08   \n",
      "2     2019.07.15 14:30:00    2019.07.15 14:15:00                  NaN   \n",
      "3     2019.07.15 14:30:00    2019.07.15 14:30:00                  NaN   \n",
      "4     2019.07.15 14:30:06    2019.07.15 14:30:00  2019.07.15 14:30:06   \n",
      "...                   ...                    ...                  ...   \n",
      "5666  2021.02.11 04:00:00    2021.02.11 02:00:00                  NaN   \n",
      "5667  2021.02.11 05:50:10    2021.02.11 05:00:00  2021.02.11 05:50:10   \n",
      "5668  2021.02.11 06:00:00    2021.02.11 04:00:00                  NaN   \n",
      "5669  2021.02.11 06:41:28    2021.02.11 06:00:00  2021.02.11 06:41:28   \n",
      "5670  2021.02.11 10:40:30    2021.02.11 10:40:30                  NaN   \n",
      "\n",
      "     GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0                NaN           NaN            NaN  \n",
      "1       Resolved QFP     33.384380    -111.811327  \n",
      "2                NaN           NaN            NaN  \n",
      "3                NaN           NaN            NaN  \n",
      "4       Resolved QFP     33.384410    -111.811311  \n",
      "...              ...           ...            ...  \n",
      "5666             NaN           NaN            NaN  \n",
      "5667    Resolved QFP     37.752154      17.380009  \n",
      "5668             NaN           NaN            NaN  \n",
      "5669    Resolved QFP     37.742126      17.386460  \n",
      "5670             NaN           NaN            NaN  \n",
      "\n",
      "[5671 rows x 6 columns]\n",
      "-----SAME DF without NaN values ---------\n",
      "         Acquisition Time Acquisition Start Time         GPS Fix Time  \\\n",
      "0     2019.07.15 14:15:08    2019.07.15 14:15:00  2019.07.15 14:15:08   \n",
      "1     2019.07.15 14:30:06    2019.07.15 14:30:00  2019.07.15 14:30:06   \n",
      "2     2019.07.15 14:45:11    2019.07.15 14:45:00  2019.07.15 14:45:11   \n",
      "3     2019.07.15 15:00:07    2019.07.15 15:00:00  2019.07.15 15:00:07   \n",
      "4     2019.07.15 15:15:08    2019.07.15 15:15:00  2019.07.15 15:15:08   \n",
      "...                   ...                    ...                  ...   \n",
      "2575  2021.02.10 22:28:03    2021.02.10 22:00:00  2021.02.10 22:28:03   \n",
      "2576  2021.02.11 02:57:25    2021.02.11 02:00:00  2021.02.11 02:57:25   \n",
      "2577  2021.02.11 03:00:07    2021.02.11 03:00:00  2021.02.11 03:00:07   \n",
      "2578  2021.02.11 05:50:10    2021.02.11 05:00:00  2021.02.11 05:50:10   \n",
      "2579  2021.02.11 06:41:28    2021.02.11 06:00:00  2021.02.11 06:41:28   \n",
      "\n",
      "     GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0       Resolved QFP     33.384380    -111.811327  \n",
      "1       Resolved QFP     33.384410    -111.811311  \n",
      "2       Resolved QFP     33.384463    -111.811327  \n",
      "3       Resolved QFP     33.384328    -111.811264  \n",
      "4       Resolved QFP     33.384443    -111.811241  \n",
      "...              ...           ...            ...  \n",
      "2575    Resolved QFP     37.799874      17.300539  \n",
      "2576    Resolved QFP     37.781820      17.352911  \n",
      "2577    Resolved QFP     37.781188      17.353534  \n",
      "2578    Resolved QFP     37.752154      17.380009  \n",
      "2579    Resolved QFP     37.742126      17.386460  \n",
      "\n",
      "[2580 rows x 6 columns]\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                      1  2019.07.15 14:15:08    2019.07.15 14:15:00   \n",
      "1                      2  2019.07.15 14:30:06    2019.07.15 14:30:00   \n",
      "2                      3  2019.07.15 14:45:11    2019.07.15 14:45:00   \n",
      "3                      4  2019.07.15 15:00:07    2019.07.15 15:00:00   \n",
      "4                      5  2019.07.15 15:15:08    2019.07.15 15:15:00   \n",
      "...                  ...                  ...                    ...   \n",
      "2575                2576  2021.02.10 22:28:03    2021.02.10 22:00:00   \n",
      "2576                2577  2021.02.11 02:57:25    2021.02.11 02:00:00   \n",
      "2577                2578  2021.02.11 03:00:07    2021.02.11 03:00:00   \n",
      "2578                2579  2021.02.11 05:50:10    2021.02.11 05:00:00   \n",
      "2579                2580  2021.02.11 06:41:28    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0     2019.07.15 14:15:08    Resolved QFP     33.384380    -111.811327  \n",
      "1     2019.07.15 14:30:06    Resolved QFP     33.384410    -111.811311  \n",
      "2     2019.07.15 14:45:11    Resolved QFP     33.384463    -111.811327  \n",
      "3     2019.07.15 15:00:07    Resolved QFP     33.384328    -111.811264  \n",
      "4     2019.07.15 15:15:08    Resolved QFP     33.384443    -111.811241  \n",
      "...                   ...             ...           ...            ...  \n",
      "2575  2021.02.10 22:28:03    Resolved QFP     37.799874      17.300539  \n",
      "2576  2021.02.11 02:57:25    Resolved QFP     37.781820      17.352911  \n",
      "2577  2021.02.11 03:00:07    Resolved QFP     37.781188      17.353534  \n",
      "2578  2021.02.11 05:50:10    Resolved QFP     37.752154      17.380009  \n",
      "2579  2021.02.11 06:41:28    Resolved QFP     37.742126      17.386460  \n",
      "\n",
      "[2580 rows x 7 columns]\n",
      " End of all GPS Df ^\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# build dfs of all gps\n",
    "getAllGpsDataframes(turtlesData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turtlesData[0].allGpsDf\n",
      "710333a\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                      1  2019.07.15 14:15:08    2019.07.15 14:15:00   \n",
      "1                      2  2019.07.15 14:30:10    2019.07.15 14:30:00   \n",
      "2                      3  2019.07.15 14:45:08    2019.07.15 14:45:00   \n",
      "3                      4  2019.07.15 15:00:10    2019.07.15 15:00:00   \n",
      "4                      5  2019.07.15 15:15:07    2019.07.15 15:15:00   \n",
      "...                  ...                  ...                    ...   \n",
      "4647                4648  2021.02.10 19:28:58    2021.02.10 19:00:00   \n",
      "4648                4649  2021.02.10 22:42:32    2021.02.10 22:00:00   \n",
      "4649                4650  2021.02.11 02:28:20    2021.02.11 02:00:00   \n",
      "4650                4651  2021.02.11 05:55:38    2021.02.11 05:00:00   \n",
      "4651                4652  2021.02.11 06:00:10    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time           GPS Fix Attempt  GPS Latitude  \\\n",
      "0     2019.07.15 14:15:08              Resolved QFP     33.384364   \n",
      "1     2019.07.15 14:30:10              Resolved QFP     33.384385   \n",
      "2     2019.07.15 14:45:08              Resolved QFP     33.384473   \n",
      "3     2019.07.15 15:00:10              Resolved QFP     33.384442   \n",
      "4     2019.07.15 15:15:07  Resolved QFP (Uncertain)     33.384412   \n",
      "...                   ...                       ...           ...   \n",
      "4647  2021.02.10 19:28:58              Resolved QFP     38.754772   \n",
      "4648  2021.02.10 22:42:32              Resolved QFP     38.741873   \n",
      "4649  2021.02.11 02:28:20              Resolved QFP     38.727643   \n",
      "4650  2021.02.11 05:55:38              Resolved QFP     38.720644   \n",
      "4651  2021.02.11 06:00:10              Resolved QFP     38.720648   \n",
      "\n",
      "      GPS Longitude  \n",
      "0       -111.811310  \n",
      "1       -111.811292  \n",
      "2       -111.811319  \n",
      "3       -111.811340  \n",
      "4       -111.811369  \n",
      "...             ...  \n",
      "4647      11.809630  \n",
      "4648      11.821516  \n",
      "4649      11.821051  \n",
      "4650      11.825379  \n",
      "4651      11.825217  \n",
      "\n",
      "[4652 rows x 7 columns]\n",
      "turtlesData[0].allGpsDf\n",
      "710348a\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                      1  2019.07.15 14:15:08    2019.07.15 14:15:00   \n",
      "1                      2  2019.07.15 14:30:06    2019.07.15 14:30:00   \n",
      "2                      3  2019.07.15 14:45:11    2019.07.15 14:45:00   \n",
      "3                      4  2019.07.15 15:00:07    2019.07.15 15:00:00   \n",
      "4                      5  2019.07.15 15:15:08    2019.07.15 15:15:00   \n",
      "...                  ...                  ...                    ...   \n",
      "2575                2576  2021.02.10 22:28:03    2021.02.10 22:00:00   \n",
      "2576                2577  2021.02.11 02:57:25    2021.02.11 02:00:00   \n",
      "2577                2578  2021.02.11 03:00:07    2021.02.11 03:00:00   \n",
      "2578                2579  2021.02.11 05:50:10    2021.02.11 05:00:00   \n",
      "2579                2580  2021.02.11 06:41:28    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0     2019.07.15 14:15:08    Resolved QFP     33.384380    -111.811327  \n",
      "1     2019.07.15 14:30:06    Resolved QFP     33.384410    -111.811311  \n",
      "2     2019.07.15 14:45:11    Resolved QFP     33.384463    -111.811327  \n",
      "3     2019.07.15 15:00:07    Resolved QFP     33.384328    -111.811264  \n",
      "4     2019.07.15 15:15:08    Resolved QFP     33.384443    -111.811241  \n",
      "...                   ...             ...           ...            ...  \n",
      "2575  2021.02.10 22:28:03    Resolved QFP     37.799874      17.300539  \n",
      "2576  2021.02.11 02:57:25    Resolved QFP     37.781820      17.352911  \n",
      "2577  2021.02.11 03:00:07    Resolved QFP     37.781188      17.353534  \n",
      "2578  2021.02.11 05:50:10    Resolved QFP     37.752154      17.380009  \n",
      "2579  2021.02.11 06:41:28    Resolved QFP     37.742126      17.386460  \n",
      "\n",
      "[2580 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# see dfs of all gps\n",
    "displayAllGpsDf(turtlesData)\n",
    "# or\n",
    "#turtlesData[0].allGpsDf\n",
    "#turtlesData[1].allGpsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Last Entry in the Dataframe for 710333a is from: \n",
      "2021_Feb\n",
      "The Name for the allGpsDf CSV for the turtleData 710333a is: \n",
      "allGpsDf_Tag_710333a_2021_Feb.csv\n",
      "--------------\n",
      "The Last Entry in the Dataframe for 710348a is from: \n",
      "2021_Feb\n",
      "The Name for the allGpsDf CSV for the turtleData 710348a is: \n",
      "allGpsDf_Tag_710348a_2021_Feb.csv\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# get name for each ALL GPS DF turtleData\n",
    "createAllGpsDfCsvNameForEachInstance(turtlesData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allGpsDf_Tag_710333a_2021_Feb.csv', 'allGpsDf_Tag_710348a_2021_Feb.csv']\n",
      "The CSV allGpsDf_Tag_710333a_2021_Feb.csv has already been saved in the results folder\n",
      "The CSV allGpsDf_Tag_710348a_2021_Feb.csv has already been saved in the results folder\n"
     ]
    }
   ],
   "source": [
    "# SAVE THE ALL GPS DATAFRAME in the Results Folder\n",
    "checkIfAllGpsDfHasBeenSaved(turtlesData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For obj in Class, print its tagDatetime\n",
      "2020.07.09 23:00:09\n",
      "For obj in Class, print its tagDatetime\n",
      "2020.08.12 02:00:11\n",
      "Tag Datetime for all instances assign!\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "assignTagDayDatetimeToEachInstance(turtlesData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning, the AllGpsDf called: allGpsDf_Tag_710333a_2021_Feb.csv, contained 4652 rows\n",
      "Removing 2019 data from the allGpsDf_Tag_710333a_2021_Feb.csv\n",
      "After removing 2019 data, the AllGpsDf called: allGpsDf_Tag_710333a_2021_Feb.csv, contained 4641 rows\n",
      "--------------\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                     12  2020.06.27 08:03:28    2020.06.27 08:02:40   \n",
      "1                     13  2020.06.27 15:39:07    2020.06.27 15:35:59   \n",
      "2                     14  2020.06.29 09:24:06    2020.06.29 09:22:54   \n",
      "3                     15  2020.06.29 10:00:07    2020.06.29 10:00:00   \n",
      "4                     16  2020.06.29 10:30:07    2020.06.29 10:30:00   \n",
      "...                  ...                  ...                    ...   \n",
      "4636                4648  2021.02.10 19:28:58    2021.02.10 19:00:00   \n",
      "4637                4649  2021.02.10 22:42:32    2021.02.10 22:00:00   \n",
      "4638                4650  2021.02.11 02:28:20    2021.02.11 02:00:00   \n",
      "4639                4651  2021.02.11 05:55:38    2021.02.11 05:00:00   \n",
      "4640                4652  2021.02.11 06:00:10    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0     2020.06.27 08:03:28       Succeeded     37.995522      16.123309  \n",
      "1     2020.06.27 15:39:07       Succeeded     37.925063      16.059105  \n",
      "2     2020.06.29 09:24:06       Succeeded     37.924899      16.058567  \n",
      "3     2020.06.29 10:00:07    Resolved QFP     37.924433      16.058961  \n",
      "4     2020.06.29 10:30:07    Resolved QFP     37.924525      16.058992  \n",
      "...                   ...             ...           ...            ...  \n",
      "4636  2021.02.10 19:28:58    Resolved QFP     38.754772      11.809630  \n",
      "4637  2021.02.10 22:42:32    Resolved QFP     38.741873      11.821516  \n",
      "4638  2021.02.11 02:28:20    Resolved QFP     38.727643      11.821051  \n",
      "4639  2021.02.11 05:55:38    Resolved QFP     38.720644      11.825379  \n",
      "4640  2021.02.11 06:00:10    Resolved QFP     38.720648      11.825217  \n",
      "\n",
      "[3329 rows x 7 columns]\n",
      "13    2020.07.09 23:00:09\n",
      "15    2020.07.09 23:30:12\n",
      "17    2020.07.10 00:30:08\n",
      "19    2020.07.10 01:00:08\n",
      "21    2020.07.10 01:30:07\n",
      "23    2020.07.10 02:00:08\n",
      "Name: Acquisition Time, dtype: object\n",
      "Without duplicated rows, the dataframe has now 3329 rows\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                     12  2020.06.27 08:03:28    2020.06.27 08:02:40   \n",
      "1                     13  2020.06.27 15:39:07    2020.06.27 15:35:59   \n",
      "2                     14  2020.06.29 09:24:06    2020.06.29 09:22:54   \n",
      "3                     15  2020.06.29 10:00:07    2020.06.29 10:00:00   \n",
      "4                     16  2020.06.29 10:30:07    2020.06.29 10:30:00   \n",
      "...                  ...                  ...                    ...   \n",
      "4636                4648  2021.02.10 19:28:58    2021.02.10 19:00:00   \n",
      "4637                4649  2021.02.10 22:42:32    2021.02.10 22:00:00   \n",
      "4638                4650  2021.02.11 02:28:20    2021.02.11 02:00:00   \n",
      "4639                4651  2021.02.11 05:55:38    2021.02.11 05:00:00   \n",
      "4640                4652  2021.02.11 06:00:10    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0     2020.06.27 08:03:28       Succeeded     37.995522      16.123309  \n",
      "1     2020.06.27 15:39:07       Succeeded     37.925063      16.059105  \n",
      "2     2020.06.29 09:24:06       Succeeded     37.924899      16.058567  \n",
      "3     2020.06.29 10:00:07    Resolved QFP     37.924433      16.058961  \n",
      "4     2020.06.29 10:30:07    Resolved QFP     37.924525      16.058992  \n",
      "...                   ...             ...           ...            ...  \n",
      "4636  2021.02.10 19:28:58    Resolved QFP     38.754772      11.809630  \n",
      "4637  2021.02.10 22:42:32    Resolved QFP     38.741873      11.821516  \n",
      "4638  2021.02.11 02:28:20    Resolved QFP     38.727643      11.821051  \n",
      "4639  2021.02.11 05:55:38    Resolved QFP     38.720644      11.825379  \n",
      "4640  2021.02.11 06:00:10    Resolved QFP     38.720648      11.825217  \n",
      "\n",
      "[3261 rows x 7 columns]\n",
      "13    2020.07.09 23:00:09\n",
      "15    2020.07.09 23:30:12\n",
      "17    2020.07.10 00:30:08\n",
      "19    2020.07.10 01:00:08\n",
      "21    2020.07.10 01:30:07\n",
      "23    2020.07.10 02:00:08\n",
      "Name: Acquisition Time, dtype: object\n",
      "The lines where we had the same acquisition time\n",
      "33    2020.07.10 06:08:16\n",
      "35    2020.07.10 06:51:31\n",
      "37    2020.07.10 07:14:58\n",
      "39    2020.07.10 07:34:24\n",
      "41    2020.07.10 08:24:43\n",
      "43    2020.07.10 08:45:59\n",
      "Name: Acquisition Time, dtype: object\n",
      "Without duplicated acquisition times, the dataframe has now 3261 rows\n",
      "The df without duplicated rows and Without duplicated acquisition times is the duplicateRowsTemporaryDf\n",
      "--------------\n",
      "Excluding date BEFORE TAG DAY DATETIME\n",
      "    All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                   12  2020.06.27 08:03:28    2020.06.27 08:02:40   \n",
      "1                   13  2020.06.27 15:39:07    2020.06.27 15:35:59   \n",
      "2                   14  2020.06.29 09:24:06    2020.06.29 09:22:54   \n",
      "3                   15  2020.06.29 10:00:07    2020.06.29 10:00:00   \n",
      "4                   16  2020.06.29 10:30:07    2020.06.29 10:30:00   \n",
      "5                   17  2020.06.29 11:00:09    2020.06.29 11:00:00   \n",
      "6                   18  2020.06.29 11:30:08    2020.06.29 11:30:00   \n",
      "7                   19  2020.06.29 12:00:07    2020.06.29 12:00:00   \n",
      "8                   20  2020.06.29 12:30:10    2020.06.29 12:30:00   \n",
      "9                   21  2020.06.29 13:00:08    2020.06.29 13:00:00   \n",
      "10                  22  2020.06.29 13:30:08    2020.06.29 13:30:00   \n",
      "11                  23  2020.06.29 14:00:10    2020.06.29 14:00:00   \n",
      "12                  24  2020.07.09 22:39:05    2020.07.09 22:38:29   \n",
      "\n",
      "           GPS Fix Time           GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0   2020.06.27 08:03:28                 Succeeded     37.995522      16.123309  \n",
      "1   2020.06.27 15:39:07                 Succeeded     37.925063      16.059105  \n",
      "2   2020.06.29 09:24:06                 Succeeded     37.924899      16.058567  \n",
      "3   2020.06.29 10:00:07              Resolved QFP     37.924433      16.058961  \n",
      "4   2020.06.29 10:30:07              Resolved QFP     37.924525      16.058992  \n",
      "5   2020.06.29 11:00:09  Resolved QFP (Uncertain)     37.924453      16.058859  \n",
      "6   2020.06.29 11:30:08              Resolved QFP     37.924501      16.058975  \n",
      "7   2020.06.29 12:00:07              Resolved QFP     37.924509      16.058983  \n",
      "8   2020.06.29 12:30:10              Resolved QFP     37.924500      16.058956  \n",
      "9   2020.06.29 13:00:08              Resolved QFP     37.924474      16.058929  \n",
      "10  2020.06.29 13:30:08              Resolved QFP     37.924450      16.058951  \n",
      "11  2020.06.29 14:00:10              Resolved QFP     37.924491      16.058963  \n",
      "12  2020.07.09 22:39:05                 Succeeded     37.930134      16.068234  \n",
      "TEST -------------- TEST ------- TEST\n",
      "2020.07.09 23:00:09\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "13                    25  2020.07.09 23:00:09    2020.07.09 23:00:00   \n",
      "15                    27  2020.07.09 23:30:12    2020.07.09 23:30:00   \n",
      "17                    29  2020.07.10 00:30:08    2020.07.10 00:30:00   \n",
      "19                    31  2020.07.10 01:00:08    2020.07.10 01:00:00   \n",
      "21                    33  2020.07.10 01:30:07    2020.07.10 01:30:00   \n",
      "...                  ...                  ...                    ...   \n",
      "4636                4648  2021.02.10 19:28:58    2021.02.10 19:00:00   \n",
      "4637                4649  2021.02.10 22:42:32    2021.02.10 22:00:00   \n",
      "4638                4650  2021.02.11 02:28:20    2021.02.11 02:00:00   \n",
      "4639                4651  2021.02.11 05:55:38    2021.02.11 05:00:00   \n",
      "4640                4652  2021.02.11 06:00:10    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time           GPS Fix Attempt  GPS Latitude  \\\n",
      "13    2020.07.09 23:00:09  Resolved QFP (Uncertain)     37.930044   \n",
      "15    2020.07.09 23:30:12              Resolved QFP     37.930187   \n",
      "17    2020.07.10 00:30:08              Resolved QFP     37.931116   \n",
      "19    2020.07.10 01:00:08              Resolved QFP     37.931058   \n",
      "21    2020.07.10 01:30:07              Resolved QFP     37.931116   \n",
      "...                   ...                       ...           ...   \n",
      "4636  2021.02.10 19:28:58              Resolved QFP     38.754772   \n",
      "4637  2021.02.10 22:42:32              Resolved QFP     38.741873   \n",
      "4638  2021.02.11 02:28:20              Resolved QFP     38.727643   \n",
      "4639  2021.02.11 05:55:38              Resolved QFP     38.720644   \n",
      "4640  2021.02.11 06:00:10              Resolved QFP     38.720648   \n",
      "\n",
      "      GPS Longitude  \n",
      "13        16.068138  \n",
      "15        16.068178  \n",
      "17        16.069576  \n",
      "19        16.069576  \n",
      "21        16.069615  \n",
      "...             ...  \n",
      "4636      11.809630  \n",
      "4637      11.821516  \n",
      "4638      11.821051  \n",
      "4639      11.825379  \n",
      "4640      11.825217  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3248 rows x 7 columns]\n",
      "Without days before turtle tag day, the dataframe has now 3248 rows\n",
      "The df without duplicated rows, without duplicated acquisition times and without days before turtle tag is the testDateRowsTemporaryDf\n",
      "--------------\n",
      "ALL THE DF THAT IS GONNA BE SAVE IN ALL CLEANED GPS DATAFRAME\n",
      "Saving this temporary df into the allCleanedGpsDf...\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                     25  2020.07.09 23:00:09    2020.07.09 23:00:00   \n",
      "1                     27  2020.07.09 23:30:12    2020.07.09 23:30:00   \n",
      "2                     29  2020.07.10 00:30:08    2020.07.10 00:30:00   \n",
      "3                     31  2020.07.10 01:00:08    2020.07.10 01:00:00   \n",
      "4                     33  2020.07.10 01:30:07    2020.07.10 01:30:00   \n",
      "...                  ...                  ...                    ...   \n",
      "3243                4648  2021.02.10 19:28:58    2021.02.10 19:00:00   \n",
      "3244                4649  2021.02.10 22:42:32    2021.02.10 22:00:00   \n",
      "3245                4650  2021.02.11 02:28:20    2021.02.11 02:00:00   \n",
      "3246                4651  2021.02.11 05:55:38    2021.02.11 05:00:00   \n",
      "3247                4652  2021.02.11 06:00:10    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time           GPS Fix Attempt  GPS Latitude  \\\n",
      "0     2020.07.09 23:00:09  Resolved QFP (Uncertain)     37.930044   \n",
      "1     2020.07.09 23:30:12              Resolved QFP     37.930187   \n",
      "2     2020.07.10 00:30:08              Resolved QFP     37.931116   \n",
      "3     2020.07.10 01:00:08              Resolved QFP     37.931058   \n",
      "4     2020.07.10 01:30:07              Resolved QFP     37.931116   \n",
      "...                   ...                       ...           ...   \n",
      "3243  2021.02.10 19:28:58              Resolved QFP     38.754772   \n",
      "3244  2021.02.10 22:42:32              Resolved QFP     38.741873   \n",
      "3245  2021.02.11 02:28:20              Resolved QFP     38.727643   \n",
      "3246  2021.02.11 05:55:38              Resolved QFP     38.720644   \n",
      "3247  2021.02.11 06:00:10              Resolved QFP     38.720648   \n",
      "\n",
      "      GPS Longitude  \n",
      "0         16.068138  \n",
      "1         16.068178  \n",
      "2         16.069576  \n",
      "3         16.069576  \n",
      "4         16.069615  \n",
      "...             ...  \n",
      "3243      11.809630  \n",
      "3244      11.821516  \n",
      "3245      11.821051  \n",
      "3246      11.825379  \n",
      "3247      11.825217  \n",
      "\n",
      "[3248 rows x 7 columns]\n",
      "13    2020.07.10 07:34:24\n",
      "14    2020.07.10 08:24:43\n",
      "15    2020.07.10 08:45:59\n",
      "16    2020.07.10 09:35:16\n",
      "17    2020.07.10 10:47:42\n",
      "18    2020.07.10 11:06:10\n",
      "Name: Acquisition Time, dtype: object\n",
      "The df without duplicated rows is now the self.allCleanedGpsDf\n",
      "------- END -------\n",
      "Before cleaning, the AllGpsDf called: allGpsDf_Tag_710348a_2021_Feb.csv, contained 2580 rows\n",
      "Removing 2019 data from the allGpsDf_Tag_710348a_2021_Feb.csv\n",
      "After removing 2019 data, the AllGpsDf called: allGpsDf_Tag_710348a_2021_Feb.csv, contained 2569 rows\n",
      "--------------\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                     12  2020.08.03 20:38:24    2020.08.03 20:37:17   \n",
      "1                     13  2020.08.04 12:49:31    2020.08.04 12:45:00   \n",
      "2                     14  2020.08.04 12:49:31    2020.08.04 12:48:35   \n",
      "3                     15  2020.08.05 12:29:21    2020.08.05 12:15:00   \n",
      "4                     16  2020.08.05 12:29:21    2020.08.05 12:28:28   \n",
      "...                  ...                  ...                    ...   \n",
      "2564                2576  2021.02.10 22:28:03    2021.02.10 22:00:00   \n",
      "2565                2577  2021.02.11 02:57:25    2021.02.11 02:00:00   \n",
      "2566                2578  2021.02.11 03:00:07    2021.02.11 03:00:00   \n",
      "2567                2579  2021.02.11 05:50:10    2021.02.11 05:00:00   \n",
      "2568                2580  2021.02.11 06:41:28    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0     2020.08.03 20:38:24       Succeeded     37.918752      15.990526  \n",
      "1     2020.08.04 12:49:31       Succeeded     37.918734      15.990457  \n",
      "2     2020.08.04 12:49:31       Succeeded     37.918734      15.990457  \n",
      "3     2020.08.05 12:29:21       Succeeded     37.918737      15.990459  \n",
      "4     2020.08.05 12:29:21       Succeeded     37.918737      15.990459  \n",
      "...                   ...             ...           ...            ...  \n",
      "2564  2021.02.10 22:28:03    Resolved QFP     37.799874      17.300539  \n",
      "2565  2021.02.11 02:57:25    Resolved QFP     37.781820      17.352911  \n",
      "2566  2021.02.11 03:00:07    Resolved QFP     37.781188      17.353534  \n",
      "2567  2021.02.11 05:50:10    Resolved QFP     37.752154      17.380009  \n",
      "2568  2021.02.11 06:41:28    Resolved QFP     37.742126      17.386460  \n",
      "\n",
      "[2569 rows x 7 columns]\n",
      "13    2020.08.12 07:58:14\n",
      "14    2020.08.12 08:00:06\n",
      "15    2020.08.12 08:34:30\n",
      "16    2020.08.12 09:16:38\n",
      "17    2020.08.12 09:54:19\n",
      "18    2020.08.12 10:00:06\n",
      "Name: Acquisition Time, dtype: object\n",
      "Without duplicated rows, the dataframe has now 2569 rows\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                     12  2020.08.03 20:38:24    2020.08.03 20:37:17   \n",
      "1                     13  2020.08.04 12:49:31    2020.08.04 12:45:00   \n",
      "3                     15  2020.08.05 12:29:21    2020.08.05 12:15:00   \n",
      "5                     17  2020.08.12 01:24:05    2020.08.12 01:23:21   \n",
      "6                     18  2020.08.12 02:00:11    2020.08.12 02:00:00   \n",
      "...                  ...                  ...                    ...   \n",
      "2564                2576  2021.02.10 22:28:03    2021.02.10 22:00:00   \n",
      "2565                2577  2021.02.11 02:57:25    2021.02.11 02:00:00   \n",
      "2566                2578  2021.02.11 03:00:07    2021.02.11 03:00:00   \n",
      "2567                2579  2021.02.11 05:50:10    2021.02.11 05:00:00   \n",
      "2568                2580  2021.02.11 06:41:28    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0     2020.08.03 20:38:24       Succeeded     37.918752      15.990526  \n",
      "1     2020.08.04 12:49:31       Succeeded     37.918734      15.990457  \n",
      "3     2020.08.05 12:29:21       Succeeded     37.918737      15.990459  \n",
      "5     2020.08.12 01:24:05       Succeeded     37.928312      15.910054  \n",
      "6     2020.08.12 02:00:11    Resolved QFP     37.928124      15.909817  \n",
      "...                   ...             ...           ...            ...  \n",
      "2564  2021.02.10 22:28:03    Resolved QFP     37.799874      17.300539  \n",
      "2565  2021.02.11 02:57:25    Resolved QFP     37.781820      17.352911  \n",
      "2566  2021.02.11 03:00:07    Resolved QFP     37.781188      17.353534  \n",
      "2567  2021.02.11 05:50:10    Resolved QFP     37.752154      17.380009  \n",
      "2568  2021.02.11 06:41:28    Resolved QFP     37.742126      17.386460  \n",
      "\n",
      "[2567 rows x 7 columns]\n",
      "15    2020.08.12 08:34:30\n",
      "16    2020.08.12 09:16:38\n",
      "17    2020.08.12 09:54:19\n",
      "18    2020.08.12 10:00:06\n",
      "19    2020.08.12 10:33:02\n",
      "20    2020.08.12 11:02:25\n",
      "Name: Acquisition Time, dtype: object\n",
      "The lines where we had the same acquisition time\n",
      "25    2020.08.12 14:08:36\n",
      "26    2020.08.12 14:35:11\n",
      "27    2020.08.12 15:21:23\n",
      "28    2020.08.12 16:04:31\n",
      "29    2020.08.12 16:36:47\n",
      "30    2020.08.12 17:20:22\n",
      "Name: Acquisition Time, dtype: object\n",
      "Without duplicated acquisition times, the dataframe has now 2567 rows\n",
      "The df without duplicated rows and Without duplicated acquisition times is the duplicateRowsTemporaryDf\n",
      "--------------\n",
      "Excluding date BEFORE TAG DAY DATETIME\n",
      "   All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                  12  2020.08.03 20:38:24    2020.08.03 20:37:17   \n",
      "1                  13  2020.08.04 12:49:31    2020.08.04 12:45:00   \n",
      "3                  15  2020.08.05 12:29:21    2020.08.05 12:15:00   \n",
      "5                  17  2020.08.12 01:24:05    2020.08.12 01:23:21   \n",
      "\n",
      "          GPS Fix Time GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0  2020.08.03 20:38:24       Succeeded     37.918752      15.990526  \n",
      "1  2020.08.04 12:49:31       Succeeded     37.918734      15.990457  \n",
      "3  2020.08.05 12:29:21       Succeeded     37.918737      15.990459  \n",
      "5  2020.08.12 01:24:05       Succeeded     37.928312      15.910054  \n",
      "TEST -------------- TEST ------- TEST\n",
      "2020.08.12 02:00:11\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "6                     18  2020.08.12 02:00:11    2020.08.12 02:00:00   \n",
      "7                     19  2020.08.12 02:47:29    2020.08.12 02:30:00   \n",
      "8                     20  2020.08.12 03:02:44    2020.08.12 03:00:00   \n",
      "9                     21  2020.08.12 03:33:54    2020.08.12 03:30:00   \n",
      "10                    22  2020.08.12 04:20:06    2020.08.12 04:00:00   \n",
      "...                  ...                  ...                    ...   \n",
      "2564                2576  2021.02.10 22:28:03    2021.02.10 22:00:00   \n",
      "2565                2577  2021.02.11 02:57:25    2021.02.11 02:00:00   \n",
      "2566                2578  2021.02.11 03:00:07    2021.02.11 03:00:00   \n",
      "2567                2579  2021.02.11 05:50:10    2021.02.11 05:00:00   \n",
      "2568                2580  2021.02.11 06:41:28    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "6     2020.08.12 02:00:11    Resolved QFP     37.928124      15.909817  \n",
      "7     2020.08.12 02:47:29    Resolved QFP     37.921919      15.914211  \n",
      "8     2020.08.12 03:02:44    Resolved QFP     37.919124      15.916755  \n",
      "9     2020.08.12 03:33:54    Resolved QFP     37.916251      15.924993  \n",
      "10    2020.08.12 04:20:06  Unresolved QFP     37.897905      15.922014  \n",
      "...                   ...             ...           ...            ...  \n",
      "2564  2021.02.10 22:28:03    Resolved QFP     37.799874      17.300539  \n",
      "2565  2021.02.11 02:57:25    Resolved QFP     37.781820      17.352911  \n",
      "2566  2021.02.11 03:00:07    Resolved QFP     37.781188      17.353534  \n",
      "2567  2021.02.11 05:50:10    Resolved QFP     37.752154      17.380009  \n",
      "2568  2021.02.11 06:41:28    Resolved QFP     37.742126      17.386460  \n",
      "\n",
      "[2563 rows x 7 columns]\n",
      "Without days before turtle tag day, the dataframe has now 2563 rows\n",
      "The df without duplicated rows, without duplicated acquisition times and without days before turtle tag is the testDateRowsTemporaryDf\n",
      "--------------\n",
      "ALL THE DF THAT IS GONNA BE SAVE IN ALL CLEANED GPS DATAFRAME\n",
      "Saving this temporary df into the allCleanedGpsDf...\n",
      "      All GPS's Track ID     Acquisition Time Acquisition Start Time  \\\n",
      "0                     18  2020.08.12 02:00:11    2020.08.12 02:00:00   \n",
      "1                     19  2020.08.12 02:47:29    2020.08.12 02:30:00   \n",
      "2                     20  2020.08.12 03:02:44    2020.08.12 03:00:00   \n",
      "3                     21  2020.08.12 03:33:54    2020.08.12 03:30:00   \n",
      "4                     22  2020.08.12 04:20:06    2020.08.12 04:00:00   \n",
      "...                  ...                  ...                    ...   \n",
      "2558                2576  2021.02.10 22:28:03    2021.02.10 22:00:00   \n",
      "2559                2577  2021.02.11 02:57:25    2021.02.11 02:00:00   \n",
      "2560                2578  2021.02.11 03:00:07    2021.02.11 03:00:00   \n",
      "2561                2579  2021.02.11 05:50:10    2021.02.11 05:00:00   \n",
      "2562                2580  2021.02.11 06:41:28    2021.02.11 06:00:00   \n",
      "\n",
      "             GPS Fix Time GPS Fix Attempt  GPS Latitude  GPS Longitude  \n",
      "0     2020.08.12 02:00:11    Resolved QFP     37.928124      15.909817  \n",
      "1     2020.08.12 02:47:29    Resolved QFP     37.921919      15.914211  \n",
      "2     2020.08.12 03:02:44    Resolved QFP     37.919124      15.916755  \n",
      "3     2020.08.12 03:33:54    Resolved QFP     37.916251      15.924993  \n",
      "4     2020.08.12 04:20:06  Unresolved QFP     37.897905      15.922014  \n",
      "...                   ...             ...           ...            ...  \n",
      "2558  2021.02.10 22:28:03    Resolved QFP     37.799874      17.300539  \n",
      "2559  2021.02.11 02:57:25    Resolved QFP     37.781820      17.352911  \n",
      "2560  2021.02.11 03:00:07    Resolved QFP     37.781188      17.353534  \n",
      "2561  2021.02.11 05:50:10    Resolved QFP     37.752154      17.380009  \n",
      "2562  2021.02.11 06:41:28    Resolved QFP     37.742126      17.386460  \n",
      "\n",
      "[2563 rows x 7 columns]\n",
      "13    2020.08.12 10:33:02\n",
      "14    2020.08.12 11:02:25\n",
      "15    2020.08.12 11:40:05\n",
      "16    2020.08.12 12:00:06\n",
      "17    2020.08.12 13:02:28\n",
      "18    2020.08.12 13:53:35\n",
      "Name: Acquisition Time, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df without duplicated rows is now the self.allCleanedGpsDf\n",
      "------- END -------\n"
     ]
    }
   ],
   "source": [
    "# now we need to look at the all gps df and delete the duplicates rows, before calculating the errors by speed\n",
    "# deleting duplicate rows and 2019 date\n",
    "getAllCleanedGpsDataframes(turtlesData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Last Entry in the Dataframe for 710333a is from: \n",
      "2021_Feb\n",
      "The Name for the allCleanedGpsDf CSV for the turtleData 710333a is: \n",
      "allCleanedGpsDf_Tag_710333a_2021_Feb.csv\n",
      "--------------\n",
      "The Last Entry in the Dataframe for 710348a is from: \n",
      "2021_Feb\n",
      "The Name for the allCleanedGpsDf CSV for the turtleData 710348a is: \n",
      "allCleanedGpsDf_Tag_710348a_2021_Feb.csv\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# get name for each ALL CLEANED GPS DF turtleData\n",
    "createAllCleanedGpsDfCsvNameForEachInstance(turtlesData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allGpsDf_Tag_710333a_2021_Feb.csv', 'allGpsDf_Tag_710348a_2021_Feb.csv']\n",
      "The filename allCleanedGpsDf_Tag_710333a_2021_Feb.csv is not yet in the folder... saving csv\n",
      "allCleanedGpsDf_Tag_710333a_2021_Feb.csv has been saved in the results folder!\n",
      "--------------\n",
      "The filename allCleanedGpsDf_Tag_710348a_2021_Feb.csv is not yet in the folder... saving csv\n",
      "allCleanedGpsDf_Tag_710348a_2021_Feb.csv has been saved in the results folder!\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# SAVE THE ALL CLEANED GPS DATAFRAME in the Results Folder\n",
    "checkIfAllCleanedGpsDfHasBeenSaved(turtlesData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710333a\n",
      "Length of pointsToRemove List: \n",
      "33\n",
      "remSpeeds List: [array([1.18930457]), array([1.13096368]), array([42.3998984]), array([988.21761595]), array([282.15571977]), array([4.03555561]), array([171.75018604]), array([59.95711877]), array([10.36168531]), array([15.99201645]), array([234.99330641]), array([38.33812958]), array([218.95642372]), array([329.99169271]), array([1.40032288]), array([1.17689876]), array([151.11015997]), array([80.5629416]), array([21.39557692]), array([1.59042348]), array([27.78637835]), array([1.14580626]), array([41.69783778]), array([3.86245364]), array([1.22538072]), array([6.8776525]), array([23.15440736]), array([5.07402054]), array([9.28365653]), array([1.34491866]), array([29.8952071]), array([1.12774978]), array([111.65462206])]\n",
      "--------------\n",
      "['2020.07.26 05:30:07', '2020.07.28 17:33:12', '2020.08.02 04:34:30', '2020.08.05 07:01:05', '2020.08.06 08:38:31', '2020.08.06 17:36:30', '2020.08.23 19:36:02', '2020.08.24 06:58:17', '2020.08.26 01:09:49', '2020.08.30 07:10:28', '2020.09.11 22:58:22', '2020.09.19 15:40:49', '2020.10.10 03:25:59', '2020.10.20 23:10:33', '2020.10.25 10:00:06', '2020.11.02 05:00:21', '2020.11.09 12:01:17', '2020.11.29 12:40:16', '2020.12.18 15:00:40', '2020.12.23 23:02:39', '2020.12.25 13:45:58', '2020.12.29 09:15:12', '2021.01.02 17:11:16', '2021.01.07 14:00:02', '2021.01.10 00:00:02', '2021.01.17 16:10:06', '2021.01.21 23:00:19', '2021.01.22 23:00:06', '2021.01.23 14:00:06', '2021.01.25 07:25:21', '2021.01.27 09:49:09', '2021.01.29 05:50:59', '2021.02.10 15:59:39']\n",
      "BEFORE DROP - removingGpsErrorsTemporaryDf\n",
      "3248\n",
      "AFTER DROP - removingGpsErrorsTemporaryDf\n",
      "3215\n",
      "BEFORE CHANGES - FROM INT TO FLOAT\n",
      "<class 'int'>\n",
      "AFTER CHANGES - FROM INT TO FLOAT\n",
      "<class 'numpy.float64'>\n",
      "Assign the Reliable GPS DF of the objs\n",
      "      Speed Reliable ID  All GPS's Track ID     Acquisition Time  \\\n",
      "0                     1                  25  2020.07.09 23:00:09   \n",
      "1                     2                  27  2020.07.09 23:30:12   \n",
      "2                     3                  29  2020.07.10 00:30:08   \n",
      "3                     4                  31  2020.07.10 01:00:08   \n",
      "4                     5                  33  2020.07.10 01:30:07   \n",
      "...                 ...                 ...                  ...   \n",
      "3210               3244                4648  2021.02.10 19:28:58   \n",
      "3211               3245                4649  2021.02.10 22:42:32   \n",
      "3212               3246                4650  2021.02.11 02:28:20   \n",
      "3213               3247                4651  2021.02.11 05:55:38   \n",
      "3214               3248                4652  2021.02.11 06:00:10   \n",
      "\n",
      "     Acquisition Start Time         GPS Fix Time           GPS Fix Attempt  \\\n",
      "0       2020.07.09 23:00:00  2020.07.09 23:00:09  Resolved QFP (Uncertain)   \n",
      "1       2020.07.09 23:30:00  2020.07.09 23:30:12              Resolved QFP   \n",
      "2       2020.07.10 00:30:00  2020.07.10 00:30:08              Resolved QFP   \n",
      "3       2020.07.10 01:00:00  2020.07.10 01:00:08              Resolved QFP   \n",
      "4       2020.07.10 01:30:00  2020.07.10 01:30:07              Resolved QFP   \n",
      "...                     ...                  ...                       ...   \n",
      "3210    2021.02.10 19:00:00  2021.02.10 19:28:58              Resolved QFP   \n",
      "3211    2021.02.10 22:00:00  2021.02.10 22:42:32              Resolved QFP   \n",
      "3212    2021.02.11 02:00:00  2021.02.11 02:28:20              Resolved QFP   \n",
      "3213    2021.02.11 05:00:00  2021.02.11 05:55:38              Resolved QFP   \n",
      "3214    2021.02.11 06:00:00  2021.02.11 06:00:10              Resolved QFP   \n",
      "\n",
      "      GPS Latitude  GPS Longitude  Distance (m)  Time (s)  Speed m/s  \\\n",
      "0        37.930044      16.068138      0.000000       0.0   0.000000   \n",
      "1        37.930187      16.068178     16.257208    1803.0   0.009017   \n",
      "2        37.931116      16.069576    160.431667    3596.0   0.044614   \n",
      "3        37.931058      16.069576      6.437720    1800.0   0.003577   \n",
      "4        37.931116      16.069615      7.293834    1799.0   0.004054   \n",
      "...            ...            ...           ...       ...        ...   \n",
      "3210     38.754772      11.809630   2006.649120   12816.0   0.156574   \n",
      "3211     38.741873      11.821516   1765.808613   11614.0   0.152041   \n",
      "3212     38.727643      11.821051   1580.195674   13548.0   0.116637   \n",
      "3213     38.720644      11.825379    863.320601   12438.0   0.069410   \n",
      "3214     38.720648      11.825217     14.095488     272.0   0.051822   \n",
      "\n",
      "            Time (h)  \n",
      "0    0 days 00:00:00  \n",
      "1    0 days 00:30:03  \n",
      "2    0 days 00:59:56  \n",
      "3    0 days 00:30:00  \n",
      "4    0 days 00:29:59  \n",
      "...              ...  \n",
      "3210 0 days 03:33:36  \n",
      "3211 0 days 03:13:34  \n",
      "3212 0 days 03:45:48  \n",
      "3213 0 days 03:27:18  \n",
      "3214 0 days 00:04:32  \n",
      "\n",
      "[3215 rows x 12 columns]\n",
      "Speed Reliable ID                   int64\n",
      "All GPS's Track ID                  int64\n",
      "Acquisition Time                   object\n",
      "Acquisition Start Time             object\n",
      "GPS Fix Time                       object\n",
      "GPS Fix Attempt                    object\n",
      "GPS Latitude                      float64\n",
      "GPS Longitude                     float64\n",
      "Distance (m)                      float64\n",
      "Time (s)                          float64\n",
      "Speed m/s                         float64\n",
      "Time (h)                  timedelta64[ns]\n",
      "dtype: object\n",
      "--------------\n",
      "710348a\n",
      "Length of pointsToRemove List: \n",
      "14\n",
      "remSpeeds List: [array([32.6084126]), array([1.170557]), array([177.62047653]), array([177.47599964]), array([1.55690435]), array([192.31635835]), array([168.02518142]), array([1.17419418]), array([42.03013665]), array([5.1905697]), array([10.26749834]), array([44.55296201]), array([1.25665037]), array([21.49260763])]\n",
      "--------------\n",
      "['2020.08.13 02:04:04', '2020.08.14 21:01:15', '2020.08.16 21:01:00', '2020.08.17 02:36:48', '2020.08.20 13:09:28', '2020.09.07 01:30:11', '2020.09.17 21:09:34', '2020.09.27 20:00:17', '2020.10.11 18:09:28', '2020.11.22 12:00:48', '2020.11.22 18:02:52', '2020.12.04 00:00:49', '2020.12.21 19:00:03', '2021.01.27 18:00:17']\n",
      "BEFORE DROP - removingGpsErrorsTemporaryDf\n",
      "2563\n",
      "AFTER DROP - removingGpsErrorsTemporaryDf\n",
      "2549\n",
      "BEFORE CHANGES - FROM INT TO FLOAT\n",
      "<class 'int'>\n",
      "AFTER CHANGES - FROM INT TO FLOAT\n",
      "<class 'numpy.float64'>\n",
      "Assign the Reliable GPS DF of the objs\n",
      "      Speed Reliable ID  All GPS's Track ID     Acquisition Time  \\\n",
      "0                     1                  18  2020.08.12 02:00:11   \n",
      "1                     2                  19  2020.08.12 02:47:29   \n",
      "2                     3                  20  2020.08.12 03:02:44   \n",
      "3                     4                  21  2020.08.12 03:33:54   \n",
      "4                     5                  22  2020.08.12 04:20:06   \n",
      "...                 ...                 ...                  ...   \n",
      "2544               2559                2576  2021.02.10 22:28:03   \n",
      "2545               2560                2577  2021.02.11 02:57:25   \n",
      "2546               2561                2578  2021.02.11 03:00:07   \n",
      "2547               2562                2579  2021.02.11 05:50:10   \n",
      "2548               2563                2580  2021.02.11 06:41:28   \n",
      "\n",
      "     Acquisition Start Time         GPS Fix Time GPS Fix Attempt  \\\n",
      "0       2020.08.12 02:00:00  2020.08.12 02:00:11    Resolved QFP   \n",
      "1       2020.08.12 02:30:00  2020.08.12 02:47:29    Resolved QFP   \n",
      "2       2020.08.12 03:00:00  2020.08.12 03:02:44    Resolved QFP   \n",
      "3       2020.08.12 03:30:00  2020.08.12 03:33:54    Resolved QFP   \n",
      "4       2020.08.12 04:00:00  2020.08.12 04:20:06  Unresolved QFP   \n",
      "...                     ...                  ...             ...   \n",
      "2544    2021.02.10 22:00:00  2021.02.10 22:28:03    Resolved QFP   \n",
      "2545    2021.02.11 02:00:00  2021.02.11 02:57:25    Resolved QFP   \n",
      "2546    2021.02.11 03:00:00  2021.02.11 03:00:07    Resolved QFP   \n",
      "2547    2021.02.11 05:00:00  2021.02.11 05:50:10    Resolved QFP   \n",
      "2548    2021.02.11 06:00:00  2021.02.11 06:41:28    Resolved QFP   \n",
      "\n",
      "      GPS Latitude  GPS Longitude  Distance (m)  Time (s)  Speed m/s  \\\n",
      "0        37.928124      15.909817      0.000000       0.0   0.000000   \n",
      "1        37.921919      15.914211    789.677704    2838.0   0.278251   \n",
      "2        37.919124      15.916755    382.464365     915.0   0.417994   \n",
      "3        37.916251      15.924993    791.457102    1870.0   0.423239   \n",
      "4        37.897905      15.922014   2053.092728    2772.0   0.740654   \n",
      "...            ...            ...           ...       ...        ...   \n",
      "2544     37.799874      17.300539   4429.429868   16080.0   0.275462   \n",
      "2545     37.781820      17.352911   5029.430965   16162.0   0.311189   \n",
      "2546     37.781188      17.353534     89.065211     162.0   0.549785   \n",
      "2547     37.752154      17.380009   3978.232773   10203.0   0.389908   \n",
      "2548     37.742126      17.386460   1249.827975    3078.0   0.406052   \n",
      "\n",
      "            Time (h)  \n",
      "0    0 days 00:00:00  \n",
      "1    0 days 00:47:18  \n",
      "2    0 days 00:15:15  \n",
      "3    0 days 00:31:10  \n",
      "4    0 days 00:46:12  \n",
      "...              ...  \n",
      "2544 0 days 04:28:00  \n",
      "2545 0 days 04:29:22  \n",
      "2546 0 days 00:02:42  \n",
      "2547 0 days 02:50:03  \n",
      "2548 0 days 00:51:18  \n",
      "\n",
      "[2549 rows x 12 columns]\n",
      "Speed Reliable ID                   int64\n",
      "All GPS's Track ID                  int64\n",
      "Acquisition Time                   object\n",
      "Acquisition Start Time             object\n",
      "GPS Fix Time                       object\n",
      "GPS Fix Attempt                    object\n",
      "GPS Latitude                      float64\n",
      "GPS Longitude                     float64\n",
      "Distance (m)                      float64\n",
      "Time (s)                          float64\n",
      "Speed m/s                         float64\n",
      "Time (h)                  timedelta64[ns]\n",
      "dtype: object\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# see dfs of the Temp reliable gps with no tag date (Remove GPS Errors by Angular velocity/Rotational speed)\n",
    "getTempReliableGpsDfWithNoTagDateDataframes(turtlesData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Last Entry in the Dataframe for 710333a is from: \n",
      "2021_Feb\n",
      "The Name for the tempReliableGpsDfWithNoTagDate CSV for the turtleData 710333a is: \n",
      "tempReliableGpsDfWithNoTagDate_Tag_710333a_2021_Feb.csv\n",
      "--------------\n",
      "The Last Entry in the Dataframe for 710348a is from: \n",
      "2021_Feb\n",
      "The Name for the tempReliableGpsDfWithNoTagDate CSV for the turtleData 710348a is: \n",
      "tempReliableGpsDfWithNoTagDate_Tag_710348a_2021_Feb.csv\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# get name for each TEMP RELIABLE GPS DF WITH NO TAG DATE turtleData\n",
    "createTempReliableGpsDfWithNoTagDateCsvNameCsvNameForEachInstance(turtlesData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allGpsDf_Tag_710333a_2021_Feb.csv', 'allGpsDf_Tag_710348a_2021_Feb.csv']\n",
      "The filename tempReliableGpsDfWithNoTagDate_Tag_710333a_2021_Feb.csv is not yet in the folder... saving csv\n",
      "tempReliableGpsDfWithNoTagDate_Tag_710333a_2021_Feb.csv has been saved in the results folder!\n",
      "--------------\n",
      "The filename tempReliableGpsDfWithNoTagDate_Tag_710348a_2021_Feb.csv is not yet in the folder... saving csv\n",
      "tempReliableGpsDfWithNoTagDate_Tag_710348a_2021_Feb.csv has been saved in the results folder!\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# SAVE THE TEMP RELIABLE GPS DATAFRAME WITH NO TAG DATE in the Results Folder\n",
    "checkIfTempReliableGpsDfWithNoTagDateHasBeenSaved(turtlesData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
